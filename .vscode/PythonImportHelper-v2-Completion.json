[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "get_asgi_application",
        "importPath": "django.core.asgi",
        "description": "django.core.asgi",
        "isExtraImport": true,
        "detail": "django.core.asgi",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "include",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "include",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "get_wsgi_application",
        "importPath": "django.core.wsgi",
        "description": "django.core.wsgi",
        "isExtraImport": true,
        "detail": "django.core.wsgi",
        "documentation": {}
    },
    {
        "label": "audiostack",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "audiostack",
        "description": "audiostack",
        "detail": "audiostack",
        "documentation": {}
    },
    {
        "label": "azure.cognitiveservices.speech",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "wave",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wave",
        "description": "wave",
        "detail": "wave",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "transliterate",
        "importPath": "aksharamukha",
        "description": "aksharamukha",
        "isExtraImport": true,
        "detail": "aksharamukha",
        "documentation": {}
    },
    {
        "label": "os,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.",
        "description": "os.",
        "detail": "os.",
        "documentation": {}
    },
    {
        "label": "DefaultAzureCredential",
        "importPath": "azure.identity",
        "description": "azure.identity",
        "isExtraImport": true,
        "detail": "azure.identity",
        "documentation": {}
    },
    {
        "label": "DefaultAzureCredential",
        "importPath": "azure.identity",
        "description": "azure.identity",
        "isExtraImport": true,
        "detail": "azure.identity",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob",
        "description": "azure.storage.blob",
        "isExtraImport": true,
        "detail": "azure.storage.blob",
        "documentation": {}
    },
    {
        "label": "BlobClient",
        "importPath": "azure.storage.blob",
        "description": "azure.storage.blob",
        "isExtraImport": true,
        "detail": "azure.storage.blob",
        "documentation": {}
    },
    {
        "label": "ContainerClient",
        "importPath": "azure.storage.blob",
        "description": "azure.storage.blob",
        "isExtraImport": true,
        "detail": "azure.storage.blob",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob",
        "description": "azure.storage.blob",
        "isExtraImport": true,
        "detail": "azure.storage.blob",
        "documentation": {}
    },
    {
        "label": "BlobClient",
        "importPath": "azure.storage.blob",
        "description": "azure.storage.blob",
        "isExtraImport": true,
        "detail": "azure.storage.blob",
        "documentation": {}
    },
    {
        "label": "ContainerClient",
        "importPath": "azure.storage.blob",
        "description": "azure.storage.blob",
        "isExtraImport": true,
        "detail": "azure.storage.blob",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageOps",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "openai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openai",
        "description": "openai",
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "google.generativeai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "VideoFileClip",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "ImageClip",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "CompositeVideoClip",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "VideoFileClip",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "concatenate_videoclips",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "VideoFileClip",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "concatenate_videoclips",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "fadein",
        "importPath": "moviepy.video.fx",
        "description": "moviepy.video.fx",
        "isExtraImport": true,
        "detail": "moviepy.video.fx",
        "documentation": {}
    },
    {
        "label": "fadeout",
        "importPath": "moviepy.video.fx",
        "description": "moviepy.video.fx",
        "isExtraImport": true,
        "detail": "moviepy.video.fx",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "query",
        "importPath": "bing_search_query",
        "description": "bing_search_query",
        "isExtraImport": true,
        "detail": "bing_search_query",
        "documentation": {}
    },
    {
        "label": "ImageSearchClient",
        "importPath": "azure.cognitiveservices.search.imagesearch",
        "description": "azure.cognitiveservices.search.imagesearch",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.search.imagesearch",
        "documentation": {}
    },
    {
        "label": "CognitiveServicesCredentials",
        "importPath": "msrest.authentication",
        "description": "msrest.authentication",
        "isExtraImport": true,
        "detail": "msrest.authentication",
        "documentation": {}
    },
    {
        "label": "CognitiveServicesCredentials",
        "importPath": "msrest.authentication",
        "description": "msrest.authentication",
        "isExtraImport": true,
        "detail": "msrest.authentication",
        "documentation": {}
    },
    {
        "label": "VideoSearchClient",
        "importPath": "azure.cognitiveservices.search.videosearch",
        "description": "azure.cognitiveservices.search.videosearch",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.search.videosearch",
        "documentation": {}
    },
    {
        "label": "VideoPricing",
        "importPath": "azure.cognitiveservices.search.videosearch.models",
        "description": "azure.cognitiveservices.search.videosearch.models",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.search.videosearch.models",
        "documentation": {}
    },
    {
        "label": "VideoLength",
        "importPath": "azure.cognitiveservices.search.videosearch.models",
        "description": "azure.cognitiveservices.search.videosearch.models",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.search.videosearch.models",
        "documentation": {}
    },
    {
        "label": "VideoResolution",
        "importPath": "azure.cognitiveservices.search.videosearch.models",
        "description": "azure.cognitiveservices.search.videosearch.models",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.search.videosearch.models",
        "documentation": {}
    },
    {
        "label": "VideoInsightModule",
        "importPath": "azure.cognitiveservices.search.videosearch.models",
        "description": "azure.cognitiveservices.search.videosearch.models",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.search.videosearch.models",
        "documentation": {}
    },
    {
        "label": "GoogleImagesSearch",
        "importPath": "google_images_search",
        "description": "google_images_search",
        "isExtraImport": true,
        "detail": "google_images_search",
        "documentation": {}
    },
    {
        "label": "GoogleImagesSearch",
        "importPath": "google_images_search",
        "description": "google_images_search",
        "isExtraImport": true,
        "detail": "google_images_search",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "spacy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "spacy",
        "description": "spacy",
        "detail": "spacy",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "KeyBERT",
        "importPath": "keybert",
        "description": "keybert",
        "isExtraImport": true,
        "detail": "keybert",
        "documentation": {}
    },
    {
        "label": "KeyBERT",
        "importPath": "keybert",
        "description": "keybert",
        "isExtraImport": true,
        "detail": "keybert",
        "documentation": {}
    },
    {
        "label": "KeyBERT",
        "importPath": "keybert",
        "description": "keybert",
        "isExtraImport": true,
        "detail": "keybert",
        "documentation": {}
    },
    {
        "label": "KeyBERT",
        "importPath": "keybert",
        "description": "keybert",
        "isExtraImport": true,
        "detail": "keybert",
        "documentation": {}
    },
    {
        "label": "KeyBERT",
        "importPath": "keybert",
        "description": "keybert",
        "isExtraImport": true,
        "detail": "keybert",
        "documentation": {}
    },
    {
        "label": "Rake",
        "importPath": "rake_nltk",
        "description": "rake_nltk",
        "isExtraImport": true,
        "detail": "rake_nltk",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "scraper_mustu",
        "description": "scraper_mustu",
        "isExtraImport": true,
        "detail": "scraper_mustu",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "image_search_mustu",
        "description": "image_search_mustu",
        "isExtraImport": true,
        "detail": "image_search_mustu",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "text_summarization_mustu",
        "description": "text_summarization_mustu",
        "isExtraImport": true,
        "detail": "text_summarization_mustu",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "keywords_extraction",
        "description": "keywords_extraction",
        "isExtraImport": true,
        "detail": "keywords_extraction",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "run_upload_video",
        "description": "run_upload_video",
        "isExtraImport": true,
        "detail": "run_upload_video",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "avatar",
        "description": "avatar",
        "isExtraImport": true,
        "detail": "avatar",
        "documentation": {}
    },
    {
        "label": "large_tts",
        "importPath": "text_to_speech_mustu",
        "description": "text_to_speech_mustu",
        "isExtraImport": true,
        "detail": "text_to_speech_mustu",
        "documentation": {}
    },
    {
        "label": "script",
        "importPath": "prompt_tune",
        "description": "prompt_tune",
        "isExtraImport": true,
        "detail": "prompt_tune",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "WhisperModel",
        "importPath": "faster_whisper",
        "description": "faster_whisper",
        "isExtraImport": true,
        "detail": "faster_whisper",
        "documentation": {}
    },
    {
        "label": "WhisperModel",
        "importPath": "faster_whisper",
        "description": "faster_whisper",
        "isExtraImport": true,
        "detail": "faster_whisper",
        "documentation": {}
    },
    {
        "label": "WhisperModel",
        "importPath": "faster_whisper",
        "description": "faster_whisper",
        "isExtraImport": true,
        "detail": "faster_whisper",
        "documentation": {}
    },
    {
        "label": "WhisperModel",
        "importPath": "faster_whisper",
        "description": "faster_whisper",
        "isExtraImport": true,
        "detail": "faster_whisper",
        "documentation": {}
    },
    {
        "label": "TextAnalyticsClient",
        "importPath": "azure.ai.textanalytics",
        "description": "azure.ai.textanalytics",
        "isExtraImport": true,
        "detail": "azure.ai.textanalytics",
        "documentation": {}
    },
    {
        "label": "TextAnalyticsClient",
        "importPath": "azure.ai.textanalytics",
        "description": "azure.ai.textanalytics",
        "isExtraImport": true,
        "detail": "azure.ai.textanalytics",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "docx",
        "description": "docx",
        "isExtraImport": true,
        "detail": "docx",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "docx",
        "description": "docx",
        "isExtraImport": true,
        "detail": "docx",
        "documentation": {}
    },
    {
        "label": "subject_json",
        "importPath": "Keyword_json",
        "description": "Keyword_json",
        "isExtraImport": true,
        "detail": "Keyword_json",
        "documentation": {}
    },
    {
        "label": "TextTranslationClient",
        "importPath": "azure.ai.translation.text",
        "description": "azure.ai.translation.text",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text",
        "documentation": {}
    },
    {
        "label": "TranslatorCredential",
        "importPath": "azure.ai.translation.text",
        "description": "azure.ai.translation.text",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text",
        "documentation": {}
    },
    {
        "label": "TextTranslationClient",
        "importPath": "azure.ai.translation.text",
        "description": "azure.ai.translation.text",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text",
        "documentation": {}
    },
    {
        "label": "TranslatorCredential",
        "importPath": "azure.ai.translation.text",
        "description": "azure.ai.translation.text",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text",
        "documentation": {}
    },
    {
        "label": "TextTranslationClient",
        "importPath": "azure.ai.translation.text",
        "description": "azure.ai.translation.text",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text",
        "documentation": {}
    },
    {
        "label": "TranslatorCredential",
        "importPath": "azure.ai.translation.text",
        "description": "azure.ai.translation.text",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text",
        "documentation": {}
    },
    {
        "label": "InputTextItem",
        "importPath": "azure.ai.translation.text.models",
        "description": "azure.ai.translation.text.models",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text.models",
        "documentation": {}
    },
    {
        "label": "InputTextItem",
        "importPath": "azure.ai.translation.text.models",
        "description": "azure.ai.translation.text.models",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text.models",
        "documentation": {}
    },
    {
        "label": "InputTextItem",
        "importPath": "azure.ai.translation.text.models",
        "description": "azure.ai.translation.text.models",
        "isExtraImport": true,
        "detail": "azure.ai.translation.text.models",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "PIL.Image",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL.Image",
        "description": "PIL.Image",
        "detail": "PIL.Image",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "url_select",
        "importPath": "edictai_app.app.scraper",
        "description": "edictai_app.app.scraper",
        "isExtraImport": true,
        "detail": "edictai_app.app.scraper",
        "documentation": {}
    },
    {
        "label": "get_keyword",
        "importPath": "edictai_app.app.keywords_extraction",
        "description": "edictai_app.app.keywords_extraction",
        "isExtraImport": true,
        "detail": "edictai_app.app.keywords_extraction",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "django.core.files",
        "description": "django.core.files",
        "isExtraImport": true,
        "detail": "django.core.files",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "django.core.files",
        "description": "django.core.files",
        "isExtraImport": true,
        "detail": "django.core.files",
        "documentation": {}
    },
    {
        "label": "send_mail",
        "importPath": "django.core.mail",
        "description": "django.core.mail",
        "isExtraImport": true,
        "detail": "django.core.mail",
        "documentation": {}
    },
    {
        "label": "EmailMultiAlternatives",
        "importPath": "django.core.mail",
        "description": "django.core.mail",
        "isExtraImport": true,
        "detail": "django.core.mail",
        "documentation": {}
    },
    {
        "label": "send_mail",
        "importPath": "django.core.mail",
        "description": "django.core.mail",
        "isExtraImport": true,
        "detail": "django.core.mail",
        "documentation": {}
    },
    {
        "label": "generate_image",
        "importPath": "edictai_app.app.generateImage",
        "description": "edictai_app.app.generateImage",
        "isExtraImport": true,
        "detail": "edictai_app.app.generateImage",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "seo_description",
        "description": "seo_description",
        "isExtraImport": true,
        "detail": "seo_description",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "selenium.webdriver.chrome.options",
        "description": "selenium.webdriver.chrome.options",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.options",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "urllib.request",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request",
        "description": "urllib.request",
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "cloudinary",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cloudinary",
        "description": "cloudinary",
        "detail": "cloudinary",
        "documentation": {}
    },
    {
        "label": "cloudinary.uploader",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cloudinary.uploader",
        "description": "cloudinary.uploader",
        "detail": "cloudinary.uploader",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "django.db.models.deletion",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "django.db.models.deletion",
        "description": "django.db.models.deletion",
        "detail": "django.db.models.deletion",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "settings",
        "importPath": "django.conf",
        "description": "django.conf",
        "isExtraImport": true,
        "detail": "django.conf",
        "documentation": {}
    },
    {
        "label": "static",
        "importPath": "django.conf.urls.static",
        "description": "django.conf.urls.static",
        "isExtraImport": true,
        "detail": "django.conf.urls.static",
        "documentation": {}
    },
    {
        "label": "csrf_exempt",
        "importPath": "django.views.decorators.csrf",
        "description": "django.views.decorators.csrf",
        "isExtraImport": true,
        "detail": "django.views.decorators.csrf",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "HttpResponse",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "redirect",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "data",
        "importPath": "edictai_app.app.audio_test.ssml_1",
        "description": "edictai_app.app.audio_test.ssml_1",
        "isExtraImport": true,
        "detail": "edictai_app.app.audio_test.ssml_1",
        "documentation": {}
    },
    {
        "label": "ContentFile",
        "importPath": "django.core.files.base",
        "description": "django.core.files.base",
        "isExtraImport": true,
        "detail": "django.core.files.base",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "EdictAI.asgi",
        "description": "EdictAI.asgi",
        "peekOfCode": "application = get_asgi_application()",
        "detail": "EdictAI.asgi",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "BASE_DIR = Path(__file__).resolve().parent.parent\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = 'django-insecure-8lwlf+i#da0ve#z2@=!ov2c4k7@tofm%lgl==(=&_o_9^%_7pj'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "SECRET_KEY",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "SECRET_KEY = 'django-insecure-8lwlf+i#da0ve#z2@=!ov2c4k7@tofm%lgl==(=&_o_9^%_7pj'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "DEBUG = True\nALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "ALLOWED_HOSTS",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "ALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'edictai_app',",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "INSTALLED_APPS",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "INSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'edictai_app',\n    'corsheaders',\n]",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "MIDDLEWARE",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "MIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'corsheaders.middleware.CorsMiddleware',\n]",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "ROOT_URLCONF",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "ROOT_URLCONF = 'EdictAI.urls'\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': ['templates'],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "TEMPLATES",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "TEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': ['templates'],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "WSGI_APPLICATION",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "WSGI_APPLICATION = 'EdictAI.wsgi.application'\n# Database\n# https://docs.djangoproject.com/en/4.2/ref/settings/#databases\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR / 'db.sqlite3',\n    }\n}\n# Password validation",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "DATABASES",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR / 'db.sqlite3',\n    }\n}\n# Password validation\n# https://docs.djangoproject.com/en/4.2/ref/settings/#auth-password-validators\nAUTH_PASSWORD_VALIDATORS = [\n    {",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "AUTH_PASSWORD_VALIDATORS",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "AUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_CODE",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "LANGUAGE_CODE = 'en-us'\nTIME_ZONE = 'UTC'\nUSE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "TIME_ZONE = 'UTC'\nUSE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nimport os",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "USE_I18N",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "USE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nimport os\n#Added manually",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "USE_TZ",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "USE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nimport os\n#Added manually\nMEDIA_URL = '/media/'",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "STATIC_URL",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "STATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nimport os\n#Added manually\nMEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, 'media')\nEMAIL_HOST='smtp.gmail.com'\nEMAIL_PORT=587",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "DEFAULT_AUTO_FIELD",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nimport os\n#Added manually\nMEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, 'media')\nEMAIL_HOST='smtp.gmail.com'\nEMAIL_PORT=587\nEMAIL_HOST_USER='forsih01@gmail.com'\nEMAIL_HOST_PASSWORD='pnyf ylhp dcqu dfft'\nEMAIL_USE_TLS= True",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "MEDIA_URL",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "MEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, 'media')\nEMAIL_HOST='smtp.gmail.com'\nEMAIL_PORT=587\nEMAIL_HOST_USER='forsih01@gmail.com'\nEMAIL_HOST_PASSWORD='pnyf ylhp dcqu dfft'\nEMAIL_USE_TLS= True\nCORS_ALLOWED_ORIGINS = [\n    \"http://127.0.0.1:3000\",\n    \"http://localhost:3000\"",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "MEDIA_ROOT",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "MEDIA_ROOT = os.path.join(BASE_DIR, 'media')\nEMAIL_HOST='smtp.gmail.com'\nEMAIL_PORT=587\nEMAIL_HOST_USER='forsih01@gmail.com'\nEMAIL_HOST_PASSWORD='pnyf ylhp dcqu dfft'\nEMAIL_USE_TLS= True\nCORS_ALLOWED_ORIGINS = [\n    \"http://127.0.0.1:3000\",\n    \"http://localhost:3000\"\n]",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "CORS_ALLOWED_ORIGINS",
        "kind": 5,
        "importPath": "EdictAI.settings",
        "description": "EdictAI.settings",
        "peekOfCode": "CORS_ALLOWED_ORIGINS = [\n    \"http://127.0.0.1:3000\",\n    \"http://localhost:3000\"\n]",
        "detail": "EdictAI.settings",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "EdictAI.urls",
        "description": "EdictAI.urls",
        "peekOfCode": "urlpatterns = [\n    path('admin/', admin.site.urls),\n    path('',include(\"edictai_app.urls\")),\n]",
        "detail": "EdictAI.urls",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "EdictAI.wsgi",
        "description": "EdictAI.wsgi",
        "peekOfCode": "application = get_wsgi_application()",
        "detail": "EdictAI.wsgi",
        "documentation": {}
    },
    {
        "label": "audiostack.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.audiostack_1",
        "description": "edictai_app.app.audio_test.audiostack_1",
        "peekOfCode": "audiostack.api_key = \"\"\nscript = audiostack.Content.Script.create(\n  scriptText='''\n  A function was organised in the Central Hall today to commemorate the rich legacy of the Parliament of India as the Members\n  came together to bid adieu to the historical building before stepping into the New Building of Parliament.\n  In his address to MPs in the Central Hall, the Vice-President described this transition as a journey from 'Tryst with Destiny\n  to 'Tryst with Modernity' and called upon all Members to join the historic journey towards Bharat @2047.\n  The Vice-President noted that the hallowed precincts of the Parliament building have witnessed many milestones in its seven\n  decade long journey which continue to resonate with the aspirations of over a billion hearts.\n  '''",
        "detail": "edictai_app.app.audio_test.audiostack_1",
        "documentation": {}
    },
    {
        "label": "script",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.audiostack_1",
        "description": "edictai_app.app.audio_test.audiostack_1",
        "peekOfCode": "script = audiostack.Content.Script.create(\n  scriptText='''\n  A function was organised in the Central Hall today to commemorate the rich legacy of the Parliament of India as the Members\n  came together to bid adieu to the historical building before stepping into the New Building of Parliament.\n  In his address to MPs in the Central Hall, the Vice-President described this transition as a journey from 'Tryst with Destiny\n  to 'Tryst with Modernity' and called upon all Members to join the historic journey towards Bharat @2047.\n  The Vice-President noted that the hallowed precincts of the Parliament building have witnessed many milestones in its seven\n  decade long journey which continue to resonate with the aspirations of over a billion hearts.\n  '''\n)",
        "detail": "edictai_app.app.audio_test.audiostack_1",
        "documentation": {}
    },
    {
        "label": "scriptId",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.audiostack_1",
        "description": "edictai_app.app.audio_test.audiostack_1",
        "peekOfCode": "scriptId = script.scriptId\nprint(scriptId)\nfor v in [\"sara\", \"liam\", \"prabhat\", \"priyanka\"]:\n    item = audiostack.Speech.TTS.create(scriptItem=script, voice=v)\n    print(item.response)\n# We'll get our files with the list method\ntts_files = audiostack.Speech.TTS.list(scriptId=scriptId)\nprint(tts_files.response)\nfor tts in tts_files:\n    print(\"getting\", tts.speechId)",
        "detail": "edictai_app.app.audio_test.audiostack_1",
        "documentation": {}
    },
    {
        "label": "tts_files",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.audiostack_1",
        "description": "edictai_app.app.audio_test.audiostack_1",
        "peekOfCode": "tts_files = audiostack.Speech.TTS.list(scriptId=scriptId)\nprint(tts_files.response)\nfor tts in tts_files:\n    print(\"getting\", tts.speechId)\n    item = audiostack.Speech.TTS.get(tts.speechId)\n\t\t#We'll download each file\n    item.download(fileName=item.speechId)\n#We'll list the rendered files\ntts_files = audiostack.Speech.TTS.list(scriptId=scriptId)\nprint(tts_files.response)",
        "detail": "edictai_app.app.audio_test.audiostack_1",
        "documentation": {}
    },
    {
        "label": "tts_files",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.audiostack_1",
        "description": "edictai_app.app.audio_test.audiostack_1",
        "peekOfCode": "tts_files = audiostack.Speech.TTS.list(scriptId=scriptId)\nprint(tts_files.response)\nfor tts in tts_files:\n    # At this point we can delete the files (not needed anymore)\n    item = audiostack.Speech.TTS.get(tts.speechId)\n    r = item.delete()\n    print(r)\nprint(\"Cost for this session: \", audiostack.credits_used_in_this_session())\n# Response\nResponse from creating script {'data': {'projectName': 'untitled', 'moduleName': 'untitled', 'scriptName': 'untitled', 'scriptId': '3c548655-25d4-4f98-b9c2-fd51456ee26b', 'scriptText': '<as:section name=\"default\">A function was organised in the Central Hall today to commemorate the rich legacy of the Parliament of India as the Members  came together to bid adieu to the historical building before stepping into the New Building of Parliament.  In his address to MPs in the Central Hall, the Vice-President described this transition as a journey from \\'Tryst with Destiny  to \\'Tryst with Modernity\\' and called upon all Members to join the historic journey towards Bharat @2047.  The Vice-President noted that the hallowed precincts of the Parliament building have witnessed many milestones in its seven  decade long journey which continue to resonate with the aspirations of over a billion hearts.  </as:section>', 'metadata': '{}', 'creationDate': '2023-09-19T21:00:22.896684', 'lang': 'en', 'sections': [{'name': 'default', 'soundSegment': '', 'contentType': 'tts', 'content': \"A function was organised in the Central Hall today to commemorate the rich legacy of the Parliament of India as the Members  came together to bid adieu to the historical building before stepping into the New Building of Parliament.  In his address to MPs in the Central Hall, the Vice-President described this transition as a journey from 'Tryst with Destiny  to 'Tryst with Modernity' and called upon all Members to join the historic journey towards Bharat @2047.  The Vice-President noted that the hallowed precincts of the Parliament building have witnessed many milestones in its seven  decade long journey which continue to resonate with the aspirations of over a billion hearts.\", 'placeholders': {}, 'parent': '', 'subSections': [], 'uuid': 'e3472b40-fb90-4077-94e8-67caff57833f'}]}, 'meta': {'version': '2.0.0', 'requestId': '02c53d42-d55a-46eb-b805-26972ccb7298', 'creditsUsed': 0.1, 'creditsRemaining': 250.0}, 'message': 'Script created', 'warnings': [], 'statusCode': 200}",
        "detail": "edictai_app.app.audio_test.audiostack_1",
        "documentation": {}
    },
    {
        "label": "audiostack.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.audiostack_2",
        "description": "edictai_app.app.audio_test.audiostack_2",
        "peekOfCode": "audiostack.api_key = \"\"\n# # We'll get our files with the list method\n# tts_files = audiostack.Speech.TTS.list(scriptId=scriptId)\n# print(tts_files.response)\n# for tts in tts_files:\n#     print(\"getting\", tts.speechId)\n    # item = audiostack.Speech.TTS.get(tts.speechId)\n\t# \t#We'll download each file\n    # item.download(fileName=item.speechId)\n# item = audiostack.Speech.TTS.get(\"f1fe10aa-5f78-4f0a-bfeb-3b3868a1aff2\")",
        "detail": "edictai_app.app.audio_test.audiostack_2",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_1",
        "description": "edictai_app.app.audio_test.azure_tts_1",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"\")\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n# The language of the voice that speaks.\nspeech_config.speech_synthesis_voice_name='en-US-JennyNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Get text from the console and synthesize to the default speaker.\n# print(\"Enter some text that you want to speak >\")\n# text = input()\ntext = '''\n        By working together, the Ministry of Health and Family Welfare, the Ministry of Housing and Urban Affairs and National /State teams can create a synergy which will lead to more sustainable, healthy and safe urban environment for urban population.",
        "detail": "edictai_app.app.audio_test.azure_tts_1",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_1",
        "description": "edictai_app.app.audio_test.azure_tts_1",
        "peekOfCode": "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n# The language of the voice that speaks.\nspeech_config.speech_synthesis_voice_name='en-US-JennyNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Get text from the console and synthesize to the default speaker.\n# print(\"Enter some text that you want to speak >\")\n# text = input()\ntext = '''\n        By working together, the Ministry of Health and Family Welfare, the Ministry of Housing and Urban Affairs and National /State teams can create a synergy which will lead to more sustainable, healthy and safe urban environment for urban population.\n        '''",
        "detail": "edictai_app.app.audio_test.azure_tts_1",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_1",
        "description": "edictai_app.app.audio_test.azure_tts_1",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Get text from the console and synthesize to the default speaker.\n# print(\"Enter some text that you want to speak >\")\n# text = input()\ntext = '''\n        By working together, the Ministry of Health and Family Welfare, the Ministry of Housing and Urban Affairs and National /State teams can create a synergy which will lead to more sustainable, healthy and safe urban environment for urban population.\n        '''\nspeech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"audios/basic_audio_1.wav\")",
        "detail": "edictai_app.app.audio_test.azure_tts_1",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_1",
        "description": "edictai_app.app.audio_test.azure_tts_1",
        "peekOfCode": "text = '''\n        By working together, the Ministry of Health and Family Welfare, the Ministry of Housing and Urban Affairs and National /State teams can create a synergy which will lead to more sustainable, healthy and safe urban environment for urban population.\n        '''\nspeech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"audios/basic_audio_1.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(text))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details",
        "detail": "edictai_app.app.audio_test.azure_tts_1",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_result",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_1",
        "description": "edictai_app.app.audio_test.azure_tts_1",
        "peekOfCode": "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"audios/basic_audio_1.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(text))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:",
        "detail": "edictai_app.app.audio_test.azure_tts_1",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_stream",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_1",
        "description": "edictai_app.app.audio_test.azure_tts_1",
        "peekOfCode": "speech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"audios/basic_audio_1.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(text))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:\n            print(\"Error details: {}\".format(cancellation_details.error_details))",
        "detail": "edictai_app.app.audio_test.azure_tts_1",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_bookmark_reached_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "def speech_synthesizer_bookmark_reached_cb(evt: speechsdk.SessionEventArgs):\n    print('BookmarkReached event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tText: {}'.format(evt.text))\ndef speech_synthesizer_synthesis_canceled_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCanceled event')\ndef speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_canceled_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "def speech_synthesizer_synthesis_canceled_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCanceled event')\ndef speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))\ndef speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_completed_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "def speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))\ndef speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_started_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "def speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesizing_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "def speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_viseme_received_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "def speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tDuration: {}'.format(evt.duration))\n    print('\\tText: {}'.format(evt.text))",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_word_boundary_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "def speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tDuration: {}'.format(evt.duration))\n    print('\\tText: {}'.format(evt.text))\n    print('\\tTextOffset: {}'.format(evt.text_offset))\n    print('\\tWordLength: {}'.format(evt.word_length))\n# This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\nspeech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"\")",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"\")\n# Required for WordBoundary event sentences.\nspeech_config.set_property(property_id=speechsdk.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, value='true')\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)\nspeech_synthesizer.synthesizing.connect(speech_synthesizer_synthesizing_cb)\nspeech_synthesizer.viseme_received.connect(speech_synthesizer_viseme_received_cb)\nspeech_synthesizer.synthesis_word_boundary.connect(speech_synthesizer_word_boundary_cb)",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)\nspeech_synthesizer.synthesizing.connect(speech_synthesizer_synthesizing_cb)\nspeech_synthesizer.viseme_received.connect(speech_synthesizer_viseme_received_cb)\nspeech_synthesizer.synthesis_word_boundary.connect(speech_synthesizer_word_boundary_cb)\n# The language of the voice that speaks.",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "ssml",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "ssml = '''\n<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-IN\">\n  <voice name=\"{}\">\n    <prosody rate=\"+12%\" pitch=\"medium\" contour=\"(0%,+10%) (50%,+20%) (100%,+10%)\" volume=\"medium\">\n      Breaking news! The Prime Minister, Shri Narendra Modi <break time=\"200ms\"/> congratulated Muhammed Ajmal, Vithya Ramraj, Rajesh Ramesh and Venkatesan Subha for winning a silver medal in the 4x400m Mixed Relay event at the Asian Games. <break time=\"300ms\"/> \n      <emphasis level=\"strong\">What a splendid Silver for our Athletes in the 4x400m Mixed Relay event at the Asian Games!</emphasis> <break time=\"300ms\"/> \n      <emphasis level=\"moderate\">Congratulations on this spectacular win to Muhammed Ajmal, Vithya Ramraj, Rajesh Ramesh and Venkatesan Subha!</emphasis> <break time=\"300ms\"/> \n      <emphasis level=\"moderate\">Their teamwork was outstanding.</emphasis>\n    </prosody>\n  </voice>",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_result",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"audios/audio_7.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"SynthesizingAudioCompleted result\")\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_stream",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_2",
        "description": "edictai_app.app.audio_test.azure_tts_2",
        "peekOfCode": "speech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"audios/audio_7.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"SynthesizingAudioCompleted result\")\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:\n            print(\"Error details: {}\".format(cancellation_details.error_details))",
        "detail": "edictai_app.app.audio_test.azure_tts_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_bookmark_reached_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def speech_synthesizer_bookmark_reached_cb(evt: speechsdk.SessionEventArgs):\n    print('BookmarkReached event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tText: {}'.format(evt.text))\ndef speech_synthesizer_synthesis_canceled_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCanceled event')\ndef speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_canceled_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def speech_synthesizer_synthesis_canceled_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCanceled event')\ndef speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))\ndef speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_completed_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))\ndef speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_started_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesizing_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_viseme_received_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tDuration: {}'.format(evt.duration))\n    print('\\tText: {}'.format(evt.text))",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_word_boundary_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tDuration: {}'.format(evt.duration))\n    print('\\tText: {}'.format(evt.text))\n    print('\\tTextOffset: {}'.format(evt.text_offset))\n    print('\\tWordLength: {}'.format(evt.word_length))\n# This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\nspeech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"\")",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "viseme_cb",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "def viseme_cb(evt):\n    print(\"Viseme event received: audio offset: {}ms, viseme id: {}.\".format(\n        evt.audio_offset / 10000, evt.viseme_id))\n    animation = evt.animation\n    print(animation)\n    print('\\n')\nspeech_synthesizer.viseme_received.connect(viseme_cb)\n# If VisemeID is the only thing you want, you can also use `speak_text_async()`\nresult = speech_synthesizer.speak_ssml_async(ssml).get()\nprint(result)",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"\")\n# speech_config = speechsdk.SpeechConfig(subscription=\"9dfa789ee50047d7944ad4c9d277e8f3\", region=\"eastus\")\n# Required for WordBoundary event sentences.\nspeech_config.set_property(property_id=speechsdk.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, value='true')\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)\nspeech_synthesizer.synthesizing.connect(speech_synthesizer_synthesizing_cb)\nspeech_synthesizer.viseme_received.connect(speech_synthesizer_viseme_received_cb)\nspeech_synthesizer.synthesis_word_boundary.connect(speech_synthesizer_word_boundary_cb)",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)\nspeech_synthesizer.synthesizing.connect(speech_synthesizer_synthesizing_cb)\nspeech_synthesizer.viseme_received.connect(speech_synthesizer_viseme_received_cb)\nspeech_synthesizer.synthesis_word_boundary.connect(speech_synthesizer_word_boundary_cb)\n# The language of the voice that speaks.",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "ssml",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "ssml = \"\"\"\n<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xml:lang=\"en-US\">\n  <voice name=\"en-US-JennyNeural\">\n    <mstts:viseme type=\"redlips_front\"/>\n    Rainbow has seven colors: Red, orange, yellow, green, blue, indigo, and violet.\n  </voice>\n</speak>\n\"\"\".format(speech_synthesis_voice_name)\n# Synthesize the SSML\n# print(\"SSML to synthesize: \\r\\n{}\".format(ssml))",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\ndef viseme_cb(evt):\n    print(\"Viseme event received: audio offset: {}ms, viseme id: {}.\".format(\n        evt.audio_offset / 10000, evt.viseme_id))\n    animation = evt.animation\n    print(animation)\n    print('\\n')\nspeech_synthesizer.viseme_received.connect(viseme_cb)\n# If VisemeID is the only thing you want, you can also use `speak_text_async()`\nresult = speech_synthesizer.speak_ssml_async(ssml).get()",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.azure_tts_3",
        "description": "edictai_app.app.audio_test.azure_tts_3",
        "peekOfCode": "result = speech_synthesizer.speak_ssml_async(ssml).get()\nprint(result)",
        "detail": "edictai_app.app.audio_test.azure_tts_3",
        "documentation": {}
    },
    {
        "label": "speech_recognize_once_from_mic",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_once_from_mic():\n    \"\"\"performs one-shot speech recognition from the default microphone\"\"\"\n    # <SpeechRecognitionWithMicrophone>\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # Creates a speech recognizer using microphone as audio input.\n    # The default language is \"en-us\".\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n    # single utterance is determined by listening for silence at the end or until a maximum of 15\n    # seconds of audio is processed. It returns the recognition text as result.",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_once_from_file",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_once_from_file():\n    \"\"\"performs one-shot speech recognition with input from an audio file\"\"\"\n    # <SpeechRecognitionWithFile>\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n    # Creates a speech recognizer using a file as audio input, also specify the speech language\n    speech_recognizer = speechsdk.SpeechRecognizer(\n        speech_config=speech_config, language=\"de-DE\", audio_config=audio_config)\n    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n    # single utterance is determined by listening for silence at the end or until a maximum of 15",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_once_from_file_with_detailed_recognition_results",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_once_from_file_with_detailed_recognition_results():\n    \"\"\"performs one-shot speech recognition with input from an audio file, showing detailed recognition results\n    including word-level timing \"\"\"\n    # <SpeechRecognitionFromFileWithDetailedRecognitionResults>\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # Ask for detailed recognition result\n    speech_config.output_format = speechsdk.OutputFormat.Detailed\n    # If you also want word-level timing in the detailed recognition results, set the following.\n    # Note that if you set the following, you can omit the previous line\n    #   \"speech_config.output_format = speechsdk.OutputFormat.Detailed\",",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_once_compressed_input",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_once_compressed_input():\n    \"\"\"performs one-shot speech recognition with compressed input from an audio file\"\"\"\n    # <SpeechRecognitionWithCompressedFile>\n    class BinaryFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n        def __init__(self, filename: str):\n            super().__init__()\n            self._file_h = open(filename, \"rb\")\n        def read(self, buffer: memoryview) -> int:\n            try:\n                size = buffer.nbytes",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_once_from_file_with_customized_model",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_once_from_file_with_customized_model():\n    \"\"\"performs one-shot speech recognition with input from an audio file, specifying a custom\n    model\"\"\"\n    # <SpeechRecognitionUsingCustomizedModel>\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # Create source language configuration with the speech language and the endpoint ID of your customized model\n    # Replace with your speech language and CRIS endpoint ID.\n    source_language_config = speechsdk.languageconfig.SourceLanguageConfig(\"zh-CN\", \"YourEndpointId\")\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n    # Creates a speech recognizer using a file as audio input and specify the source language config",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_once_from_file_with_custom_endpoint_parameters",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_once_from_file_with_custom_endpoint_parameters():\n    \"\"\"performs one-shot speech recognition with input from an audio file, specifying an\n    endpoint with custom parameters\"\"\"\n    initial_silence_timeout_ms = 15 * 1e3\n    template = \"wss://{}.stt.speech.microsoft.com/speech/recognition\" \\\n        \"/conversation/cognitiveservices/v1?initialSilenceTimeoutMs={:d}\"\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key,\n                                           endpoint=template.format(service_region, int(initial_silence_timeout_ms)))\n    print(\"Using endpoint\", speech_config.get_property(speechsdk.PropertyId.SpeechServiceConnection_Endpoint))\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_async_from_file",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_async_from_file():\n    \"\"\"performs one-shot speech recognition asynchronously with input from an audio file\"\"\"\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n    # Creates a speech recognizer using a file as audio input.\n    # The default language is \"en-us\".\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n    # Perform recognition. `recognize_async` does not block until recognition is complete,\n    # so other tasks can be performed while recognition is running.\n    # However, recognition stops when the first utterance has been recognized.",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_continuous_from_file",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_continuous_from_file():\n    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n    # <SpeechContinuousRecognitionWithFile>\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n    done = False\n    def stop_cb(evt: speechsdk.SessionEventArgs):\n        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n        print('CLOSING on {}'.format(evt))",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_continuous_async_from_microphone",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_continuous_async_from_microphone():\n    \"\"\"performs continuous speech recognition asynchronously with input from microphone\"\"\"\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # The default language is \"en-us\".\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n    done = False\n    def recognizing_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n        print('RECOGNIZING: {}'.format(evt))\n    def recognized_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n        print('RECOGNIZED: {}'.format(evt))",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_keyword_from_microphone",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_keyword_from_microphone():\n    \"\"\"performs keyword-triggered speech recognition with input microphone\"\"\"\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # Creates an instance of a keyword recognition model. Update this to\n    # point to the location of your keyword recognition model.\n    model = speechsdk.KeywordRecognitionModel(\"YourKeywordRecognitionModelFile.table\")\n    # The phrase your keyword recognition model triggers on.\n    keyword = \"YourKeyword\"\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n    done = False",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognition_with_pull_stream",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognition_with_pull_stream():\n    \"\"\"gives an example how to use a pull audio stream to recognize speech from a custom audio\n    source\"\"\"\n    class WavFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n        \"\"\"Example class that implements the Pull Audio Stream interface to recognize speech from\n        an audio file\"\"\"\n        def __init__(self, filename: str):\n            super().__init__()\n            self._file_h = wave.open(filename, mode=None)\n            self.sample_width = self._file_h.getsampwidth()",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "push_stream_writer",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def push_stream_writer(stream):\n    # The number of bytes to push per buffer\n    n_bytes = 3200\n    wav_fh = wave.open(weatherfilename)\n    # start pushing data until all data has been read from the file\n    try:\n        while True:\n            frames = wav_fh.readframes(n_bytes // 2)\n            print('read {} bytes'.format(len(frames)))\n            if not frames:",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognition_with_push_stream",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognition_with_push_stream():\n    \"\"\"gives an example how to use a push audio stream to recognize speech from a custom audio\n    source\"\"\"\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # setup the audio stream\n    stream = speechsdk.audio.PushAudioInputStream()\n    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n    # instantiate the speech recognizer with push stream input\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n    recognition_done = threading.Event()",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_once_with_auto_language_detection_from_mic",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_once_with_auto_language_detection_from_mic():\n    \"\"\"performs one-shot speech recognition from the default microphone with auto language detection\"\"\"\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # create the auto detection language configuration with the potential source language candidates\n    auto_detect_source_language_config = \\\n        speechsdk.languageconfig.AutoDetectSourceLanguageConfig(languages=[\"de-DE\", \"en-US\"])\n    speech_recognizer = speechsdk.SpeechRecognizer(\n        speech_config=speech_config, auto_detect_source_language_config=auto_detect_source_language_config)\n    result = speech_recognizer.recognize_once()\n    # Check the result",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_with_auto_language_detection_UsingCustomizedModel",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_with_auto_language_detection_UsingCustomizedModel():\n    \"\"\"performs speech recognition from the audio file with auto language detection, using customized model\"\"\"\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n    # Replace the languages with your languages in BCP-47 format, e.g. fr-FR.\n    # Please see https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support\n    # for all supported languages\n    en_language_config = speechsdk.languageconfig.SourceLanguageConfig(\"en-US\")\n    # Replace the languages with your languages in BCP-47 format, e.g. zh-CN.\n    # Set the endpoint ID of your customized mode that will be used for fr-FR.",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "speech_recognize_keyword_locally_from_microphone",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def speech_recognize_keyword_locally_from_microphone():\n    \"\"\"runs keyword spotting locally, with direct access to the result audio\"\"\"\n    # Creates an instance of a keyword recognition model. Update this to\n    # point to the location of your keyword recognition model.\n    model = speechsdk.KeywordRecognitionModel(\"YourKeywordRecognitionModelFile.table\")\n    # The phrase your keyword recognition model triggers on.\n    keyword = \"YourKeyword\"\n    # Create a local keyword recognizer with the default microphone device for input.\n    keyword_recognizer = speechsdk.KeywordRecognizer()\n    done = False",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "pronunciation_assessment_from_microphone",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def pronunciation_assessment_from_microphone():\n    \"\"\"Performs one-shot pronunciation assessment asynchronously with input from microphone.\n        See more information at https://aka.ms/csspeech/pa\"\"\"\n    # Creates an instance of a speech config with specified subscription key and service region.\n    # Replace with your own subscription key and service region (e.g., \"westus\").\n    config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # The pronunciation assessment service has a longer default end silence timeout (5 seconds) than normal STT\n    # as the pronunciation assessment is widely used in education scenario where kids have longer break in reading.\n    # You can adjust the end silence timeout based on your real scenario.\n    config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, \"3000\")",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "pronunciation_assessment_continuous_from_file",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def pronunciation_assessment_continuous_from_file():\n    \"\"\"Performs continuous pronunciation assessment asynchronously with input from an audio file.\n        See more information at https://aka.ms/csspeech/pa\"\"\"\n    import difflib\n    import json\n    # Creates an instance of a speech config with specified subscription key and service region.\n    # Replace with your own subscription key and service region (e.g., \"westus\").\n    # Note: The sample is for en-US language.\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "pronunciation_assessment_from_stream",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def pronunciation_assessment_from_stream():\n    \"\"\"Performs pronunciation assessment asynchronously with input from an audio stream.\n        See more information at https://aka.ms/csspeech/pa\"\"\"\n    # Creates an instance of a speech config with specified subscription key and service region.\n    # Replace with your own subscription key and service region (e.g., \"westus\").\n    # Note: The sample is for en-US language.\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # setup the audio stream\n    stream = speechsdk.audio.PushAudioInputStream()\n    audio_config = speechsdk.audio.AudioConfig(stream=stream)",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "pronunciation_assessment_configured_with_json",
        "kind": 2,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "def pronunciation_assessment_configured_with_json():\n    \"\"\"Performs pronunciation assessment asynchronously with input from an audio file.\n        See more information at https://aka.ms/csspeech/pa\"\"\"\n    # Creates an instance of a speech config with specified subscription key and service region.\n    # Replace with your own subscription key and service region (e.g., \"westus\").\n    # Note: The sample is for en-US language.\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n    reference_text = \"What's the weather like?\"\n    # create pronunciation assessment config, set grading system, granularity and if enable miscue based on your requirement.",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "weatherfilename",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "weatherfilename = \"audio3_1_of_1.wav\"\nweatherfilenamemp3 = \"whatstheweatherlike.mp3\"\ndef speech_recognize_once_from_mic():\n    \"\"\"performs one-shot speech recognition from the default microphone\"\"\"\n    # <SpeechRecognitionWithMicrophone>\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # Creates a speech recognizer using microphone as audio input.\n    # The default language is \"en-us\".\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n    # Starts speech recognition, and returns after a single utterance is recognized. The end of a",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "weatherfilenamemp3",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.pronunciation",
        "description": "edictai_app.app.audio_test.pronunciation",
        "peekOfCode": "weatherfilenamemp3 = \"whatstheweatherlike.mp3\"\ndef speech_recognize_once_from_mic():\n    \"\"\"performs one-shot speech recognition from the default microphone\"\"\"\n    # <SpeechRecognitionWithMicrophone>\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n    # Creates a speech recognizer using microphone as audio input.\n    # The default language is \"en-us\".\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n    # single utterance is determined by listening for silence at the end or until a maximum of 15",
        "detail": "edictai_app.app.audio_test.pronunciation",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.ssml_1",
        "description": "edictai_app.app.audio_test.ssml_1",
        "peekOfCode": "headers = {\n    'x-api-key': 'sec_wCTcXMskYQQsoBTahoAj9a2rBHwfXCG3',\n    \"Content-Type\": \"application/json\",\n}\nprompt = '''\n        '''\ndata = {\n    'sourceId': \"src_cha_6SeIkVuTSeKaSDZhF7lkJ\",\n    'messages': [\n        {",
        "detail": "edictai_app.app.audio_test.ssml_1",
        "documentation": {}
    },
    {
        "label": "prompt",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.ssml_1",
        "description": "edictai_app.app.audio_test.ssml_1",
        "peekOfCode": "prompt = '''\n        '''\ndata = {\n    'sourceId': \"src_cha_6SeIkVuTSeKaSDZhF7lkJ\",\n    'messages': [\n        {\n            'role': \"user\",\n            'content': f\"{prompt}\",\n        }\n    ]",
        "detail": "edictai_app.app.audio_test.ssml_1",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.ssml_1",
        "description": "edictai_app.app.audio_test.ssml_1",
        "peekOfCode": "data = {\n    'sourceId': \"src_cha_6SeIkVuTSeKaSDZhF7lkJ\",\n    'messages': [\n        {\n            'role': \"user\",\n            'content': f\"{prompt}\",\n        }\n    ]\n}\nresponse = requests.post(",
        "detail": "edictai_app.app.audio_test.ssml_1",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.ssml_1",
        "description": "edictai_app.app.audio_test.ssml_1",
        "peekOfCode": "response = requests.post(\n    'https://api.chatpdf.com/v1/chats/message', headers=headers, json=data)\nif response.status_code == 200:\n    print('Result:', response.json()['content'])\nelse:\n    print('Status:', response.status_code)\n    print('Error:', response.text)\n# Prompt 1\n# Generate SSML for the following text to produce natural intonation, expressions, and audio cues according to the provided documentation:\n# Text: ''' The Prime Minister, Shri Narendra Modi congratulated Muhammed Ajmal, Vithya Ramraj, Rajesh Ramesh and Venkatesan Subha for winning silver medal in  4x400m Mixed Relay event at the Asian Games. The Prime Minister posted on X : \"What a splendid Silver for our Athletes in the 4x400m Mixed Relay event at the Asian Games. Congratulations on this spectacular win to Muhammed Ajmal, Vithya Ramraj, Rajesh Ramesh and Venkatesan Subha! Their teamwork was outstanding.\" '''",
        "detail": "edictai_app.app.audio_test.ssml_1",
        "documentation": {}
    },
    {
        "label": "orig_text",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.tts_odia",
        "description": "edictai_app.app.audio_test.tts_odia",
        "peekOfCode": "orig_text = \"ప్రధాన మంత్రి శ్రీ నరేంద్ర మోదీ 2023 అక్టోబరు 1 వ తేదీ నాడు తెలంగాణ ను సందర్శించనున్నారు. మధ్యాహ్నం పూట దాదాపు గా 2 గంటల 15 నిమిషాల కు, ప్రధాన మంత్రి మహబూబ్ నగర్ జిల్లా కు చేరుకొంటారు. అక్కడ ఆయన రహదారులు, రైలు మార్గాలు, పెట్రోలియమ్, సహజ వాయువు మరియు ఉన్నత విద్య ల వంటి ముఖ్య రంగాల లో 13,500 కోట్ల రూపాయల కు పైగా విలువ కలిగిన అనేక అభివృద్ధి ప్రాజెక్టుల కు శంకుస్థాపన చేయడం తో పాటుగా వాటిని దేశ ప్రజల కు అంకితం కూడా చేస్తారు. కార్యక్రమం లో ప్రధాన మంత్రి వీడియో కాన్ఫరెన్సింగ్ మాధ్యం ద్వారా ఒక రైలు సర్వీసు కు కూడా ప్రారంభ సూచక ఆకుపచ్చటి జెండా ను చూపి ఆ రైలు ప్రయాణాన్ని మొదలుపెట్టడాన్ని తిలకిస్తారు.\"\nroman_text = transliterate.process('autodetect', 'ISO', orig_text)\nprint(roman_text)\naudio = model.apply_tts(roman_text,\n                        speaker='hindi_male')",
        "detail": "edictai_app.app.audio_test.tts_odia",
        "documentation": {}
    },
    {
        "label": "roman_text",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.tts_odia",
        "description": "edictai_app.app.audio_test.tts_odia",
        "peekOfCode": "roman_text = transliterate.process('autodetect', 'ISO', orig_text)\nprint(roman_text)\naudio = model.apply_tts(roman_text,\n                        speaker='hindi_male')",
        "detail": "edictai_app.app.audio_test.tts_odia",
        "documentation": {}
    },
    {
        "label": "audio",
        "kind": 5,
        "importPath": "edictai_app.app.audio_test.tts_odia",
        "description": "edictai_app.app.audio_test.tts_odia",
        "peekOfCode": "audio = model.apply_tts(roman_text,\n                        speaker='hindi_male')",
        "detail": "edictai_app.app.audio_test.tts_odia",
        "documentation": {}
    },
    {
        "label": "r",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.generate_1",
        "description": "edictai_app.app.image_generation.generate_1",
        "peekOfCode": "r = requests.post('https://clipdrop-api.co/text-to-image/v1',\n  files = {\n      'prompt': (None, 'Narendra Modi', 'text/plain')\n  },\n  headers = { 'x-api-key': ''}\n)\nif (r.ok):\n    file_path = 'images/image.jpg'\n    try:\n        with open(file_path, 'wb') as file:",
        "detail": "edictai_app.app.image_generation.generate_1",
        "documentation": {}
    },
    {
        "label": "engine_id",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.generate_2",
        "description": "edictai_app.app.image_generation.generate_2",
        "peekOfCode": "engine_id = \"stable-diffusion-xl-1024-v1-0\"\napi_host = os.getenv('API_HOST', 'https://api.stability.ai')\napi_key = \"\"\nif api_key is None:\n    raise Exception(\"Missing Stability API key.\")\ntext = \"icon of clock\"\nresponse = requests.post(\n    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n    headers={\n        \"Content-Type\": \"application/json\",",
        "detail": "edictai_app.app.image_generation.generate_2",
        "documentation": {}
    },
    {
        "label": "api_host",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.generate_2",
        "description": "edictai_app.app.image_generation.generate_2",
        "peekOfCode": "api_host = os.getenv('API_HOST', 'https://api.stability.ai')\napi_key = \"\"\nif api_key is None:\n    raise Exception(\"Missing Stability API key.\")\ntext = \"icon of clock\"\nresponse = requests.post(\n    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n    headers={\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"application/json\",",
        "detail": "edictai_app.app.image_generation.generate_2",
        "documentation": {}
    },
    {
        "label": "api_key",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.generate_2",
        "description": "edictai_app.app.image_generation.generate_2",
        "peekOfCode": "api_key = \"\"\nif api_key is None:\n    raise Exception(\"Missing Stability API key.\")\ntext = \"icon of clock\"\nresponse = requests.post(\n    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n    headers={\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {api_key}\"",
        "detail": "edictai_app.app.image_generation.generate_2",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.generate_2",
        "description": "edictai_app.app.image_generation.generate_2",
        "peekOfCode": "text = \"icon of clock\"\nresponse = requests.post(\n    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n    headers={\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {api_key}\"\n    },\n    json={\n        \"text_prompts\": [",
        "detail": "edictai_app.app.image_generation.generate_2",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.generate_2",
        "description": "edictai_app.app.image_generation.generate_2",
        "peekOfCode": "response = requests.post(\n    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n    headers={\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {api_key}\"\n    },\n    json={\n        \"text_prompts\": [\n            {",
        "detail": "edictai_app.app.image_generation.generate_2",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.generate_2",
        "description": "edictai_app.app.image_generation.generate_2",
        "peekOfCode": "data = response.json()\nfor i, image in enumerate(data[\"artifacts\"]):\n    with open(f\"chunk_{i}.png\", \"wb\") as f:\n        f.write(base64.b64decode(image[\"base64\"]))",
        "detail": "edictai_app.app.image_generation.generate_2",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai",
        "description": "edictai_app.app.image_generation.openai",
        "peekOfCode": "openai.organization = \"\"\nopenai.api_key = \"\"\n# print(openai.Model.list())\nresponse = openai.Image.create(\n  prompt=\"clock icon\",\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\nprint(image_url)",
        "detail": "edictai_app.app.image_generation.openai",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai",
        "description": "edictai_app.app.image_generation.openai",
        "peekOfCode": "openai.api_key = \"\"\n# print(openai.Model.list())\nresponse = openai.Image.create(\n  prompt=\"clock icon\",\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\nprint(image_url)",
        "detail": "edictai_app.app.image_generation.openai",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai",
        "description": "edictai_app.app.image_generation.openai",
        "peekOfCode": "response = openai.Image.create(\n  prompt=\"clock icon\",\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\nprint(image_url)",
        "detail": "edictai_app.app.image_generation.openai",
        "documentation": {}
    },
    {
        "label": "image_url",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai",
        "description": "edictai_app.app.image_generation.openai",
        "peekOfCode": "image_url = response['data'][0]['url']\nprint(image_url)",
        "detail": "edictai_app.app.image_generation.openai",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai2",
        "description": "edictai_app.app.image_generation.openai2",
        "peekOfCode": "openai.organization = \"\"\nopenai.api_key = \"\"\n# Create the image using OpenAI API\nresponse = openai.Image.create(\n    prompt=\"kitten\",\n    n=1,\n    size=\"1024x1024\"\n)\n# Get the image URL from the response\nimage_url = response['data'][0]['url']",
        "detail": "edictai_app.app.image_generation.openai2",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai2",
        "description": "edictai_app.app.image_generation.openai2",
        "peekOfCode": "openai.api_key = \"\"\n# Create the image using OpenAI API\nresponse = openai.Image.create(\n    prompt=\"kitten\",\n    n=1,\n    size=\"1024x1024\"\n)\n# Get the image URL from the response\nimage_url = response['data'][0]['url']\n# Define the filename for the downloaded image",
        "detail": "edictai_app.app.image_generation.openai2",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai2",
        "description": "edictai_app.app.image_generation.openai2",
        "peekOfCode": "response = openai.Image.create(\n    prompt=\"kitten\",\n    n=1,\n    size=\"1024x1024\"\n)\n# Get the image URL from the response\nimage_url = response['data'][0]['url']\n# Define the filename for the downloaded image\nimage_filename = \"chunk.png\"\n# Download the image and save it with the desired filename",
        "detail": "edictai_app.app.image_generation.openai2",
        "documentation": {}
    },
    {
        "label": "image_url",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai2",
        "description": "edictai_app.app.image_generation.openai2",
        "peekOfCode": "image_url = response['data'][0]['url']\n# Define the filename for the downloaded image\nimage_filename = \"chunk.png\"\n# Download the image and save it with the desired filename\nresponse = requests.get(image_url)\nif response.status_code == 200:\n    with open(image_filename, 'wb') as f:\n        f.write(response.content)\n    print(f\"Image downloaded and saved as {image_filename}\")\nelse:",
        "detail": "edictai_app.app.image_generation.openai2",
        "documentation": {}
    },
    {
        "label": "image_filename",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai2",
        "description": "edictai_app.app.image_generation.openai2",
        "peekOfCode": "image_filename = \"chunk.png\"\n# Download the image and save it with the desired filename\nresponse = requests.get(image_url)\nif response.status_code == 200:\n    with open(image_filename, 'wb') as f:\n        f.write(response.content)\n    print(f\"Image downloaded and saved as {image_filename}\")\nelse:\n    print(\"Failed to download the image\")\n# Now the image is saved as \"chunk.png\" in your current working directory",
        "detail": "edictai_app.app.image_generation.openai2",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.openai2",
        "description": "edictai_app.app.image_generation.openai2",
        "peekOfCode": "response = requests.get(image_url)\nif response.status_code == 200:\n    with open(image_filename, 'wb') as f:\n        f.write(response.content)\n    print(f\"Image downloaded and saved as {image_filename}\")\nelse:\n    print(\"Failed to download the image\")\n# Now the image is saved as \"chunk.png\" in your current working directory",
        "detail": "edictai_app.app.image_generation.openai2",
        "documentation": {}
    },
    {
        "label": "generate_script",
        "kind": 2,
        "importPath": "edictai_app.app.image_generation.script_1",
        "description": "edictai_app.app.image_generation.script_1",
        "peekOfCode": "def generate_script(news):\n    # Prompt 1 for Creative Script Generation\n    prompt = f\"\"\"Imagine yourself as a charismatic news anchor, ready to captivate your audience with an engaging YouTube video script. Craft a script based on the following news: \"{news}\".\nBegin with a warm greeting and smoothly transition into highlighting the most significant and impactful points from the news article. Ensure that the script maintains an authentic and unbiased tone. Conclude the script by hinting at potential future developments, all within a video length of 30-90 seconds.\nRemember, your goal is to inform, inspire, and engage your viewers. Avoid any harmful, unethical, or inappropriate content. Make it captivating and creative while staying true to the news story.\nPlease break the script into meaningful chunks, each containing about 10-12 words, and separate them using <\\n>. \"\"\"\n    # Generate the creative script\n    completion = palm.generate_text(    \n        model=model,\n        prompt=prompt,",
        "detail": "edictai_app.app.image_generation.script_1",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.script_1",
        "description": "edictai_app.app.image_generation.script_1",
        "peekOfCode": "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\nmodel = models[0].name\ndef generate_script(news):\n    # Prompt 1 for Creative Script Generation\n    prompt = f\"\"\"Imagine yourself as a charismatic news anchor, ready to captivate your audience with an engaging YouTube video script. Craft a script based on the following news: \"{news}\".\nBegin with a warm greeting and smoothly transition into highlighting the most significant and impactful points from the news article. Ensure that the script maintains an authentic and unbiased tone. Conclude the script by hinting at potential future developments, all within a video length of 30-90 seconds.\nRemember, your goal is to inform, inspire, and engage your viewers. Avoid any harmful, unethical, or inappropriate content. Make it captivating and creative while staying true to the news story.\nPlease break the script into meaningful chunks, each containing about 10-12 words, and separate them using <\\n>. \"\"\"\n    # Generate the creative script\n    completion = palm.generate_text(    ",
        "detail": "edictai_app.app.image_generation.script_1",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.script_1",
        "description": "edictai_app.app.image_generation.script_1",
        "peekOfCode": "model = models[0].name\ndef generate_script(news):\n    # Prompt 1 for Creative Script Generation\n    prompt = f\"\"\"Imagine yourself as a charismatic news anchor, ready to captivate your audience with an engaging YouTube video script. Craft a script based on the following news: \"{news}\".\nBegin with a warm greeting and smoothly transition into highlighting the most significant and impactful points from the news article. Ensure that the script maintains an authentic and unbiased tone. Conclude the script by hinting at potential future developments, all within a video length of 30-90 seconds.\nRemember, your goal is to inform, inspire, and engage your viewers. Avoid any harmful, unethical, or inappropriate content. Make it captivating and creative while staying true to the news story.\nPlease break the script into meaningful chunks, each containing about 10-12 words, and separate them using <\\n>. \"\"\"\n    # Generate the creative script\n    completion = palm.generate_text(    \n        model=model,",
        "detail": "edictai_app.app.image_generation.script_1",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "edictai_app.app.image_generation.script_1",
        "description": "edictai_app.app.image_generation.script_1",
        "peekOfCode": "text = ''' \nThe Prime Minister, Shri Narendra Modi interacted with Team G20 at Bharat Mandapam today. The Prime Minister also addressed the gathering on the occasion.\nSpeaking on the occasion, the Prime Minister underlined the accolades that are being showered for the successful organization of G20 and credited the ground level functionaries for this success.\n'''\nprint(generate_script(text))",
        "detail": "edictai_app.app.image_generation.script_1",
        "documentation": {}
    },
    {
        "label": "video_file",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "video_file = 'videos/video_1.mp4'\ncap = cv2.VideoCapture(video_file)\nimage_file = 'cat.jpg'\nimage = cv2.imread(image_file)\nhorizontal_position = 'center'  # 'left', 'center', or 'right'\nvertical_position = 'bottom'   # 'top', 'center', or 'bottom'\nhorizontal_padding = 50\nvertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "cap",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "cap = cv2.VideoCapture(video_file)\nimage_file = 'cat.jpg'\nimage = cv2.imread(image_file)\nhorizontal_position = 'center'  # 'left', 'center', or 'right'\nvertical_position = 'bottom'   # 'top', 'center', or 'bottom'\nhorizontal_padding = 50\nvertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "image_file",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "image_file = 'cat.jpg'\nimage = cv2.imread(image_file)\nhorizontal_position = 'center'  # 'left', 'center', or 'right'\nvertical_position = 'bottom'   # 'top', 'center', or 'bottom'\nhorizontal_padding = 50\nvertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "image",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "image = cv2.imread(image_file)\nhorizontal_position = 'center'  # 'left', 'center', or 'right'\nvertical_position = 'bottom'   # 'top', 'center', or 'bottom'\nhorizontal_padding = 50\nvertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "horizontal_position",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "horizontal_position = 'center'  # 'left', 'center', or 'right'\nvertical_position = 'bottom'   # 'top', 'center', or 'bottom'\nhorizontal_padding = 50\nvertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "vertical_position",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "vertical_position = 'bottom'   # 'top', 'center', or 'bottom'\nhorizontal_padding = 50\nvertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "horizontal_padding",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "horizontal_padding = 50\nvertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10\nfade_in_duration = 1",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "vertical_padding",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "vertical_padding = 50\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10\nfade_in_duration = 1\nfade_out_duration = 1",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "frame_width",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "frame_width = int(cap.get(3))\nframe_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10\nfade_in_duration = 1\nfade_out_duration = 1\nwhile True:",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "frame_height",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "frame_height = int(cap.get(4))\noutput_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10\nfade_in_duration = 1\nfade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "output_file",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "output_file = 'output_video.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10\nfade_in_duration = 1\nfade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()\n    if not ret:",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "fourcc",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10\nfade_in_duration = 1\nfade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "out",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "out = cv2.VideoWriter(output_file, fourcc, 30.0, (frame_width, frame_height))\nstart_time = 5\nend_time = 10\nfade_in_duration = 1\nfade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "start_time",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "start_time = 5\nend_time = 10\nfade_in_duration = 1\nfade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n    if start_time <= current_time <= end_time:",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "end_time",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "end_time = 10\nfade_in_duration = 1\nfade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n    if start_time <= current_time <= end_time:\n        image_height, image_width, _ = image.shape",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "fade_in_duration",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "fade_in_duration = 1\nfade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n    if start_time <= current_time <= end_time:\n        image_height, image_width, _ = image.shape\n        if horizontal_position == 'left':",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "fade_out_duration",
        "kind": 5,
        "importPath": "edictai_app.app.image_on_video.video_edit",
        "description": "edictai_app.app.image_on_video.video_edit",
        "peekOfCode": "fade_out_duration = 1\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n    if start_time <= current_time <= end_time:\n        image_height, image_width, _ = image.shape\n        if horizontal_position == 'left':\n            x = horizontal_padding",
        "detail": "edictai_app.app.image_on_video.video_edit",
        "documentation": {}
    },
    {
        "label": "add_image_to_video",
        "kind": 2,
        "importPath": "edictai_app.app.image_on_video.video_edit_2",
        "description": "edictai_app.app.image_on_video.video_edit_2",
        "peekOfCode": "def add_image_to_video(input_video_path, output_video_path, image_path, horizontal_position, vertical_position, in_time, out_time, in_transition_duration=1, out_transition_duration=1):\n    cap = cv2.VideoCapture(input_video_path)\n    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Load the image with transparency\n    frame_width = int(cap.get(3))\n    frame_height = int(cap.get(4))\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (frame_width, frame_height))\n    while True:\n        ret, frame = cap.read()\n        if not ret:",
        "detail": "edictai_app.app.image_on_video.video_edit_2",
        "documentation": {}
    },
    {
        "label": "add_image_to_video",
        "kind": 2,
        "importPath": "edictai_app.app.image_on_video.video_edit_3",
        "description": "edictai_app.app.image_on_video.video_edit_3",
        "peekOfCode": "def add_image_to_video(input_video_path, output_video_path, image_path, horizontal_position, vertical_position, in_time, out_time, in_transition_duration=1, out_transition_duration=1):\n    video_clip = VideoFileClip(input_video_path)\n    image_clip = ImageClip(image_path, transparent=True)\n    image_height = image_clip.h\n    image_width = image_clip.w\n    if horizontal_position == 'left':\n        x = 20\n    elif horizontal_position == 'center':\n        x = (video_clip.w - image_width) // 2\n    elif horizontal_position == 'right':",
        "detail": "edictai_app.app.image_on_video.video_edit_3",
        "documentation": {}
    },
    {
        "label": "subscription_key",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_1",
        "description": "edictai_app.app.image_search.bing.bing_search_1",
        "peekOfCode": "subscription_key = \"\"\nsearch_url = \"https://api.bing.microsoft.com/v7.0/images/search\"\nsearch_term = query\nheaders = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nif \"value\" in search_results and len(search_results[\"value\"]) > 0:\n    image_url = search_results[\"value\"][0][\"contentUrl\"]",
        "detail": "edictai_app.app.image_search.bing.bing_search_1",
        "documentation": {}
    },
    {
        "label": "search_url",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_1",
        "description": "edictai_app.app.image_search.bing.bing_search_1",
        "peekOfCode": "search_url = \"https://api.bing.microsoft.com/v7.0/images/search\"\nsearch_term = query\nheaders = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nif \"value\" in search_results and len(search_results[\"value\"]) > 0:\n    image_url = search_results[\"value\"][0][\"contentUrl\"]\n    image_data = requests.get(image_url)",
        "detail": "edictai_app.app.image_search.bing.bing_search_1",
        "documentation": {}
    },
    {
        "label": "search_term",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_1",
        "description": "edictai_app.app.image_search.bing.bing_search_1",
        "peekOfCode": "search_term = query\nheaders = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nif \"value\" in search_results and len(search_results[\"value\"]) > 0:\n    image_url = search_results[\"value\"][0][\"contentUrl\"]\n    image_data = requests.get(image_url)\n    image_data.raise_for_status()",
        "detail": "edictai_app.app.image_search.bing.bing_search_1",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_1",
        "description": "edictai_app.app.image_search.bing.bing_search_1",
        "peekOfCode": "headers = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nif \"value\" in search_results and len(search_results[\"value\"]) > 0:\n    image_url = search_results[\"value\"][0][\"contentUrl\"]\n    image_data = requests.get(image_url)\n    image_data.raise_for_status()\n    save_path = \"team_work_2.jpg\"",
        "detail": "edictai_app.app.image_search.bing.bing_search_1",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_1",
        "description": "edictai_app.app.image_search.bing.bing_search_1",
        "peekOfCode": "response = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nif \"value\" in search_results and len(search_results[\"value\"]) > 0:\n    image_url = search_results[\"value\"][0][\"contentUrl\"]\n    image_data = requests.get(image_url)\n    image_data.raise_for_status()\n    save_path = \"team_work_2.jpg\"\n    with open(save_path, \"wb\") as image_file:\n        image_file.write(image_data.content)",
        "detail": "edictai_app.app.image_search.bing.bing_search_1",
        "documentation": {}
    },
    {
        "label": "search_results",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_1",
        "description": "edictai_app.app.image_search.bing.bing_search_1",
        "peekOfCode": "search_results = response.json()\nif \"value\" in search_results and len(search_results[\"value\"]) > 0:\n    image_url = search_results[\"value\"][0][\"contentUrl\"]\n    image_data = requests.get(image_url)\n    image_data.raise_for_status()\n    save_path = \"team_work_2.jpg\"\n    with open(save_path, \"wb\") as image_file:\n        image_file.write(image_data.content)\n    print(f\"Image saved as {save_path}\")\nelse:",
        "detail": "edictai_app.app.image_search.bing.bing_search_1",
        "documentation": {}
    },
    {
        "label": "subscription_key",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_2",
        "description": "edictai_app.app.image_search.bing.bing_search_2",
        "peekOfCode": "subscription_key = \"\"\nsearch_url = \"https://api.bing.microsoft.com/v7.0/images/search\"\nsearch_term = \"puppies\"\nheaders = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nthumbnail_urls = [img[\"thumbnailUrl\"] for img in search_results[\"value\"][:16]]\nf, axes = plt.subplots(4, 4)",
        "detail": "edictai_app.app.image_search.bing.bing_search_2",
        "documentation": {}
    },
    {
        "label": "search_url",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_2",
        "description": "edictai_app.app.image_search.bing.bing_search_2",
        "peekOfCode": "search_url = \"https://api.bing.microsoft.com/v7.0/images/search\"\nsearch_term = \"puppies\"\nheaders = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nthumbnail_urls = [img[\"thumbnailUrl\"] for img in search_results[\"value\"][:16]]\nf, axes = plt.subplots(4, 4)\nfor i in range(4):",
        "detail": "edictai_app.app.image_search.bing.bing_search_2",
        "documentation": {}
    },
    {
        "label": "search_term",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_2",
        "description": "edictai_app.app.image_search.bing.bing_search_2",
        "peekOfCode": "search_term = \"puppies\"\nheaders = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nthumbnail_urls = [img[\"thumbnailUrl\"] for img in search_results[\"value\"][:16]]\nf, axes = plt.subplots(4, 4)\nfor i in range(4):\n    for j in range(4):",
        "detail": "edictai_app.app.image_search.bing.bing_search_2",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_2",
        "description": "edictai_app.app.image_search.bing.bing_search_2",
        "peekOfCode": "headers = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\nparams  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\"}\nresponse = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nthumbnail_urls = [img[\"thumbnailUrl\"] for img in search_results[\"value\"][:16]]\nf, axes = plt.subplots(4, 4)\nfor i in range(4):\n    for j in range(4):\n        image_data = requests.get(thumbnail_urls[i+4*j])",
        "detail": "edictai_app.app.image_search.bing.bing_search_2",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_2",
        "description": "edictai_app.app.image_search.bing.bing_search_2",
        "peekOfCode": "response = requests.get(search_url, headers=headers, params=params)\nresponse.raise_for_status()\nsearch_results = response.json()\nthumbnail_urls = [img[\"thumbnailUrl\"] for img in search_results[\"value\"][:16]]\nf, axes = plt.subplots(4, 4)\nfor i in range(4):\n    for j in range(4):\n        image_data = requests.get(thumbnail_urls[i+4*j])\n        image_data.raise_for_status()\n        image = Image.open(BytesIO(image_data.content))        ",
        "detail": "edictai_app.app.image_search.bing.bing_search_2",
        "documentation": {}
    },
    {
        "label": "search_results",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_2",
        "description": "edictai_app.app.image_search.bing.bing_search_2",
        "peekOfCode": "search_results = response.json()\nthumbnail_urls = [img[\"thumbnailUrl\"] for img in search_results[\"value\"][:16]]\nf, axes = plt.subplots(4, 4)\nfor i in range(4):\n    for j in range(4):\n        image_data = requests.get(thumbnail_urls[i+4*j])\n        image_data.raise_for_status()\n        image = Image.open(BytesIO(image_data.content))        \n        axes[i][j].imshow(image)\n        axes[i][j].axis(\"off\")",
        "detail": "edictai_app.app.image_search.bing.bing_search_2",
        "documentation": {}
    },
    {
        "label": "thumbnail_urls",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_2",
        "description": "edictai_app.app.image_search.bing.bing_search_2",
        "peekOfCode": "thumbnail_urls = [img[\"thumbnailUrl\"] for img in search_results[\"value\"][:16]]\nf, axes = plt.subplots(4, 4)\nfor i in range(4):\n    for j in range(4):\n        image_data = requests.get(thumbnail_urls[i+4*j])\n        image_data.raise_for_status()\n        image = Image.open(BytesIO(image_data.content))        \n        axes[i][j].imshow(image)\n        axes[i][j].axis(\"off\")\nplt.show()",
        "detail": "edictai_app.app.image_search.bing.bing_search_2",
        "documentation": {}
    },
    {
        "label": "subscription_key",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_3",
        "description": "edictai_app.app.image_search.bing.bing_search_3",
        "peekOfCode": "subscription_key = \"\"\nsubscription_endpoint = \"https://api.bing.microsoft.com/\"\nsearch_term = \"team\"\nclient = ImageSearchClient(endpoint=subscription_endpoint, credentials=CognitiveServicesCredentials(subscription_key))\nimage_results = client.images.search(query=search_term)\nif image_results.value:\n    first_image_result = image_results.value[0]\n    print(\"Total number of images returned: {}\".format(len(image_results.value)))\n    print(\"First image thumbnail url: {}\".format(\n        first_image_result.thumbnail_url))",
        "detail": "edictai_app.app.image_search.bing.bing_search_3",
        "documentation": {}
    },
    {
        "label": "subscription_endpoint",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_3",
        "description": "edictai_app.app.image_search.bing.bing_search_3",
        "peekOfCode": "subscription_endpoint = \"https://api.bing.microsoft.com/\"\nsearch_term = \"team\"\nclient = ImageSearchClient(endpoint=subscription_endpoint, credentials=CognitiveServicesCredentials(subscription_key))\nimage_results = client.images.search(query=search_term)\nif image_results.value:\n    first_image_result = image_results.value[0]\n    print(\"Total number of images returned: {}\".format(len(image_results.value)))\n    print(\"First image thumbnail url: {}\".format(\n        first_image_result.thumbnail_url))\n    print(\"First image content url: {}\".format(first_image_result.content_url))",
        "detail": "edictai_app.app.image_search.bing.bing_search_3",
        "documentation": {}
    },
    {
        "label": "search_term",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_3",
        "description": "edictai_app.app.image_search.bing.bing_search_3",
        "peekOfCode": "search_term = \"team\"\nclient = ImageSearchClient(endpoint=subscription_endpoint, credentials=CognitiveServicesCredentials(subscription_key))\nimage_results = client.images.search(query=search_term)\nif image_results.value:\n    first_image_result = image_results.value[0]\n    print(\"Total number of images returned: {}\".format(len(image_results.value)))\n    print(\"First image thumbnail url: {}\".format(\n        first_image_result.thumbnail_url))\n    print(\"First image content url: {}\".format(first_image_result.content_url))\nelse:",
        "detail": "edictai_app.app.image_search.bing.bing_search_3",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_3",
        "description": "edictai_app.app.image_search.bing.bing_search_3",
        "peekOfCode": "client = ImageSearchClient(endpoint=subscription_endpoint, credentials=CognitiveServicesCredentials(subscription_key))\nimage_results = client.images.search(query=search_term)\nif image_results.value:\n    first_image_result = image_results.value[0]\n    print(\"Total number of images returned: {}\".format(len(image_results.value)))\n    print(\"First image thumbnail url: {}\".format(\n        first_image_result.thumbnail_url))\n    print(\"First image content url: {}\".format(first_image_result.content_url))\nelse:\n    print(\"No image results returned!\")",
        "detail": "edictai_app.app.image_search.bing.bing_search_3",
        "documentation": {}
    },
    {
        "label": "image_results",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_3",
        "description": "edictai_app.app.image_search.bing.bing_search_3",
        "peekOfCode": "image_results = client.images.search(query=search_term)\nif image_results.value:\n    first_image_result = image_results.value[0]\n    print(\"Total number of images returned: {}\".format(len(image_results.value)))\n    print(\"First image thumbnail url: {}\".format(\n        first_image_result.thumbnail_url))\n    print(\"First image content url: {}\".format(first_image_result.content_url))\nelse:\n    print(\"No image results returned!\")",
        "detail": "edictai_app.app.image_search.bing.bing_search_3",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.bing_search_query",
        "description": "edictai_app.app.image_search.bing.bing_search_query",
        "peekOfCode": "query = \"cute kitten\"",
        "detail": "edictai_app.app.image_search.bing.bing_search_query",
        "documentation": {}
    },
    {
        "label": "subscription_key",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.video_search",
        "description": "edictai_app.app.image_search.bing.video_search",
        "peekOfCode": "subscription_key = \"\"\nendpoint = \"https://api.bing.microsoft.com/v7.0/videos/search\"\nclient = VideoSearchClient(endpoint, CognitiveServicesCredentials(subscription_key))\nvideo_result = client.videos.search(query=\"kittens\")\nif video_result.value:\n    first_video_result = video_result.value[0]\n    print(\"Video result count: {}\".format(len(video_result.value)))\n    print(\"First video id: {}\".format(first_video_result.video_id))\n    print(\"First video name: {}\".format(first_video_result.name))\n    print(\"First video url: {}\".format(first_video_result.content_url))",
        "detail": "edictai_app.app.image_search.bing.video_search",
        "documentation": {}
    },
    {
        "label": "endpoint",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.video_search",
        "description": "edictai_app.app.image_search.bing.video_search",
        "peekOfCode": "endpoint = \"https://api.bing.microsoft.com/v7.0/videos/search\"\nclient = VideoSearchClient(endpoint, CognitiveServicesCredentials(subscription_key))\nvideo_result = client.videos.search(query=\"kittens\")\nif video_result.value:\n    first_video_result = video_result.value[0]\n    print(\"Video result count: {}\".format(len(video_result.value)))\n    print(\"First video id: {}\".format(first_video_result.video_id))\n    print(\"First video name: {}\".format(first_video_result.name))\n    print(\"First video url: {}\".format(first_video_result.content_url))\nelse:",
        "detail": "edictai_app.app.image_search.bing.video_search",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.video_search",
        "description": "edictai_app.app.image_search.bing.video_search",
        "peekOfCode": "client = VideoSearchClient(endpoint, CognitiveServicesCredentials(subscription_key))\nvideo_result = client.videos.search(query=\"kittens\")\nif video_result.value:\n    first_video_result = video_result.value[0]\n    print(\"Video result count: {}\".format(len(video_result.value)))\n    print(\"First video id: {}\".format(first_video_result.video_id))\n    print(\"First video name: {}\".format(first_video_result.name))\n    print(\"First video url: {}\".format(first_video_result.content_url))\nelse:\n    print(\"Didn't see any video result data..\")",
        "detail": "edictai_app.app.image_search.bing.video_search",
        "documentation": {}
    },
    {
        "label": "video_result",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.bing.video_search",
        "description": "edictai_app.app.image_search.bing.video_search",
        "peekOfCode": "video_result = client.videos.search(query=\"kittens\")\nif video_result.value:\n    first_video_result = video_result.value[0]\n    print(\"Video result count: {}\".format(len(video_result.value)))\n    print(\"First video id: {}\".format(first_video_result.video_id))\n    print(\"First video name: {}\".format(first_video_result.name))\n    print(\"First video url: {}\".format(first_video_result.content_url))\nelse:\n    print(\"Didn't see any video result data..\")",
        "detail": "edictai_app.app.image_search.bing.video_search",
        "documentation": {}
    },
    {
        "label": "key",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.flaticons.icon_search",
        "description": "edictai_app.app.image_search.flaticons.icon_search",
        "peekOfCode": "key = \"\"\nimport requests\nurl = 'https://api.flaticon.com/v3/search/icons/{orderBy}'\nheaders = {\n    'Accept': 'application/json',\n    'Authorization': 'string'\n}\nparams = {'q': 'string'}\nresponse = requests.get(url, params=params, headers=headers)\nif response.status_code == 200:",
        "detail": "edictai_app.app.image_search.flaticons.icon_search",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.flaticons.icon_search",
        "description": "edictai_app.app.image_search.flaticons.icon_search",
        "peekOfCode": "url = 'https://api.flaticon.com/v3/search/icons/{orderBy}'\nheaders = {\n    'Accept': 'application/json',\n    'Authorization': 'string'\n}\nparams = {'q': 'string'}\nresponse = requests.get(url, params=params, headers=headers)\nif response.status_code == 200:\n    data = response.json()\n    print(data)",
        "detail": "edictai_app.app.image_search.flaticons.icon_search",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.flaticons.icon_search",
        "description": "edictai_app.app.image_search.flaticons.icon_search",
        "peekOfCode": "headers = {\n    'Accept': 'application/json',\n    'Authorization': 'string'\n}\nparams = {'q': 'string'}\nresponse = requests.get(url, params=params, headers=headers)\nif response.status_code == 200:\n    data = response.json()\n    print(data)\nelse:",
        "detail": "edictai_app.app.image_search.flaticons.icon_search",
        "documentation": {}
    },
    {
        "label": "params",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.flaticons.icon_search",
        "description": "edictai_app.app.image_search.flaticons.icon_search",
        "peekOfCode": "params = {'q': 'string'}\nresponse = requests.get(url, params=params, headers=headers)\nif response.status_code == 200:\n    data = response.json()\n    print(data)\nelse:\n    print(f\"Request failed with status code {response.status_code}\")",
        "detail": "edictai_app.app.image_search.flaticons.icon_search",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.flaticons.icon_search",
        "description": "edictai_app.app.image_search.flaticons.icon_search",
        "peekOfCode": "response = requests.get(url, params=params, headers=headers)\nif response.status_code == 200:\n    data = response.json()\n    print(data)\nelse:\n    print(f\"Request failed with status code {response.status_code}\")",
        "detail": "edictai_app.app.image_search.flaticons.icon_search",
        "documentation": {}
    },
    {
        "label": "google_image_search_api",
        "kind": 2,
        "importPath": "edictai_app.app.image_search.google.image_search",
        "description": "edictai_app.app.image_search.google.image_search",
        "peekOfCode": "def google_image_search_api(query,chunk_number):\n    if(\"gender equality\" in query):\n        query = \"balanced scale of gender equality\"\n    gis = GoogleImagesSearch('', '')\n    _search_params = {\n        'q': query,\n        'num': 1,\n        'fileType': 'jpg|png|jpeg',\n        'rights': 'cc_publicdomain|cc_attribute|cc_sharealike|cc_noncommercial|cc_nonderived',\n        'safe': 'off', ##",
        "detail": "edictai_app.app.image_search.google.image_search",
        "documentation": {}
    },
    {
        "label": "rename_images",
        "kind": 2,
        "importPath": "edictai_app.app.image_search.google.image_search",
        "description": "edictai_app.app.image_search.google.image_search",
        "peekOfCode": "def rename_images():\n    # Path to the folder containing the image files\n    folder_path = \"images\"\n    # Get a list of all image files in the folder\n    image_files = [f for f in os.listdir(folder_path) if f.endswith(\".jpg\")]\n    # Loop through each image file and rename it\n    for i, old_name in enumerate(image_files):\n        new_name = f\"coindesk_multiple_{i}.jpg\"\n        old_path = os.path.join(folder_path, old_name)\n        new_path = os.path.join(folder_path, new_name)",
        "detail": "edictai_app.app.image_search.google.image_search",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.google.image_search",
        "description": "edictai_app.app.image_search.google.image_search",
        "peekOfCode": "query = \"Nature\"\ngoogle_image_search_api(query,1)",
        "detail": "edictai_app.app.image_search.google.image_search",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.images_pexels",
        "description": "edictai_app.app.image_search.pexels.images_pexels",
        "peekOfCode": "API_KEY = ''\nquery = 'Nature'\nbase_url = 'https://api.pexels.com/v1/'\nheaders = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}",
        "detail": "edictai_app.app.image_search.pexels.images_pexels",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.images_pexels",
        "description": "edictai_app.app.image_search.pexels.images_pexels",
        "peekOfCode": "query = 'Nature'\nbase_url = 'https://api.pexels.com/v1/'\nheaders = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)",
        "detail": "edictai_app.app.image_search.pexels.images_pexels",
        "documentation": {}
    },
    {
        "label": "base_url",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.images_pexels",
        "description": "edictai_app.app.image_search.pexels.images_pexels",
        "peekOfCode": "base_url = 'https://api.pexels.com/v1/'\nheaders = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:",
        "detail": "edictai_app.app.image_search.pexels.images_pexels",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.images_pexels",
        "description": "edictai_app.app.image_search.pexels.images_pexels",
        "peekOfCode": "headers = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:\n    data = response.json()",
        "detail": "edictai_app.app.image_search.pexels.images_pexels",
        "documentation": {}
    },
    {
        "label": "params",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.images_pexels",
        "description": "edictai_app.app.image_search.pexels.images_pexels",
        "peekOfCode": "params = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:\n    data = response.json()\n    photos = data.get('photos', [])\n    if photos:\n        if not os.path.exists('images'):",
        "detail": "edictai_app.app.image_search.pexels.images_pexels",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.images_pexels",
        "description": "edictai_app.app.image_search.pexels.images_pexels",
        "peekOfCode": "response = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:\n    data = response.json()\n    photos = data.get('photos', [])\n    if photos:\n        if not os.path.exists('images'):\n            os.makedirs('images')\n        for i, photo in enumerate(photos, 1):\n            original_url = photo['src']['original']\n            file_extension = original_url.split('.')[-1]",
        "detail": "edictai_app.app.image_search.pexels.images_pexels",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.videos_pexels",
        "description": "edictai_app.app.image_search.pexels.videos_pexels",
        "peekOfCode": "API_KEY = ''\nquery = 'Nature'\nbase_url = 'https://api.pexels.com/videos/'\nheaders = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}",
        "detail": "edictai_app.app.image_search.pexels.videos_pexels",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.videos_pexels",
        "description": "edictai_app.app.image_search.pexels.videos_pexels",
        "peekOfCode": "query = 'Nature'\nbase_url = 'https://api.pexels.com/videos/'\nheaders = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)",
        "detail": "edictai_app.app.image_search.pexels.videos_pexels",
        "documentation": {}
    },
    {
        "label": "base_url",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.videos_pexels",
        "description": "edictai_app.app.image_search.pexels.videos_pexels",
        "peekOfCode": "base_url = 'https://api.pexels.com/videos/'\nheaders = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:",
        "detail": "edictai_app.app.image_search.pexels.videos_pexels",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.videos_pexels",
        "description": "edictai_app.app.image_search.pexels.videos_pexels",
        "peekOfCode": "headers = {\n    'Authorization': API_KEY,\n}\nparams = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:\n    data = response.json()",
        "detail": "edictai_app.app.image_search.pexels.videos_pexels",
        "documentation": {}
    },
    {
        "label": "params",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.videos_pexels",
        "description": "edictai_app.app.image_search.pexels.videos_pexels",
        "peekOfCode": "params = {\n    'query': query,\n    'per_page': 5,\n}\nresponse = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:\n    data = response.json()\n    videos = data.get('videos', [])\n    if videos:\n        if not os.path.exists('videos'):",
        "detail": "edictai_app.app.image_search.pexels.videos_pexels",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.image_search.pexels.videos_pexels",
        "description": "edictai_app.app.image_search.pexels.videos_pexels",
        "peekOfCode": "response = requests.get(base_url + 'search', headers=headers, params=params)\nif response.status_code == 200:\n    data = response.json()\n    videos = data.get('videos', [])\n    if videos:\n        if not os.path.exists('videos'):\n            os.makedirs('videos')\n        for i, video in enumerate(videos, 1):\n            video_url = video['video_files'][0]['link']\n            file_extension = os.path.splitext(urlparse(video_url).path)[-1]",
        "detail": "edictai_app.app.image_search.pexels.videos_pexels",
        "documentation": {}
    },
    {
        "label": "edict_video",
        "kind": 2,
        "importPath": "edictai_app.app.potrait_video_1.new_final",
        "description": "edictai_app.app.potrait_video_1.new_final",
        "peekOfCode": "def edict_video(url):\n    # Web Scraping\n    data = url_select(url)\n    print(data)\n    # News Authentication \n    # Put here \n    chunks = []\n    # Text Summarization and Chunking\n    if(url_identify(url)==\"single\"):\n        content = data[\"content\"]",
        "detail": "edictai_app.app.potrait_video_1.new_final",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.scripting.script_1",
        "description": "edictai_app.app.scripting.script_1",
        "peekOfCode": "openai.organization = \"\"\nopenai.api_key = \"\"\n# print(openai.Model.list())\nnews = '''\nNLC India Ltd secures 810 MW Grid Connected Solar Photovoltaic Power Project in Rajasthan\nPosted On: 09 OCT 2023 12:34PM by PIB Delhi\nNLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).\nNLCIL has successfully garnered the entire capacity of the 810 MW tender floated by RRVUNL in December 2022, for developing the project RRVUNL’s 2000 MW Ultra Mega Solar Park at Pugal Tehsil, Bikaner District, Rajasthan. The Letter of Intent for this project has been issued by RRVUNL. This achievement marks a significant step forward in NLCIL's commitment to clean and sustainable energy solutions.\nThe land for the project and the power evacuation system connected to STU will be offered by RVUNL, paving the way for completion of the project at shorter period. This is the largest Renewable project to be developed by the company. With this project, the capacity of power project in   Rajasthan will be 1.36 GW including 1.1 GW of green power, bringing economies of scale and optimized fixed costs.\nConsidering the good Solar radiation at Rajasthan, the higher CUF for the project is possible and will generate green power of more than 50 Billion Units and offsets more than 50,000 tonnes of carbon dioxide emissions during the life of the project.",
        "detail": "edictai_app.app.scripting.script_1",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.scripting.script_1",
        "description": "edictai_app.app.scripting.script_1",
        "peekOfCode": "openai.api_key = \"\"\n# print(openai.Model.list())\nnews = '''\nNLC India Ltd secures 810 MW Grid Connected Solar Photovoltaic Power Project in Rajasthan\nPosted On: 09 OCT 2023 12:34PM by PIB Delhi\nNLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).\nNLCIL has successfully garnered the entire capacity of the 810 MW tender floated by RRVUNL in December 2022, for developing the project RRVUNL’s 2000 MW Ultra Mega Solar Park at Pugal Tehsil, Bikaner District, Rajasthan. The Letter of Intent for this project has been issued by RRVUNL. This achievement marks a significant step forward in NLCIL's commitment to clean and sustainable energy solutions.\nThe land for the project and the power evacuation system connected to STU will be offered by RVUNL, paving the way for completion of the project at shorter period. This is the largest Renewable project to be developed by the company. With this project, the capacity of power project in   Rajasthan will be 1.36 GW including 1.1 GW of green power, bringing economies of scale and optimized fixed costs.\nConsidering the good Solar radiation at Rajasthan, the higher CUF for the project is possible and will generate green power of more than 50 Billion Units and offsets more than 50,000 tonnes of carbon dioxide emissions during the life of the project.\n'''",
        "detail": "edictai_app.app.scripting.script_1",
        "documentation": {}
    },
    {
        "label": "news",
        "kind": 5,
        "importPath": "edictai_app.app.scripting.script_1",
        "description": "edictai_app.app.scripting.script_1",
        "peekOfCode": "news = '''\nNLC India Ltd secures 810 MW Grid Connected Solar Photovoltaic Power Project in Rajasthan\nPosted On: 09 OCT 2023 12:34PM by PIB Delhi\nNLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).\nNLCIL has successfully garnered the entire capacity of the 810 MW tender floated by RRVUNL in December 2022, for developing the project RRVUNL’s 2000 MW Ultra Mega Solar Park at Pugal Tehsil, Bikaner District, Rajasthan. The Letter of Intent for this project has been issued by RRVUNL. This achievement marks a significant step forward in NLCIL's commitment to clean and sustainable energy solutions.\nThe land for the project and the power evacuation system connected to STU will be offered by RVUNL, paving the way for completion of the project at shorter period. This is the largest Renewable project to be developed by the company. With this project, the capacity of power project in   Rajasthan will be 1.36 GW including 1.1 GW of green power, bringing economies of scale and optimized fixed costs.\nConsidering the good Solar radiation at Rajasthan, the higher CUF for the project is possible and will generate green power of more than 50 Billion Units and offsets more than 50,000 tonnes of carbon dioxide emissions during the life of the project.\n'''\ncompletion = openai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",",
        "detail": "edictai_app.app.scripting.script_1",
        "documentation": {}
    },
    {
        "label": "completion",
        "kind": 5,
        "importPath": "edictai_app.app.scripting.script_1",
        "description": "edictai_app.app.scripting.script_1",
        "peekOfCode": "completion = openai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n    {\"role\": \"user\", \"content\": '''\n    Ensure that the script maintains an authentic and unbiased tone. Consider the video length to be 60-90 seconds. Our goal is to inform viewers about the official news from the government, and engage the viewers to see news in a visual format. \n    Please break the script into meaningful chunks with independent meaning.\n    Each chunk containing about 15-20 words.\n    Separate these chunks using \"<m>\" in the output.  \n    Note: Don't add any instructions or text in the output. Give the output in <m> tags only. ",
        "detail": "edictai_app.app.scripting.script_1",
        "documentation": {}
    },
    {
        "label": "add_speak_and_voice_tags",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.prompt_tune",
        "description": "edictai_app.app.sicp.prompt_tune",
        "peekOfCode": "def add_speak_and_voice_tags(input_xml):\n    # Check if <speak> and <voice> tags are present\n    speak_present = re.search(r'<speak[^>]*>', input_xml)\n    voice_present = re.search(r'<voice[^>]*>', input_xml)\n    if not speak_present and not voice_present:\n        # If both are missing, add both tags\n        input_xml = f'<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\"><voice name=\"en-US-JennyNeural\">{input_xml}</voice></speak>'\n    elif not speak_present:\n        # If only <speak> is missing, add it\n        input_xml = f'<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">{input_xml}</speak>'",
        "detail": "edictai_app.app.sicp.prompt_tune",
        "documentation": {}
    },
    {
        "label": "extract_text_between_speak_tags",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.prompt_tune",
        "description": "edictai_app.app.sicp.prompt_tune",
        "peekOfCode": "def extract_text_between_speak_tags(text):\n    # Define a regular expression pattern to match text between <speak> and </speak> tags.\n    pattern = r'<(.*?)</speak>'\n    # Use the re.findall function to find all matches of the pattern in the input text.\n    matches = re.findall(pattern, text, re.DOTALL)\n    # Reconstruct the matches with the <speak> and </speak> tags.\n    extracted_text = ['<' + match + '</speak>' for match in matches]\n    return extracted_text[0]\ndef script(scripts):\n    headers = {",
        "detail": "edictai_app.app.sicp.prompt_tune",
        "documentation": {}
    },
    {
        "label": "script",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.prompt_tune",
        "description": "edictai_app.app.sicp.prompt_tune",
        "peekOfCode": "def script(scripts):\n    headers = {\n        'x-api-key': '',\n        \"Content-Type\": \"application/json\",\n    }\n# sec_biHK4lRS8jyN3wsUapmqj14EwAllrR1v\n    data = {\n        'referenceSources':False,\n        'sourceId': \"src_EcUO1OGaEaoo6g5RAIrCJ\",\n        # src_qEYxtsLMRoH7J6jwSeFMT",
        "detail": "edictai_app.app.sicp.prompt_tune",
        "documentation": {}
    },
    {
        "label": "create_text_document",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.prompt_tune",
        "description": "edictai_app.app.sicp.prompt_tune",
        "peekOfCode": "def create_text_document(text, filename):\n    try:\n        with open(filename, 'w') as file:\n            file.write(text)\n        print(f\"Text has been successfully saved to {filename}\")\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\noutput_filename = \"ssml.txt\"\n# output_ssml = script(text)\n# print(output_ssml)",
        "detail": "edictai_app.app.sicp.prompt_tune",
        "documentation": {}
    },
    {
        "label": "output_filename",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.prompt_tune",
        "description": "edictai_app.app.sicp.prompt_tune",
        "peekOfCode": "output_filename = \"ssml.txt\"\n# output_ssml = script(text)\n# print(output_ssml)\n# create_text_document(output_ssml, output_filename)\n#   {\n#                 'role': \"user\",\n#                 'content': f\"\"\"Don't extend the given text, just take the given text as input , no annytype of extension like no suggestions , or self made comments should be made.\n#   Follow the steps to convert text to ssml:\n#                 0.Check if text is grammetically correct , if not them make it correct so that its an perfect input for \"text to ssml\" llm,Don't extend the text.\n#                 1.Firstly Identify the sentiment of complete data given and as per that set the standard pitch, tones and lexicons as per that.",
        "detail": "edictai_app.app.sicp.prompt_tune",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_bookmark_reached_cb",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def speech_synthesizer_bookmark_reached_cb(evt: speechsdk.SessionEventArgs):\n    print('BookmarkReached event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tText: {}'.format(evt.text))\ndef speech_synthesizer_synthesis_canceled_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCanceled event')\ndef speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_canceled_cb",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def speech_synthesizer_synthesis_canceled_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCanceled event')\ndef speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))\ndef speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_completed_cb",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisCompleted event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))\ndef speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesis_started_cb",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n    print('SynthesisStarted event')\ndef speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_synthesizing_cb",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n    print('Synthesizing event:')\n    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\ndef speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_viseme_received_cb",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n    print('VisemeReceived event:')\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tVisemeId: {}'.format(evt.viseme_id))\ndef speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tDuration: {}'.format(evt.duration))\n    print('\\tText: {}'.format(evt.text))",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer_word_boundary_cb",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n    print('WordBoundary event:')\n    print('\\tBoundaryType: {}'.format(evt.boundary_type))\n    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n    print('\\tDuration: {}'.format(evt.duration))\n    print('\\tText: {}'.format(evt.text))\n    print('\\tTextOffset: {}'.format(evt.text_offset))\n    print('\\tWordLength: {}'.format(evt.word_length))\n# This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\nspeech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"centralindia\")",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "remove_punctuation",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def remove_punctuation(text):\n    # Use a regular expression to remove all punctuation and signs\n    cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n    return cleaned_text\ntext = input(\"Enter your text:\\n\")\ncleaned_text = remove_punctuation(text)\n# print(cleaned_text)\nssml = script(cleaned_text)\ndef ssml_to_audio(ssml):\n    # Synthesize the SSML",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "ssml_to_audio",
        "kind": 2,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "def ssml_to_audio(ssml):\n    # Synthesize the SSML\n    print(\"SSML to synthesize: \\r\\n{}\".format(ssml))\n    speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()\n    stream = speechsdk.AudioDataStream(speech_synthesis_result)\n    stream.save_to_wav_file(\"audio_1.wav\")\n    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n        print(\"SynthesizingAudioCompleted result\")\n    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n        cancellation_details = speech_synthesis_result.cancellation_details",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"centralindia\")\n# Required for WordBoundary event sentences.\nspeech_config.set_property(property_id=speechsdk.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, value='true')\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)\nspeech_synthesizer.synthesizing.connect(speech_synthesizer_synthesizing_cb)\nspeech_synthesizer.viseme_received.connect(speech_synthesizer_viseme_received_cb)\nspeech_synthesizer.synthesis_word_boundary.connect(speech_synthesizer_word_boundary_cb)",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n# Subscribe to events\nspeech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\nspeech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\nspeech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\nspeech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)\nspeech_synthesizer.synthesizing.connect(speech_synthesizer_synthesizing_cb)\nspeech_synthesizer.viseme_received.connect(speech_synthesizer_viseme_received_cb)\nspeech_synthesizer.synthesis_word_boundary.connect(speech_synthesizer_word_boundary_cb)\n# The language of the voice that speaks.",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "text = input(\"Enter your text:\\n\")\ncleaned_text = remove_punctuation(text)\n# print(cleaned_text)\nssml = script(cleaned_text)\ndef ssml_to_audio(ssml):\n    # Synthesize the SSML\n    print(\"SSML to synthesize: \\r\\n{}\".format(ssml))\n    speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()\n    stream = speechsdk.AudioDataStream(speech_synthesis_result)\n    stream.save_to_wav_file(\"audio_1.wav\")",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "cleaned_text",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "cleaned_text = remove_punctuation(text)\n# print(cleaned_text)\nssml = script(cleaned_text)\ndef ssml_to_audio(ssml):\n    # Synthesize the SSML\n    print(\"SSML to synthesize: \\r\\n{}\".format(ssml))\n    speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()\n    stream = speechsdk.AudioDataStream(speech_synthesis_result)\n    stream.save_to_wav_file(\"audio_1.wav\")\n    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "ssml",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.ssml2audio",
        "description": "edictai_app.app.sicp.ssml2audio",
        "peekOfCode": "ssml = script(cleaned_text)\ndef ssml_to_audio(ssml):\n    # Synthesize the SSML\n    print(\"SSML to synthesize: \\r\\n{}\".format(ssml))\n    speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()\n    stream = speechsdk.AudioDataStream(speech_synthesis_result)\n    stream.save_to_wav_file(\"audio_1.wav\")\n    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n        print(\"SynthesizingAudioCompleted result\")\n    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:",
        "detail": "edictai_app.app.sicp.ssml2audio",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.tts",
        "description": "edictai_app.app.sicp.tts",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"centralindia\")\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n# The language of the voice that speaks.\nspeech_config.speech_synthesis_voice_name='en-IN-NeerjaNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Get text from the console and synthesize to the default speaker.\n# print(\"Enter some text that you want to speak >\")\n# text = input()\ntext = '''\nFor comprehensive coverage, these cameras are slated for installation every 1 0 km along National Highways, with state-of-the-art Command & Control Centres at every 100 km integrating various camera feeds.",
        "detail": "edictai_app.app.sicp.tts",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.tts",
        "description": "edictai_app.app.sicp.tts",
        "peekOfCode": "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n# The language of the voice that speaks.\nspeech_config.speech_synthesis_voice_name='en-IN-NeerjaNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Get text from the console and synthesize to the default speaker.\n# print(\"Enter some text that you want to speak >\")\n# text = input()\ntext = '''\nFor comprehensive coverage, these cameras are slated for installation every 1 0 km along National Highways, with state-of-the-art Command & Control Centres at every 100 km integrating various camera feeds.\n'''",
        "detail": "edictai_app.app.sicp.tts",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.tts",
        "description": "edictai_app.app.sicp.tts",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n# Get text from the console and synthesize to the default speaker.\n# print(\"Enter some text that you want to speak >\")\n# text = input()\ntext = '''\nFor comprehensive coverage, these cameras are slated for installation every 1 0 km along National Highways, with state-of-the-art Command & Control Centres at every 100 km integrating various camera feeds.\n'''\nspeech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"simple_chunk.wav\")",
        "detail": "edictai_app.app.sicp.tts",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.tts",
        "description": "edictai_app.app.sicp.tts",
        "peekOfCode": "text = '''\nFor comprehensive coverage, these cameras are slated for installation every 1 0 km along National Highways, with state-of-the-art Command & Control Centres at every 100 km integrating various camera feeds.\n'''\nspeech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"simple_chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(text))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details",
        "detail": "edictai_app.app.sicp.tts",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_result",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.tts",
        "description": "edictai_app.app.sicp.tts",
        "peekOfCode": "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"simple_chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(text))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:",
        "detail": "edictai_app.app.sicp.tts",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_stream",
        "kind": 5,
        "importPath": "edictai_app.app.sicp.tts",
        "description": "edictai_app.app.sicp.tts",
        "peekOfCode": "speech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"simple_chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(text))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:\n            print(\"Error details: {}\".format(cancellation_details.error_details))",
        "detail": "edictai_app.app.sicp.tts",
        "documentation": {}
    },
    {
        "label": "recognizing_handler",
        "kind": 2,
        "importPath": "edictai_app.app.speech_to_text.stt_1",
        "description": "edictai_app.app.speech_to_text.stt_1",
        "peekOfCode": "def recognizing_handler(e : speechsdk.SpeechRecognitionEventArgs) :\n    if speechsdk.ResultReason.RecognizingSpeech == e.result.reason and len(e.result.text) > 0 :\n        print(\"Recognized: {}\".format(result.text))\n        print(\"Offset in Ticks: {}\".format(result.offset))\n        print(\"Duration in Ticks: {}\".format(result.duration))\nspeech_config.request_word_level_timestamps()",
        "detail": "edictai_app.app.speech_to_text.stt_1",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.speech_to_text.stt_1",
        "description": "edictai_app.app.speech_to_text.stt_1",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"\")\naudio_config = speechsdk.AudioConfig(filename=\"audio_test/audios/audio_7.wav\")\nspeech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\nresult = speech_recognizer.recognize_once_async().get()\nprint(result.text)\ndef recognizing_handler(e : speechsdk.SpeechRecognitionEventArgs) :\n    if speechsdk.ResultReason.RecognizingSpeech == e.result.reason and len(e.result.text) > 0 :\n        print(\"Recognized: {}\".format(result.text))\n        print(\"Offset in Ticks: {}\".format(result.offset))\n        print(\"Duration in Ticks: {}\".format(result.duration))",
        "detail": "edictai_app.app.speech_to_text.stt_1",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.speech_to_text.stt_1",
        "description": "edictai_app.app.speech_to_text.stt_1",
        "peekOfCode": "audio_config = speechsdk.AudioConfig(filename=\"audio_test/audios/audio_7.wav\")\nspeech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\nresult = speech_recognizer.recognize_once_async().get()\nprint(result.text)\ndef recognizing_handler(e : speechsdk.SpeechRecognitionEventArgs) :\n    if speechsdk.ResultReason.RecognizingSpeech == e.result.reason and len(e.result.text) > 0 :\n        print(\"Recognized: {}\".format(result.text))\n        print(\"Offset in Ticks: {}\".format(result.offset))\n        print(\"Duration in Ticks: {}\".format(result.duration))\nspeech_config.request_word_level_timestamps()",
        "detail": "edictai_app.app.speech_to_text.stt_1",
        "documentation": {}
    },
    {
        "label": "speech_recognizer",
        "kind": 5,
        "importPath": "edictai_app.app.speech_to_text.stt_1",
        "description": "edictai_app.app.speech_to_text.stt_1",
        "peekOfCode": "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\nresult = speech_recognizer.recognize_once_async().get()\nprint(result.text)\ndef recognizing_handler(e : speechsdk.SpeechRecognitionEventArgs) :\n    if speechsdk.ResultReason.RecognizingSpeech == e.result.reason and len(e.result.text) > 0 :\n        print(\"Recognized: {}\".format(result.text))\n        print(\"Offset in Ticks: {}\".format(result.offset))\n        print(\"Duration in Ticks: {}\".format(result.duration))\nspeech_config.request_word_level_timestamps()",
        "detail": "edictai_app.app.speech_to_text.stt_1",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "edictai_app.app.speech_to_text.stt_1",
        "description": "edictai_app.app.speech_to_text.stt_1",
        "peekOfCode": "result = speech_recognizer.recognize_once_async().get()\nprint(result.text)\ndef recognizing_handler(e : speechsdk.SpeechRecognitionEventArgs) :\n    if speechsdk.ResultReason.RecognizingSpeech == e.result.reason and len(e.result.text) > 0 :\n        print(\"Recognized: {}\".format(result.text))\n        print(\"Offset in Ticks: {}\".format(result.offset))\n        print(\"Duration in Ticks: {}\".format(result.duration))\nspeech_config.request_word_level_timestamps()",
        "detail": "edictai_app.app.speech_to_text.stt_1",
        "documentation": {}
    },
    {
        "label": "SpeechToTextProcessor",
        "kind": 6,
        "importPath": "edictai_app.app.transcript.azure_transcripting",
        "description": "edictai_app.app.transcript.azure_transcripting",
        "peekOfCode": "class SpeechToTextProcessor:\n    def __init__(self, audio_file_path, subscription_key, service_region, locale=\"en-US\"):\n        self.audio_file_path = audio_file_path\n        self.subscription_key = subscription_key\n        self.service_region = service_region\n        self.locale = locale\n        self.done = False\n        self.transcript_display_list = []\n        self.transcript_ITN_list = []\n        self.confidence_list = []",
        "detail": "edictai_app.app.transcript.azure_transcripting",
        "documentation": {}
    },
    {
        "label": "json_dedo",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.azure_transcript_output",
        "description": "edictai_app.app.transcript.azure_transcript_output",
        "peekOfCode": "def json_dedo():\n    return (apnaJson)",
        "detail": "edictai_app.app.transcript.azure_transcript_output",
        "documentation": {}
    },
    {
        "label": "apnaJson",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.azure_transcript_output",
        "description": "edictai_app.app.transcript.azure_transcript_output",
        "peekOfCode": "apnaJson = [\n    {\n        \"Id\": \"ac6679dfe3e8455c81a43e0e335c6198\",\n        \"RecognitionStatus\": 0,\n        \"Offset\": 1300000,\n        \"Duration\": 57200000,\n        \"Channel\": 0,\n        \"DisplayText\": \"The Prime Minister, Sri Narendra Modi, congratulated Ronick Sidhwani on his remarkable victory.\",\n        \"NBest\": [\n            {",
        "detail": "edictai_app.app.transcript.azure_transcript_output",
        "documentation": {}
    },
    {
        "label": "lavdeKafunction",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.complete_transcript",
        "description": "edictai_app.app.transcript.complete_transcript",
        "peekOfCode": "def lavdeKafunction():\n    # Create chunks \n    chunks_list = []\n    import os\n    import openai\n    openai.organization = \"\"\n    openai.api_key = \"\"\n    news = '''\n    PM inaugurates 141st International Olympic Committee (IOC) Session in Mumbai \"India is eager to host the Olympics in the country. India will leave no stone unturned in the preparation for the successful organization of the Olympics in 2036. This is the dream of the 140 crore Indians\" “India is also eager to host the Youth Olympics taking place in the year 2029” “Indians are not just sports lovers, but we also live it” “The sporting legacy of India belongs to the entire world” “In sports, there are no losers, there are only winners and learners” “We are focussing on inclusivity and diversity in sports in India” “IOC Executive Board has recommended including Cricket in the Olympics and we hope to hear positive news soon” Posted On: 14 OCT 2023 9:09PM by PIB Delhi The Prime Minister, Shri Narendra Modi inaugurated the 141st International Olympic Committee (IOC) Session in Mumbai today. The Session provides an opportunity for interaction and knowledge sharing among the various stakeholders related to sports. Addressing the gathering, the Prime Minister underlined the significance of the session taking place in India after 40 years. He also informed the audience about India’s victory in the Cricket World Cup fixture at the world’s largest stadium in Ahmedabad to the roar of cheers. “I congratulate Team Bharat and every Indian on this historic victory”, he said. The Prime Minister emphasized that sports has been a vital part of India’s culture and lifestyle. When you go to the villages of India, the Prime Minister said, one can find that any festival remains incomplete without sports. “Indians are not just sports lovers, but we also live it”, Shri Modi said. He highlighted that the sporting culture is reflected through the thousands year old history of India. Be it the Indus Valley Civilization, the Vedic Period or the era after it, the Prime Minister underlined that India’s sporting legacy has been very prosperous. He informed that scriptures written thousands of years ago mentioned being proficient in 64 genres including sports such as horse riding, swimming, archery wrestling etc. and emphasis was laid on excelling in them. He stated that a ‘Dhanur Veda Samhita’ i.e. a Code for Archery was published to learn the sport of archery which mentions 7 mandatory skills as a prerequisite to learn archery namely Dhanushvan, Chakra, Bhala, Fencing, Dagger, Mace and Wrestling. The Prime Minister presented scientific evidence of this ancient sport legacy of India. He mentioned the Dholavira UNESCO World Heritage site and talked about sports infrastructure in the urban planning of this 5000-year-old city. In the excavation, the Prime Minister said, two stadiums were found, one of them being the oldest and biggest stadium in the world at that time. Similarly, in Rakhigarhi sports-related structures have been found. “This sporting legacy of India belongs to the entire world”, Shri Modi said. Prime Minister Modi said, “There are no losers in sports, only the winners and learners. The language and spirit of sports are universal. Sports is not mere competition. Sports gives humanity an opportunity to expand.” “That is why records are celebrated globally. Sports also strengthens the spirit of ‘Vasudhaiva Kutumbakam’ - One Earth, One Family, One Future”, he added. The Prime Minister also listed recent measures for the development of sports in India. He mentioned Khelo India Games, Khelo India Youth Games, Khelo India Winter Games, Member of Parliament sports competitions and the upcoming Khelo India Para Games. “We are focussing on inclusivity and diversity in sports in India”, the Prime Minister emphasized The Prime Minister credited the efforts of the government for India’s shining performance in the world of sports. He recalled the magnificent performances of many athletes in the last edition of the Olympics and also highlighted India’s best-ever performance in the recently concluded Asian Games and the new records made by young athletes of India in the World University Games.  He underlined that the positive changes are a sign of the rapidly transforming landscape of sports in India. Shri Modi emphasized that India has successfully proved its capability to organize global sports tournaments. He mentioned the recently hosted global tournaments such as the Chess Olympiad which witnessed the participation of 186 countries, the Football Under-17 Women’s World Cup, the Hockey World Cup, the Women’s World Boxing Championship, the Shooting World Cup and the ongoing Cricket World Cup. He also underlined that the nation organizes the largest cricket league in the world every year. The Prime Minister informed that the IOC Executive Board has recommended including Cricket in the Olympics and expressed confidence that the recommendations will be accepted. Underling that global events are an opportunity for India to welcome the world, the Prime Minister emphasized that India is primed to host global events owing to its fast-expanding economy and well-developed infrastructure. He gave the example of the G20 Summit where events were organized in more than 60 cities of the country and said that it is proof of India’s organizing capacity in every sector. The Prime Minister put forth the belief of 140 crore citizens of India “India is eager to host the Olympics in the country. India will leave no stone unturned in the preparation for the successful organization of the Olympics in 2036, this is the dream of the 140 crore Indians”, the Prime Minister said. He emphasized that the nation wishes to fulfill this dream with the support of all stakeholders. “India is also eager to host the Youth Olympics taking place in the year 2029”, Shri Modi remarked and expressed confidence that the IOC will continue lending its support to India. The Prime Minister said that “sports is not just for winning medals but is a medium to win hearts. Sports belongs to all for all. It not only prepares champions but also promotes peace, progress and wellness. Therefore, sports is another medium of uniting the world”. Once again welcoming the delegates, the Prime Minister declared the session open. President of the International Olympic Committee, Mr Thomas Bach and member of International Olympic Committee, Mrs Nita Ambani were present on the occasion among others. Background The IOC session serves as a key meeting of the International Olympic Committee (IOC) members. Important decisions regarding the future of the Olympic games are made at the IOC Sessions. India is hosting the IOC session for the second time after a gap of about 40 years. The IOC's 86th session was held in New Delhi in 1983. The 141st IOC Session, being held in India embodies the nation's dedication to fostering global cooperation, celebrating sporting excellence and furthering the Olympic ideals of friendship, respect, and excellence. It provides an opportunity for interaction and knowledge sharing among the various sports-related stakeholders. The session was also attended by the President of the International Olympic Committee, Mr. Thomas Bach and other members of the IOC, along with prominent Indian sports personalities and representatives from various sports federations, including the Indian Olympic Association.    \n    '''",
        "detail": "edictai_app.app.transcript.complete_transcript",
        "documentation": {}
    },
    {
        "label": "chunks_list",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "chunks_list = []\nimport os\nimport openai\nopenai.organization = \"org-5LY5AiUTjRELf7YC1UtBfo0j\"\nopenai.api_key = \"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\"\nnews = '''\nPM thanks artists for rendition of his Garba song Posted On: 14 OCT 2023 11:57AM by PIB Delhi The Prime Minister, Shri Narendra Modi today thanked artists Dhvani Bhanushali, Tanishk Bagchi and team of Jjust  Music for musical, rendition of a Garba that he had penned years ago. He also informed that he will share a new Garba during the upcoming Navratri. Shri Narendra Modi posted on X : \"Thank you @dhvanivinod, Tanishk Bagchi and the team of @Jjust_Music for this lovely rendition of a Garba I had penned years ago! It does bring back many memories. I have not written for many years now but I did manage to write a new Garba over the last few days, which I will share during Navratri. #SoulfulGarba\"'''\ncompletion = openai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "openai.organization = \"org-5LY5AiUTjRELf7YC1UtBfo0j\"\nopenai.api_key = \"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\"\nnews = '''\nPM thanks artists for rendition of his Garba song Posted On: 14 OCT 2023 11:57AM by PIB Delhi The Prime Minister, Shri Narendra Modi today thanked artists Dhvani Bhanushali, Tanishk Bagchi and team of Jjust  Music for musical, rendition of a Garba that he had penned years ago. He also informed that he will share a new Garba during the upcoming Navratri. Shri Narendra Modi posted on X : \"Thank you @dhvanivinod, Tanishk Bagchi and the team of @Jjust_Music for this lovely rendition of a Garba I had penned years ago! It does bring back many memories. I have not written for many years now but I did manage to write a new Garba over the last few days, which I will share during Navratri. #SoulfulGarba\"'''\ncompletion = openai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n    {\"role\": \"user\", \"content\": '''\n    Ensure that the script maintains an authentic and unbiased tone. Consider the video length to be 60-90 seconds. Our goal is to inform viewers about the official news from the government, and engage the viewers to see news in a visual format. ",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "openai.api_key = \"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\"\nnews = '''\nPM thanks artists for rendition of his Garba song Posted On: 14 OCT 2023 11:57AM by PIB Delhi The Prime Minister, Shri Narendra Modi today thanked artists Dhvani Bhanushali, Tanishk Bagchi and team of Jjust  Music for musical, rendition of a Garba that he had penned years ago. He also informed that he will share a new Garba during the upcoming Navratri. Shri Narendra Modi posted on X : \"Thank you @dhvanivinod, Tanishk Bagchi and the team of @Jjust_Music for this lovely rendition of a Garba I had penned years ago! It does bring back many memories. I have not written for many years now but I did manage to write a new Garba over the last few days, which I will share during Navratri. #SoulfulGarba\"'''\ncompletion = openai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n    {\"role\": \"user\", \"content\": '''\n    Ensure that the script maintains an authentic and unbiased tone. Consider the video length to be 60-90 seconds. Our goal is to inform viewers about the official news from the government, and engage the viewers to see news in a visual format. \n    Please break the script into meaningful chunks with independent meaning.",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "news",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "news = '''\nPM thanks artists for rendition of his Garba song Posted On: 14 OCT 2023 11:57AM by PIB Delhi The Prime Minister, Shri Narendra Modi today thanked artists Dhvani Bhanushali, Tanishk Bagchi and team of Jjust  Music for musical, rendition of a Garba that he had penned years ago. He also informed that he will share a new Garba during the upcoming Navratri. Shri Narendra Modi posted on X : \"Thank you @dhvanivinod, Tanishk Bagchi and the team of @Jjust_Music for this lovely rendition of a Garba I had penned years ago! It does bring back many memories. I have not written for many years now but I did manage to write a new Garba over the last few days, which I will share during Navratri. #SoulfulGarba\"'''\ncompletion = openai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n    {\"role\": \"user\", \"content\": '''\n    Ensure that the script maintains an authentic and unbiased tone. Consider the video length to be 60-90 seconds. Our goal is to inform viewers about the official news from the government, and engage the viewers to see news in a visual format. \n    Please break the script into meaningful chunks with independent meaning.\n    Each chunk containing about 15-20 words.",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "completion",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "completion = openai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n    {\"role\": \"user\", \"content\": '''\n    Ensure that the script maintains an authentic and unbiased tone. Consider the video length to be 60-90 seconds. Our goal is to inform viewers about the official news from the government, and engage the viewers to see news in a visual format. \n    Please break the script into meaningful chunks with independent meaning.\n    Each chunk containing about 15-20 words.\n    Separate these chunks using \"<m>\" in the output.  \n    Note: Don't add any instructions or text in the output. Give the output in <m> tags only. ",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "chunks = completion.choices[0].message.content\nsentences = re.split(r\"<m>|\\\\n|\\n|</m>\",chunks)\nsentences = [sentence.strip() for sentence in sentences]\nsentences = [sentence for sentence in sentences if sentence]\nprint(sentences)\nprint()\n# Creating keywords for sentences\nfrom keybert import KeyBERT\nfor sentence in sentences:\n    kw_model = KeyBERT()",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "sentences = re.split(r\"<m>|\\\\n|\\n|</m>\",chunks)\nsentences = [sentence.strip() for sentence in sentences]\nsentences = [sentence for sentence in sentences if sentence]\nprint(sentences)\nprint()\n# Creating keywords for sentences\nfrom keybert import KeyBERT\nfor sentence in sentences:\n    kw_model = KeyBERT()\n    extracted_keywords = kw_model.extract_keywords(sentence,keyphrase_ngram_range=(1, 1))",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "sentences = [sentence.strip() for sentence in sentences]\nsentences = [sentence for sentence in sentences if sentence]\nprint(sentences)\nprint()\n# Creating keywords for sentences\nfrom keybert import KeyBERT\nfor sentence in sentences:\n    kw_model = KeyBERT()\n    extracted_keywords = kw_model.extract_keywords(sentence,keyphrase_ngram_range=(1, 1))\n    keywords = []",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "sentences = [sentence for sentence in sentences if sentence]\nprint(sentences)\nprint()\n# Creating keywords for sentences\nfrom keybert import KeyBERT\nfor sentence in sentences:\n    kw_model = KeyBERT()\n    extracted_keywords = kw_model.extract_keywords(sentence,keyphrase_ngram_range=(1, 1))\n    keywords = []\n    if len(extracted_keywords)>3:",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"21186bfc40b44f23bdd5d7afe3f19552\", region=\"centralindia\")\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_config.speech_synthesis_voice_name='en-US-JennyNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\ncombined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk_2.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_config.speech_synthesis_voice_name='en-US-JennyNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\ncombined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk_2.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\ncombined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk_2.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "combined_chunks",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "combined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk_2.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_result",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "speech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk_2.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_stream",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "speech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk_2.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:\n            print(\"Error details: {}\".format(cancellation_details.error_details))",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "model_size",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "model_size = \"small\"\nmodel = WhisperModel(model_size)\nsegments, info = model.transcribe(\"chunk.wav\", word_timestamps=True)\nsegments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "model = WhisperModel(model_size)\nsegments, info = model.transcribe(\"chunk.wav\", word_timestamps=True)\nsegments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word.strip().lower(),'start':word.start,'end':word.end})",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "segments",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "segments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word.strip().lower(),'start':word.start,'end':word.end})\nprint(wordlevel_info)\n# JSON Converter ",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "wordlevel_info",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "wordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word.strip().lower(),'start':word.start,'end':word.end})\nprint(wordlevel_info)\n# JSON Converter \n# output = []\n# item={'chunk':chunks_list[0]['sentence'],'start_time':wordlevel_info[0]['start'],'end_time':wordlevel_info[0+len(chunks_list[0]['sentence'].split())]['end'],'keywords':chunks_list[0]['keywords']}\n# print(item)\n# # print(wordlevel_info[len(chunks_list[0]['sentence'])]['end'])",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "output = []\ncurrentStartWord = 0\nfor i in chunks_list:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            if (wordlevel_info[k]['word'] == j):\n                keywordArray.append({'word':j,'start_time':wordlevel_info[k]['start'],'end_time':wordlevel_info[k]['end']})\n    print(wordlevel_info[currentStartWord]['start'])\n    item = {'chunk': i['sentence'], 'start_time': wordlevel_info[currentStartWord]['start'],",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "currentStartWord",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.complete_transcript_2",
        "description": "edictai_app.app.transcript.complete_transcript_2",
        "peekOfCode": "currentStartWord = 0\nfor i in chunks_list:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            if (wordlevel_info[k]['word'] == j):\n                keywordArray.append({'word':j,'start_time':wordlevel_info[k]['start'],'end_time':wordlevel_info[k]['end']})\n    print(wordlevel_info[currentStartWord]['start'])\n    item = {'chunk': i['sentence'], 'start_time': wordlevel_info[currentStartWord]['start'],\n            'end_time': wordlevel_info[currentStartWord+len(i['sentence'].split())-1]['end'], 'keywords': keywordArray}",
        "detail": "edictai_app.app.transcript.complete_transcript_2",
        "documentation": {}
    },
    {
        "label": "lavdeKafunction",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.complete_transcript_3",
        "description": "edictai_app.app.transcript.complete_transcript_3",
        "peekOfCode": "def lavdeKafunction():\n    # Create chunks \n    import json\n    chunks_list = []\n    from Keyword_json import subject_json\n    import os\n    import openai\n    openai.organization = \"\"\n    openai.api_key = \"\"\n    news = '''",
        "detail": "edictai_app.app.transcript.complete_transcript_3",
        "documentation": {}
    },
    {
        "label": "inputList1",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter",
        "description": "edictai_app.app.transcript.json_converter",
        "peekOfCode": "inputList1 = [\n    {'word': ' Good', 'start': 0.0, 'end': 0.34},\n    {'word': ' morning', 'start': 0.34, 'end': 0.82},\n    {'word': ' everyone', 'start': 0.98, 'end': 1.56},\n    {'word': \" I'm\", 'start': 2.64, 'end': 2.78},\n    {'word': ' here', 'start': 2.78, 'end': 3.0},\n    {'word': ' today', 'start': 3.0, 'end': 3.38},\n    {'word': ' to', 'start': 3.38, 'end': 3.68},\n    {'word': ' talk', 'start': 3.68, 'end': 3.94},\n    {'word': ' about', 'start': 3.94, 'end': 4.12},",
        "detail": "edictai_app.app.transcript.json_converter",
        "documentation": {}
    },
    {
        "label": "inputList2",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter",
        "description": "edictai_app.app.transcript.json_converter",
        "peekOfCode": "inputList2 = [\n    {'sentence': \"Good morning everyone\", 'keywords': ['morning']},\n    {'sentence':  \"I'm here today to talk about the\", 'keywords': ['talk', 'about']},\n    {\"sentence\": \"historic passage of the\", \"keywords\": [\"historic\"]},\n    {'sentence': \"Nari Shakti Vandana\", 'keywords': ['Nari']}\n]\noutput = []\n# item={'chunk':inputList2[0]['sentence'],'start_time':inputList1[0]['start'],'end_time':inputList1[0+len(inputList2[0]['sentence'].split())]['end'],'keywords':inputList2[0]['keywords']}\n# print(item)\n# # print(inputList1[len(inputList2[0]['sentence'])]['end'])",
        "detail": "edictai_app.app.transcript.json_converter",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter",
        "description": "edictai_app.app.transcript.json_converter",
        "peekOfCode": "output = []\n# item={'chunk':inputList2[0]['sentence'],'start_time':inputList1[0]['start'],'end_time':inputList1[0+len(inputList2[0]['sentence'].split())]['end'],'keywords':inputList2[0]['keywords']}\n# print(item)\n# # print(inputList1[len(inputList2[0]['sentence'])]['end'])\n# for i in range(0,len(inputList2[0]['sentence'].split())):\n#     if(inputList1[i]['word']==' Good'):\n#         output.append(inputList1[i]['word'])\n#     else:continue\nfinalop = []\ncurrentStartWord = 0",
        "detail": "edictai_app.app.transcript.json_converter",
        "documentation": {}
    },
    {
        "label": "finalop",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter",
        "description": "edictai_app.app.transcript.json_converter",
        "peekOfCode": "finalop = []\ncurrentStartWord = 0\nfor i in inputList2:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            if (inputList1[k]['word'].strip() == j):\n                keywordArray.append({'word':j,'start_time':inputList1[k]['start'],'end_time':inputList1[k]['end']})\n    print(inputList1[currentStartWord]['start'])\n    item = {'chunk': i['sentence'], 'start_time': inputList1[currentStartWord]['start'],",
        "detail": "edictai_app.app.transcript.json_converter",
        "documentation": {}
    },
    {
        "label": "currentStartWord",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter",
        "description": "edictai_app.app.transcript.json_converter",
        "peekOfCode": "currentStartWord = 0\nfor i in inputList2:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            if (inputList1[k]['word'].strip() == j):\n                keywordArray.append({'word':j,'start_time':inputList1[k]['start'],'end_time':inputList1[k]['end']})\n    print(inputList1[currentStartWord]['start'])\n    item = {'chunk': i['sentence'], 'start_time': inputList1[currentStartWord]['start'],\n            'end_time': inputList1[currentStartWord+len(i['sentence'].split())-1]['end'], 'keywords': keywordArray}",
        "detail": "edictai_app.app.transcript.json_converter",
        "documentation": {}
    },
    {
        "label": "apnaJson",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter_2",
        "description": "edictai_app.app.transcript.json_converter_2",
        "peekOfCode": "apnaJson = []\noutput = []\nfor jid in apnaJson: \n    output.append({'chunk':jid['DisplayText'], 'start':(jid['Offset']/10000000), 'end':((jid['Duration']+jid['Offset'])/10000000)})\nwords = []\nfor jid in apnaJson:\n    for chunk_words in jid['NBest'][0]['Words']:\n        words.append({'word':chunk_words['Word'], 'start':chunk_words['Offset']/10000000, 'end':((chunk_words['Duration']+chunk_words['Offset'])/10000000)})\nprint(words)",
        "detail": "edictai_app.app.transcript.json_converter_2",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter_2",
        "description": "edictai_app.app.transcript.json_converter_2",
        "peekOfCode": "output = []\nfor jid in apnaJson: \n    output.append({'chunk':jid['DisplayText'], 'start':(jid['Offset']/10000000), 'end':((jid['Duration']+jid['Offset'])/10000000)})\nwords = []\nfor jid in apnaJson:\n    for chunk_words in jid['NBest'][0]['Words']:\n        words.append({'word':chunk_words['Word'], 'start':chunk_words['Offset']/10000000, 'end':((chunk_words['Duration']+chunk_words['Offset'])/10000000)})\nprint(words)",
        "detail": "edictai_app.app.transcript.json_converter_2",
        "documentation": {}
    },
    {
        "label": "words",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter_2",
        "description": "edictai_app.app.transcript.json_converter_2",
        "peekOfCode": "words = []\nfor jid in apnaJson:\n    for chunk_words in jid['NBest'][0]['Words']:\n        words.append({'word':chunk_words['Word'], 'start':chunk_words['Offset']/10000000, 'end':((chunk_words['Duration']+chunk_words['Offset'])/10000000)})\nprint(words)",
        "detail": "edictai_app.app.transcript.json_converter_2",
        "documentation": {}
    },
    {
        "label": "SpeechToTextProcessor",
        "kind": 6,
        "importPath": "edictai_app.app.transcript.json_converter_3",
        "description": "edictai_app.app.transcript.json_converter_3",
        "peekOfCode": "class SpeechToTextProcessor:\n    def __init__(self):\n        pass\n    def process(self):\n        apnaJson = []\n        words = []\n        output = []\n        audio_filepath = 'audios/chunk.wav'  # Replace with your audio file path\n        locale = \"en-US\"  # Change as per requirement\n        logger.debug(audio_filepath)",
        "detail": "edictai_app.app.transcript.json_converter_3",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.json_converter_3",
        "description": "edictai_app.app.transcript.json_converter_3",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.DEBUG)\nclass SpeechToTextProcessor:\n    def __init__(self):\n        pass\n    def process(self):\n        apnaJson = []\n        words = []\n        output = []\n        audio_filepath = 'audios/chunk.wav'  # Replace with your audio file path",
        "detail": "edictai_app.app.transcript.json_converter_3",
        "documentation": {}
    },
    {
        "label": "kw_model",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keybert_1",
        "description": "edictai_app.app.transcript.keybert_1",
        "peekOfCode": "kw_model = KeyBERT()\nkeywords = kw_model.extract_keywords(\"If someone were to ask me- if there is one place you must visit in Uttarakhand which place would it be, I would say you must visit Parvati Kund and Jageshwar Temples in the Kumaon region of the state. The natural beauty and divinity will leave you spellbound. \",keyphrase_ngram_range=(1, 1)) \nonly_keywords = []\nif len(keywords)>3:\n    keywords = keywords[0:3]\nfor key in keywords: \n    only_keywords.append(key[0])\nprint(only_keywords)\n# import openai\n# from keybert.llm import OpenAI",
        "detail": "edictai_app.app.transcript.keybert_1",
        "documentation": {}
    },
    {
        "label": "keywords",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keybert_1",
        "description": "edictai_app.app.transcript.keybert_1",
        "peekOfCode": "keywords = kw_model.extract_keywords(\"If someone were to ask me- if there is one place you must visit in Uttarakhand which place would it be, I would say you must visit Parvati Kund and Jageshwar Temples in the Kumaon region of the state. The natural beauty and divinity will leave you spellbound. \",keyphrase_ngram_range=(1, 1)) \nonly_keywords = []\nif len(keywords)>3:\n    keywords = keywords[0:3]\nfor key in keywords: \n    only_keywords.append(key[0])\nprint(only_keywords)\n# import openai\n# from keybert.llm import OpenAI\n# from keybert import KeyLLM",
        "detail": "edictai_app.app.transcript.keybert_1",
        "documentation": {}
    },
    {
        "label": "only_keywords",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keybert_1",
        "description": "edictai_app.app.transcript.keybert_1",
        "peekOfCode": "only_keywords = []\nif len(keywords)>3:\n    keywords = keywords[0:3]\nfor key in keywords: \n    only_keywords.append(key[0])\nprint(only_keywords)\n# import openai\n# from keybert.llm import OpenAI\n# from keybert import KeyLLM\n# from sentence_transformers import SentenceTransformer",
        "detail": "edictai_app.app.transcript.keybert_1",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keybert_1",
        "description": "edictai_app.app.transcript.keybert_1",
        "peekOfCode": "openai.organization = \"\"\nopenai.api_key = \"\"\nsentence = '''The Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023.'''\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": '''",
        "detail": "edictai_app.app.transcript.keybert_1",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keybert_1",
        "description": "edictai_app.app.transcript.keybert_1",
        "peekOfCode": "openai.api_key = \"\"\nsentence = '''The Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023.'''\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": '''\n            You will be provided with a block of text, and your task is to extract a list of keywords from it.",
        "detail": "edictai_app.app.transcript.keybert_1",
        "documentation": {}
    },
    {
        "label": "sentence",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keybert_1",
        "description": "edictai_app.app.transcript.keybert_1",
        "peekOfCode": "sentence = '''The Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023.'''\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": '''\n            You will be provided with a block of text, and your task is to extract a list of keywords from it.\n            Note: Keywords extracted would be used as a query to search for images on search engines. ",
        "detail": "edictai_app.app.transcript.keybert_1",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keybert_1",
        "description": "edictai_app.app.transcript.keybert_1",
        "peekOfCode": "response = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": '''\n            You will be provided with a block of text, and your task is to extract a list of keywords from it.\n            Note: Keywords extracted would be used as a query to search for images on search engines. \n            Please avoid unnecessary details or tangential points.",
        "detail": "edictai_app.app.transcript.keybert_1",
        "documentation": {}
    },
    {
        "label": "authenticate_client",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.keywords",
        "description": "edictai_app.app.transcript.keywords",
        "peekOfCode": "def authenticate_client():\n    ta_credential = AzureKeyCredential(key)\n    text_analytics_client = TextAnalyticsClient(\n            endpoint=endpoint, \n            credential=ta_credential)\n    return text_analytics_client\nclient = authenticate_client()\ndef key_phrase_extraction_example(client):\n    try:\n        documents = ['''The Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023.''']",
        "detail": "edictai_app.app.transcript.keywords",
        "documentation": {}
    },
    {
        "label": "key_phrase_extraction_example",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.keywords",
        "description": "edictai_app.app.transcript.keywords",
        "peekOfCode": "def key_phrase_extraction_example(client):\n    try:\n        documents = ['''The Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023.''']\n        response = client.extract_key_phrases(documents = documents)[0]\n        if not response.is_error:\n            print(\"\\tKey Phrases:\")\n            for phrase in response.key_phrases:\n                print(\"\\t\\t\", phrase)\n        else:\n            print(response.id, response.error)",
        "detail": "edictai_app.app.transcript.keywords",
        "documentation": {}
    },
    {
        "label": "key",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keywords",
        "description": "edictai_app.app.transcript.keywords",
        "peekOfCode": "key = \"\"\nendpoint = \"https://keyword-extraction-1.cognitiveservices.azure.com/\"\ndef authenticate_client():\n    ta_credential = AzureKeyCredential(key)\n    text_analytics_client = TextAnalyticsClient(\n            endpoint=endpoint, \n            credential=ta_credential)\n    return text_analytics_client\nclient = authenticate_client()\ndef key_phrase_extraction_example(client):",
        "detail": "edictai_app.app.transcript.keywords",
        "documentation": {}
    },
    {
        "label": "endpoint",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keywords",
        "description": "edictai_app.app.transcript.keywords",
        "peekOfCode": "endpoint = \"https://keyword-extraction-1.cognitiveservices.azure.com/\"\ndef authenticate_client():\n    ta_credential = AzureKeyCredential(key)\n    text_analytics_client = TextAnalyticsClient(\n            endpoint=endpoint, \n            credential=ta_credential)\n    return text_analytics_client\nclient = authenticate_client()\ndef key_phrase_extraction_example(client):\n    try:",
        "detail": "edictai_app.app.transcript.keywords",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.keywords",
        "description": "edictai_app.app.transcript.keywords",
        "peekOfCode": "client = authenticate_client()\ndef key_phrase_extraction_example(client):\n    try:\n        documents = ['''The Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023.''']\n        response = client.extract_key_phrases(documents = documents)[0]\n        if not response.is_error:\n            print(\"\\tKey Phrases:\")\n            for phrase in response.key_phrases:\n                print(\"\\t\\t\", phrase)\n        else:",
        "detail": "edictai_app.app.transcript.keywords",
        "documentation": {}
    },
    {
        "label": "subject_json",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.Keyword_json",
        "description": "edictai_app.app.transcript.Keyword_json",
        "peekOfCode": "def subject_json(scripts):\n    headers = {\n        'x-api-key': '',\n        \"Content-Type\": \"application/json\",\n    }\n    data = {\n        # 'referenceSources':True,\n        'sourceId': \"src_u2eiIYKqeemdNk6VShXZe\",\n        # f3 = src_151ckg3zdch65CjbJ1Emt\n        # f1 = src_i9SUoSnlj8W5PhzyswOCr",
        "detail": "edictai_app.app.transcript.Keyword_json",
        "documentation": {}
    },
    {
        "label": "transcribe_audio",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "def transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "abstract_summary_extraction",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "def abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a highly skilled AI trained in language comprehension and summarization. I would like you to read the following text and summarize it into a concise abstract paragraph. Aim to retain the most important points, providing a coherent and readable summary that could help a person understand the main points of the discussion without needing to read the entire text. Please avoid unnecessary details or tangential points.\"\n            },\n            {",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "key_points_extraction",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "def key_points_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a proficient AI with a specialty in distilling information into key points. Based on the following text, identify and list the main points that were discussed or brought up. These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. Your goal is to provide a list that someone could read to quickly understand what was talked about.\"\n            },\n            {",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "action_item_extraction",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "def action_item_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are an AI expert in analyzing conversations and extracting action items. Please review the text and identify any tasks, assignments, or actions that were agreed upon or mentioned as needing to be done. These could be tasks assigned to specific individuals, or general actions that the group has decided to take. Please list these action items clearly and concisely.\"\n            },\n            {",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "sentiment_analysis",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "def sentiment_analysis(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"As an AI with expertise in language and emotion analysis, your task is to analyze the sentiment of the following text. Please consider the overall tone of the discussion, the emotion conveyed by the language used, and the context in which words and phrases are used. Indicate whether the sentiment is generally positive, negative, or neutral, and provide brief explanations for your analysis where possible.\"\n            },\n            {",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "meeting_minutes",
        "kind": 2,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "def meeting_minutes(transcription):\n    abstract_summary = abstract_summary_extraction(transcription)\n    key_points = key_points_extraction(transcription)\n    action_items = action_item_extraction(transcription)\n    sentiment = sentiment_analysis(transcription)\n    return {\n        'abstract_summary': abstract_summary,\n        'key_points': key_points,\n        'action_items': action_items,\n        'sentiment': sentiment",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "audio_file_path",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "audio_file_path = \"blob_images/Shorts.mp4\"\nopenai.organization = \"\"\nopenai.api_key = \"\"\ndef transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "openai.organization = \"\"\nopenai.api_key = \"\"\ndef transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "openai.api_key = \"\"\ndef transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "news",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keywords",
        "description": "edictai_app.app.transcript.openai_keywords",
        "peekOfCode": "news = '''\nPM addresses Kaushal Dikshnat Samaroh 2023 via video message\n“Kaushal Dikshnat Samaroh reflects the priorities of today's India”\n“Country develops more with stronger youth power thereby doing justice to nation’s resources”\n“Today, the whole world is of the belief that this century is going to be India's century”\n“Our government understood the importance of skill and created a separate ministry for it, allocated separate budget”\n“Important for industry, research and skill development institutions to be in tune with present times”\n“Scope of skill development is continuously increasing in India. We are not limited to just mechanics, engineers, technology or any other service”\n“Unemployment rate in India is at its lowest level in 6 years”\n“IMF is confident of India becoming the top three economies of the world in the next 3-4 years”",
        "detail": "edictai_app.app.transcript.openai_keywords",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keyword_extraction",
        "description": "edictai_app.app.transcript.openai_keyword_extraction",
        "peekOfCode": "openai.organization = \"\"\nopenai.api_key = \"\"\nsentences = '''\n['NLC India Ltd secures 810 MW Grid Connected Solar Photovoltaic Power Project in Rajasthan.', 'NLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).', 'NLCIL has successfully garnered the entire capacity of the 810 MW tender floated by RRVUNL in December 2022, for developing the project RRVUNL’s 2000 MW Ultra Mega Solar Park at Pugal Tehsil, Bikaner District, Rajasthan.', 'The Letter of Intent for this project has been issued by RRVUNL.', 'The land for the project and the power evacuation system connected to STU will be offered by RVUNL, paving the way for completion of the project at shorter period.', 'This is the largest Renewable project to be developed by the company.', 'With this project, the capacity of power project in Rajasthan will be 1.36 GW including 1.1 GW of green power, bringing economies of scale and optimized fixed costs.', 'Considering the good Solar radiation at Rajasthan, the higher CUF for the project is possible and will generate green power of more than 50 Billion Units and offsets more than 50,000 tonnes of carbon dioxide emissions during the life of the project.']\n'''\nsentence = '''\nNLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).\n'''\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",",
        "detail": "edictai_app.app.transcript.openai_keyword_extraction",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keyword_extraction",
        "description": "edictai_app.app.transcript.openai_keyword_extraction",
        "peekOfCode": "openai.api_key = \"\"\nsentences = '''\n['NLC India Ltd secures 810 MW Grid Connected Solar Photovoltaic Power Project in Rajasthan.', 'NLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).', 'NLCIL has successfully garnered the entire capacity of the 810 MW tender floated by RRVUNL in December 2022, for developing the project RRVUNL’s 2000 MW Ultra Mega Solar Park at Pugal Tehsil, Bikaner District, Rajasthan.', 'The Letter of Intent for this project has been issued by RRVUNL.', 'The land for the project and the power evacuation system connected to STU will be offered by RVUNL, paving the way for completion of the project at shorter period.', 'This is the largest Renewable project to be developed by the company.', 'With this project, the capacity of power project in Rajasthan will be 1.36 GW including 1.1 GW of green power, bringing economies of scale and optimized fixed costs.', 'Considering the good Solar radiation at Rajasthan, the higher CUF for the project is possible and will generate green power of more than 50 Billion Units and offsets more than 50,000 tonnes of carbon dioxide emissions during the life of the project.']\n'''\nsentence = '''\nNLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).\n'''\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,",
        "detail": "edictai_app.app.transcript.openai_keyword_extraction",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keyword_extraction",
        "description": "edictai_app.app.transcript.openai_keyword_extraction",
        "peekOfCode": "sentences = '''\n['NLC India Ltd secures 810 MW Grid Connected Solar Photovoltaic Power Project in Rajasthan.', 'NLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).', 'NLCIL has successfully garnered the entire capacity of the 810 MW tender floated by RRVUNL in December 2022, for developing the project RRVUNL’s 2000 MW Ultra Mega Solar Park at Pugal Tehsil, Bikaner District, Rajasthan.', 'The Letter of Intent for this project has been issued by RRVUNL.', 'The land for the project and the power evacuation system connected to STU will be offered by RVUNL, paving the way for completion of the project at shorter period.', 'This is the largest Renewable project to be developed by the company.', 'With this project, the capacity of power project in Rajasthan will be 1.36 GW including 1.1 GW of green power, bringing economies of scale and optimized fixed costs.', 'Considering the good Solar radiation at Rajasthan, the higher CUF for the project is possible and will generate green power of more than 50 Billion Units and offsets more than 50,000 tonnes of carbon dioxide emissions during the life of the project.']\n'''\nsentence = '''\nNLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).\n'''\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,\n    messages=[",
        "detail": "edictai_app.app.transcript.openai_keyword_extraction",
        "documentation": {}
    },
    {
        "label": "sentence",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keyword_extraction",
        "description": "edictai_app.app.transcript.openai_keyword_extraction",
        "peekOfCode": "sentence = '''\nNLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL).\n'''\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": '''",
        "detail": "edictai_app.app.transcript.openai_keyword_extraction",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.openai_keyword_extraction",
        "description": "edictai_app.app.transcript.openai_keyword_extraction",
        "peekOfCode": "response = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.5,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": '''\n            You will be provided with a block of text, and your task is to extract a list of keywords from it.\n            Note: Keywords extracted would be used as a query to search for images on search engines. Extract those keywords which are easy to represent visually.\n            '''",
        "detail": "edictai_app.app.transcript.openai_keyword_extraction",
        "documentation": {}
    },
    {
        "label": "chunks_list",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "chunks_list = []\nfrom Keyword_json import subject_json\nimport os\nimport openai\nopenai.organization = \"\"\nopenai.api_key = \"\"\nnews = '''\nThe Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023. The Prime Minister posted on X; “Congratulations to @sadhwani2005 on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023! His strategic brilliance and skills have left the world in awe and made the nation proud. May he keep inspiring the youth of our country with his exceptional achievements. Best wishes for his future endeavours.”\n'''\n# completion = openai.ChatCompletion.create(",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "openai.organization = \"\"\nopenai.api_key = \"\"\nnews = '''\nThe Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023. The Prime Minister posted on X; “Congratulations to @sadhwani2005 on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023! His strategic brilliance and skills have left the world in awe and made the nation proud. May he keep inspiring the youth of our country with his exceptional achievements. Best wishes for his future endeavours.”\n'''\n# completion = openai.ChatCompletion.create(\n#   model=\"gpt-3.5-turbo\",\n#   messages=[\n#     {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n#     {\"role\": \"user\", \"content\": '''",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "openai.api_key = \"\"\nnews = '''\nThe Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023. The Prime Minister posted on X; “Congratulations to @sadhwani2005 on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023! His strategic brilliance and skills have left the world in awe and made the nation proud. May he keep inspiring the youth of our country with his exceptional achievements. Best wishes for his future endeavours.”\n'''\n# completion = openai.ChatCompletion.create(\n#   model=\"gpt-3.5-turbo\",\n#   messages=[\n#     {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n#     {\"role\": \"user\", \"content\": '''\n#     Ensure that the script maintains an authentic and unbiased tone. Consider the video length to be 60-90 seconds. Our goal is to inform viewers about the official news from the government, and engage the viewers to see news in a visual format. ",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "news",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "news = '''\nThe Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023. The Prime Minister posted on X; “Congratulations to @sadhwani2005 on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023! His strategic brilliance and skills have left the world in awe and made the nation proud. May he keep inspiring the youth of our country with his exceptional achievements. Best wishes for his future endeavours.”\n'''\n# completion = openai.ChatCompletion.create(\n#   model=\"gpt-3.5-turbo\",\n#   messages=[\n#     {\"role\": \"system\", \"content\": \"I want you to act as a Newsreader. I will provide you with a news article and you will create a script for to make a video out of it.\"},\n#     {\"role\": \"user\", \"content\": '''\n#     Ensure that the script maintains an authentic and unbiased tone. Consider the video length to be 60-90 seconds. Our goal is to inform viewers about the official news from the government, and engage the viewers to see news in a visual format. \n#     Please break the script into meaningful chunks with independent meaning.",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "sentences = ['The Prime Minister, Shri Narendra Modi congratulated Raunak Sadhwani on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023.', 'The Prime Minister posted on X; “Congratulations to @sadhwani2005 on the remarkable victory at the FIDE World Junior Rapid Chess Championship 2023!', 'His strategic brilliance and skills have left the world in awe and made the nation proud.', 'May he keep inspiring the youth of our country with his exceptional achievements.', 'Best wishes for his future endeavors.”']\n# # Creating keywords for sentences\n# from keybert import KeyBERT\nfor sentence in sentences:\n#     kw_model = KeyBERT()\n#     extracted_keywords = kw_model.extract_keywords(sentence,keyphrase_ngram_range=(1, 1))\n    keywords = []\n#     if len(extracted_keywords)>3:\n#         extracted_keywords = extracted_keywords[0:3]\n#     for key in extracted_keywords: ",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "speech_config",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "speech_config = speechsdk.SpeechConfig(subscription=\"\", region=\"\")\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_config.speech_synthesis_voice_name='en-US-JennyNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\ncombined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "audio_config",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\nspeech_config.speech_synthesis_voice_name='en-US-JennyNeural'\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\ncombined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "speech_synthesizer",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\ncombined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "combined_chunks",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "combined_chunks = \" \".join(sentences)\nspeech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_result",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "speech_synthesis_result = speech_synthesizer.speak_text_async(combined_chunks).get()\nspeech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "speech_synthesis_stream",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "speech_synthesis_stream = speechsdk.AudioDataStream(speech_synthesis_result)\nspeech_synthesis_stream.save_to_wav_file(\"chunk.wav\")\nif speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n    print(\"Speech synthesized for text [{}]\".format(news))\nelif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n    cancellation_details = speech_synthesis_result.cancellation_details\n    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n        if cancellation_details.error_details:\n            print(\"Error details: {}\".format(cancellation_details.error_details))",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "model_size",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "model_size = \"small\"\nmodel = WhisperModel(model_size)\nsegments, info = model.transcribe(\"chunk.wav\", word_timestamps=True)\nsegments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "model = WhisperModel(model_size)\nsegments, info = model.transcribe(\"chunk.wav\", word_timestamps=True)\nsegments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word,'start':word.start,'end':word.end})",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "segments",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "segments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word,'start':word.start,'end':word.end})\nprint(wordlevel_info)\n# JSON Converter ",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "wordlevel_info",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "wordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word,'start':word.start,'end':word.end})\nprint(wordlevel_info)\n# JSON Converter \n# output = []\n# item={'chunk':chunks_list[0]['sentence'],'start_time':wordlevel_info[0]['start'],'end_time':wordlevel_info[0+len(chunks_list[0]['sentence'].split())]['end'],'keywords':chunks_list[0]['keywords']}\n# print(item)\n# # print(wordlevel_info[len(chunks_list[0]['sentence'])]['end'])",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "output = []\ncurrentStartWord = 0\nfor i in chunks_list:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            j_list = j.split()\n            print()\n            print(j_list)\n            if (wordlevel_info[k]['word'].strip().lower() == j_list[0].strip().lower()):",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "currentStartWord",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.test",
        "description": "edictai_app.app.transcript.test",
        "peekOfCode": "currentStartWord = 0\nfor i in chunks_list:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            j_list = j.split()\n            print()\n            print(j_list)\n            if (wordlevel_info[k]['word'].strip().lower() == j_list[0].strip().lower()):\n                key_phrase_start_time = wordlevel_info[k]['start']",
        "detail": "edictai_app.app.transcript.test",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.transcript",
        "description": "edictai_app.app.transcript.transcript",
        "peekOfCode": "text = \"<m>NLC India Ltd secures 810 MW Grid Connected Solar Photovoltaic Power Project in Rajasthan. <m>NLC India Limited, a Navratna Central Public Sector Undertaking (CPSE) under the Ministry of Coal has won 810 MW Solar PV project capacity from Rajasthan Rajya Vidyut Nigam Limited (RRVUNL). <m>NLCIL has successfully garnered the entire capacity of the 810 MW tender floated by RRVUNL in December 2022, for developing the project at RRVUNL's 2000 MW Ultra Mega Solar Park. <m>The project will be located in Pugal Tehsil, Bikaner District, Rajasthan. <m>The Letter of Intent for this project has been issued by RRVUNL. <m>This achievement marks a significant step forward in NLCIL's commitment to clean and sustainable energy solutions.\"\nsentences = re.split(r\"<m>|\\\\n|\\n|</m>\",text)\nsentences = [sentence.strip() for sentence in sentences]\nsentences = [sentence for sentence in sentences if sentence]\nprint(sentences)",
        "detail": "edictai_app.app.transcript.transcript",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.transcript",
        "description": "edictai_app.app.transcript.transcript",
        "peekOfCode": "sentences = re.split(r\"<m>|\\\\n|\\n|</m>\",text)\nsentences = [sentence.strip() for sentence in sentences]\nsentences = [sentence for sentence in sentences if sentence]\nprint(sentences)",
        "detail": "edictai_app.app.transcript.transcript",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.transcript",
        "description": "edictai_app.app.transcript.transcript",
        "peekOfCode": "sentences = [sentence.strip() for sentence in sentences]\nsentences = [sentence for sentence in sentences if sentence]\nprint(sentences)",
        "detail": "edictai_app.app.transcript.transcript",
        "documentation": {}
    },
    {
        "label": "sentences",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.transcript",
        "description": "edictai_app.app.transcript.transcript",
        "peekOfCode": "sentences = [sentence for sentence in sentences if sentence]\nprint(sentences)",
        "detail": "edictai_app.app.transcript.transcript",
        "documentation": {}
    },
    {
        "label": "model_size",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.whisper_loda",
        "description": "edictai_app.app.transcript.whisper_loda",
        "peekOfCode": "model_size = \"medium\"\nmodel = WhisperModel(model_size)\nsegments, info = model.transcribe(\"audios/chunk.wav\", word_timestamps=True)\nsegments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:",
        "detail": "edictai_app.app.transcript.whisper_loda",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.whisper_loda",
        "description": "edictai_app.app.transcript.whisper_loda",
        "peekOfCode": "model = WhisperModel(model_size)\nsegments, info = model.transcribe(\"audios/chunk.wav\", word_timestamps=True)\nsegments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word,'start':word.start,'end':word.end})",
        "detail": "edictai_app.app.transcript.whisper_loda",
        "documentation": {}
    },
    {
        "label": "segments",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.whisper_loda",
        "description": "edictai_app.app.transcript.whisper_loda",
        "peekOfCode": "segments = list(segments)\nfor segment in segments:\n    for word in segment.words:\n        print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\nwordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word,'start':word.start,'end':word.end})\nprint(wordlevel_info)",
        "detail": "edictai_app.app.transcript.whisper_loda",
        "documentation": {}
    },
    {
        "label": "wordlevel_info",
        "kind": 5,
        "importPath": "edictai_app.app.transcript.whisper_loda",
        "description": "edictai_app.app.transcript.whisper_loda",
        "peekOfCode": "wordlevel_info = []\nfor segment in segments:\n    for word in segment.words:\n      wordlevel_info.append({'word':word.word,'start':word.start,'end':word.end})\nprint(wordlevel_info)",
        "detail": "edictai_app.app.transcript.whisper_loda",
        "documentation": {}
    },
    {
        "label": "translate_chunk_gu",
        "kind": 2,
        "importPath": "edictai_app.app.translator.chunk_translator",
        "description": "edictai_app.app.translator.chunk_translator",
        "peekOfCode": "def translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"gu\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]\n        response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)\n        for i, translation in enumerate(response[0].translations):\n            print(f\"{target_languages[i]}: {translation.text}\")",
        "detail": "edictai_app.app.translator.chunk_translator",
        "documentation": {}
    },
    {
        "label": "key",
        "kind": 5,
        "importPath": "edictai_app.app.translator.chunk_translator",
        "description": "edictai_app.app.translator.chunk_translator",
        "peekOfCode": "key = \"\"\nendpoint = \"https://api.cognitive.microsofttranslator.com/\"\nregion = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"gu\"]",
        "detail": "edictai_app.app.translator.chunk_translator",
        "documentation": {}
    },
    {
        "label": "endpoint",
        "kind": 5,
        "importPath": "edictai_app.app.translator.chunk_translator",
        "description": "edictai_app.app.translator.chunk_translator",
        "peekOfCode": "endpoint = \"https://api.cognitive.microsofttranslator.com/\"\nregion = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"gu\"]\n        texty = chunk",
        "detail": "edictai_app.app.translator.chunk_translator",
        "documentation": {}
    },
    {
        "label": "region",
        "kind": 5,
        "importPath": "edictai_app.app.translator.chunk_translator",
        "description": "edictai_app.app.translator.chunk_translator",
        "peekOfCode": "region = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"gu\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]",
        "detail": "edictai_app.app.translator.chunk_translator",
        "documentation": {}
    },
    {
        "label": "credential",
        "kind": 5,
        "importPath": "edictai_app.app.translator.chunk_translator",
        "description": "edictai_app.app.translator.chunk_translator",
        "peekOfCode": "credential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"gu\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]\n        response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)",
        "detail": "edictai_app.app.translator.chunk_translator",
        "documentation": {}
    },
    {
        "label": "text_translator",
        "kind": 5,
        "importPath": "edictai_app.app.translator.chunk_translator",
        "description": "edictai_app.app.translator.chunk_translator",
        "peekOfCode": "text_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"gu\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]\n        response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)\n        for i, translation in enumerate(response[0].translations):",
        "detail": "edictai_app.app.translator.chunk_translator",
        "documentation": {}
    },
    {
        "label": "key",
        "kind": 5,
        "importPath": "edictai_app.app.translator.translate_1",
        "description": "edictai_app.app.translator.translate_1",
        "peekOfCode": "key = \"\"\nendpoint = \"https://api.cognitive.microsofttranslator.com/\"\nregion = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ntry:\n    source_language = \"en\"\n    target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n    texty = '''\n    Women MPs meet PM after passage of the Nari Shakti Vandan Adhiniyam Posted On: 22 SEP 2023 8:22AM by PIB Delhi Women Members of Parliament met Prime Minister to express their happiness over the passage of the historic Nari Shakti Vandan Adhiniyam last night. The Prime Minister posted on X : \"Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed. With the passage of the Nari Shakti Vandan Adhiniyam, India stands at the cusp of a brighter, more inclusive future with our Nari Shakti being at the core of this transformation.\" Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed.",
        "detail": "edictai_app.app.translator.translate_1",
        "documentation": {}
    },
    {
        "label": "endpoint",
        "kind": 5,
        "importPath": "edictai_app.app.translator.translate_1",
        "description": "edictai_app.app.translator.translate_1",
        "peekOfCode": "endpoint = \"https://api.cognitive.microsofttranslator.com/\"\nregion = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ntry:\n    source_language = \"en\"\n    target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n    texty = '''\n    Women MPs meet PM after passage of the Nari Shakti Vandan Adhiniyam Posted On: 22 SEP 2023 8:22AM by PIB Delhi Women Members of Parliament met Prime Minister to express their happiness over the passage of the historic Nari Shakti Vandan Adhiniyam last night. The Prime Minister posted on X : \"Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed. With the passage of the Nari Shakti Vandan Adhiniyam, India stands at the cusp of a brighter, more inclusive future with our Nari Shakti being at the core of this transformation.\" Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed.\n    '''",
        "detail": "edictai_app.app.translator.translate_1",
        "documentation": {}
    },
    {
        "label": "region",
        "kind": 5,
        "importPath": "edictai_app.app.translator.translate_1",
        "description": "edictai_app.app.translator.translate_1",
        "peekOfCode": "region = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ntry:\n    source_language = \"en\"\n    target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n    texty = '''\n    Women MPs meet PM after passage of the Nari Shakti Vandan Adhiniyam Posted On: 22 SEP 2023 8:22AM by PIB Delhi Women Members of Parliament met Prime Minister to express their happiness over the passage of the historic Nari Shakti Vandan Adhiniyam last night. The Prime Minister posted on X : \"Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed. With the passage of the Nari Shakti Vandan Adhiniyam, India stands at the cusp of a brighter, more inclusive future with our Nari Shakti being at the core of this transformation.\" Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed.\n    '''\n    input_text_elements = [InputTextItem(text=texty)]",
        "detail": "edictai_app.app.translator.translate_1",
        "documentation": {}
    },
    {
        "label": "credential",
        "kind": 5,
        "importPath": "edictai_app.app.translator.translate_1",
        "description": "edictai_app.app.translator.translate_1",
        "peekOfCode": "credential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ntry:\n    source_language = \"en\"\n    target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n    texty = '''\n    Women MPs meet PM after passage of the Nari Shakti Vandan Adhiniyam Posted On: 22 SEP 2023 8:22AM by PIB Delhi Women Members of Parliament met Prime Minister to express their happiness over the passage of the historic Nari Shakti Vandan Adhiniyam last night. The Prime Minister posted on X : \"Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed. With the passage of the Nari Shakti Vandan Adhiniyam, India stands at the cusp of a brighter, more inclusive future with our Nari Shakti being at the core of this transformation.\" Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed.\n    '''\n    input_text_elements = [InputTextItem(text=texty)]\n    response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)",
        "detail": "edictai_app.app.translator.translate_1",
        "documentation": {}
    },
    {
        "label": "text_translator",
        "kind": 5,
        "importPath": "edictai_app.app.translator.translate_1",
        "description": "edictai_app.app.translator.translate_1",
        "peekOfCode": "text_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ntry:\n    source_language = \"en\"\n    target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n    texty = '''\n    Women MPs meet PM after passage of the Nari Shakti Vandan Adhiniyam Posted On: 22 SEP 2023 8:22AM by PIB Delhi Women Members of Parliament met Prime Minister to express their happiness over the passage of the historic Nari Shakti Vandan Adhiniyam last night. The Prime Minister posted on X : \"Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed. With the passage of the Nari Shakti Vandan Adhiniyam, India stands at the cusp of a brighter, more inclusive future with our Nari Shakti being at the core of this transformation.\" Had the honor of meeting our dynamic women MPs who are absolutely thrilled at the passage of the Nari Shakti Vandan Adhiniyam. It is gladdening to see the torchbearers of change come together to celebrate the very legislation they have championed.\n    '''\n    input_text_elements = [InputTextItem(text=texty)]\n    response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)\n    for i, translation in enumerate(response[0].translations):",
        "detail": "edictai_app.app.translator.translate_1",
        "documentation": {}
    },
    {
        "label": "gemini",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def gemini(chunk_list):\n    genai.configure(api_key=\"AIzaSyBT1VMTnJFfXuifJJBtmzNfMVdrmdpECHc\")\n    model = genai.GenerativeModel('gemini-pro')\n    prompt = f\"\"\" \nTask:\nGiven a list of chunks, {chunk_list}, your task is to modify each chunk by wrapping the i.mportant words inside HTML tags. Use tags like <b></b>, <strong></strong>, <i></i>, <u></u. Provide the modified list of chunks as the output without any additional details. Make sure include every string inside the list in double quotes \"\".\n    \"\"\" \n    print(\"Processing\")\n    response = model.generate_content([prompt])\n    text = response.text",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "create_chunk_lists",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def create_chunk_lists(subtitle_data, chunk_limit=5):\n    chunk_lists = []\n    current_chunk_list = []\n    for chunk in subtitle_data:\n        current_chunk_list.append(chunk)\n        if len(current_chunk_list) == chunk_limit:\n            chunk_lists.append(current_chunk_list)\n            current_chunk_list = []\n    if current_chunk_list:\n        chunk_lists.append(current_chunk_list)",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "remove_file",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def remove_file(file_path):\n    try:\n        os.remove(file_path)\n        print(f\"File {file_path} successfully removed.\")\n    except FileNotFoundError:\n        print(f\"Error: The file {file_path} was not found.\")\n    except PermissionError:\n        print(f\"Error: Permission denied. Unable to remove {file_path}.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "runCommand",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def runCommand(command): \n    subprocess.run(command, shell=True)\ndef addSubtitles(video_path, subtitles):\n    command = f'''ffmpeg -i {video_path} -vf subtitles={subtitles} final_output.mp4'''\n    runCommand(command)\ndef extract_audio(video_path):\n    output_path = \"assets/input.wav\"\n    ffmpeg_command = [\n        'ffmpeg',\n        '-i', video_path,",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "addSubtitles",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def addSubtitles(video_path, subtitles):\n    command = f'''ffmpeg -i {video_path} -vf subtitles={subtitles} final_output.mp4'''\n    runCommand(command)\ndef extract_audio(video_path):\n    output_path = \"assets/input.wav\"\n    ffmpeg_command = [\n        'ffmpeg',\n        '-i', video_path,\n        '-vn',\n        '-acodec', 'pcm_s16le',",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "extract_audio",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def extract_audio(video_path):\n    output_path = \"assets/input.wav\"\n    ffmpeg_command = [\n        'ffmpeg',\n        '-i', video_path,\n        '-vn',\n        '-acodec', 'pcm_s16le',\n        '-ar', '44100',\n        '-ac', '1',\n        output_path",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "saveJson",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def saveJson(output, input):\n    with open(output, 'w') as json_file:\n        json.dump(input, json_file, indent=2)\n    print(f\"List saved to {output}\")\ndef text_transcription(audio_path):\n    model_size = \"small\"\n    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n    segments, info = model.transcribe(audio_path, word_timestamps=True)\n    segments = list(segments)  # The transcription will actually run here.\n    wordlevel_info = []",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "text_transcription",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def text_transcription(audio_path):\n    model_size = \"small\"\n    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n    segments, info = model.transcribe(audio_path, word_timestamps=True)\n    segments = list(segments)  # The transcription will actually run here.\n    wordlevel_info = []\n    for segment in segments:\n        for word in segment.words:\n            wordlevel_info.append({'word':word.word,'start':word.start,'end':word.end})\n    return wordlevel_info",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "convert_to_srt",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def convert_to_srt(subtitle_list, output_file):\n    srt_content = \"\"\n    for index, subtitle in enumerate(subtitle_list, start=1):\n        start_time = format_time(subtitle[\"start\"])\n        end_time = format_time(subtitle[\"end\"])\n        srt_content += f\"{index}\\n{start_time} --> {end_time}\\n{subtitle['chunk']}\\n\\n\"\n    with open(output_file, \"w\") as srt_file:\n        srt_file.write(srt_content)\ndef format_time(seconds):\n    hours, remainder = divmod(seconds, 3600)",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "format_time",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def format_time(seconds):\n    hours, remainder = divmod(seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    milliseconds = int((seconds % 1) * 1000)\n    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}\"\ndef wordToChunk(wordlevel_info):\n    def split_text_into_lines(data):\n        MaxChars = 20\n        MaxDuration = 1.5\n        MaxGap = 0.5",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "wordToChunk",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def wordToChunk(wordlevel_info):\n    def split_text_into_lines(data):\n        MaxChars = 20\n        MaxDuration = 1.5\n        MaxGap = 0.5\n        subtitles = []\n        line = []\n        line_duration = 0\n        line_chars = 0\n        for idx, word_data in enumerate(data):",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "addTranscription",
        "kind": 2,
        "importPath": "edictai_app.app.aadding_subtitle",
        "description": "edictai_app.app.aadding_subtitle",
        "peekOfCode": "def addTranscription(video_path):\n    # video_path = \"subtle.mp4\"\n    extract_audio(video_path)\n    words = text_transcription(\"assets/input.wav\")\n    chunks = wordToChunk(words)\n    chunk_lists = create_chunk_lists(chunks)\n    chunks_modified = []\n    for chunk_list in chunk_lists:\n        chunks = gemini(chunk_list)\n        newlist = ast.literal_eval(chunks)",
        "detail": "edictai_app.app.aadding_subtitle",
        "documentation": {}
    },
    {
        "label": "get_caption",
        "kind": 2,
        "importPath": "edictai_app.app.caption",
        "description": "edictai_app.app.caption",
        "peekOfCode": "def get_caption(img_path):\n    img = PIL.Image.open(img_path)\n    genai.configure(api_key=\"AIzaSyCs8uC60b6p7j4OCRGSNpXnZ7rW2fHP4DU\")\n    # Set up the model\n    generation_config = {\n        \"temperature\": 0.4,\n        \"top_p\": 1,\n        \"top_k\": 32,\n        \"max_output_tokens\": 4096,\n    }",
        "detail": "edictai_app.app.caption",
        "documentation": {}
    },
    {
        "label": "translate_chunk_gu",
        "kind": 2,
        "importPath": "edictai_app.app.chunk_translator",
        "description": "edictai_app.app.chunk_translator",
        "peekOfCode": "def translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"mr\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]\n        response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)\n        for i, translation in enumerate(response[0].translations):\n            print(f\"{target_languages[i]}: {translation.text}\")",
        "detail": "edictai_app.app.chunk_translator",
        "documentation": {}
    },
    {
        "label": "key",
        "kind": 5,
        "importPath": "edictai_app.app.chunk_translator",
        "description": "edictai_app.app.chunk_translator",
        "peekOfCode": "key = chunk_translator_key\nendpoint = \"https://api.cognitive.microsofttranslator.com/\"\nregion = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"mr\"]",
        "detail": "edictai_app.app.chunk_translator",
        "documentation": {}
    },
    {
        "label": "endpoint",
        "kind": 5,
        "importPath": "edictai_app.app.chunk_translator",
        "description": "edictai_app.app.chunk_translator",
        "peekOfCode": "endpoint = \"https://api.cognitive.microsofttranslator.com/\"\nregion = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"mr\"]\n        texty = chunk",
        "detail": "edictai_app.app.chunk_translator",
        "documentation": {}
    },
    {
        "label": "region",
        "kind": 5,
        "importPath": "edictai_app.app.chunk_translator",
        "description": "edictai_app.app.chunk_translator",
        "peekOfCode": "region = \"centralindia\"\ncredential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"mr\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]",
        "detail": "edictai_app.app.chunk_translator",
        "documentation": {}
    },
    {
        "label": "credential",
        "kind": 5,
        "importPath": "edictai_app.app.chunk_translator",
        "description": "edictai_app.app.chunk_translator",
        "peekOfCode": "credential = TranslatorCredential(key, region)\ntext_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"mr\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]\n        response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)",
        "detail": "edictai_app.app.chunk_translator",
        "documentation": {}
    },
    {
        "label": "text_translator",
        "kind": 5,
        "importPath": "edictai_app.app.chunk_translator",
        "description": "edictai_app.app.chunk_translator",
        "peekOfCode": "text_translator = TextTranslationClient(endpoint=endpoint, credential=credential)\ndef translate_chunk_gu(chunk):\n    try:\n        source_language = \"en\"\n        # target_languages = [\"hi-in\", \"ur\", \"pa\", \"gu\", \"mr\", \"kn\", \"ml\", \"ta\", \"or\", \"bn\", \"as\"]\n        target_languages = [\"mr\"]\n        texty = chunk\n        input_text_elements = [InputTextItem(text=texty)]\n        response = text_translator.translate(content=input_text_elements, to=target_languages, from_parameter=source_language)\n        for i, translation in enumerate(response[0].translations):",
        "detail": "edictai_app.app.chunk_translator",
        "documentation": {}
    },
    {
        "label": "scrap_content",
        "kind": 2,
        "importPath": "edictai_app.app.content_scraper",
        "description": "edictai_app.app.content_scraper",
        "peekOfCode": "def scrap_content(url):\n    response = requests.get(url)\n    print(\"url from scrpe content\",url)\n    if response.status_code == 200:\n        soup = BeautifulSoup(response.text, 'html.parser')\n        content_div = soup.find('div', class_='innner-page-main-about-us-content-right-part')\n        # print(content_div)\n        ministry_name = soup.find('div', class_='MinistryNameSubhead text-center').text.strip()\n        title = soup.find('div', class_='text-center').text.strip()\n        posted_on = soup.find('div', class_='ReleaseDateSubHeaddateTime text-center pt20').text.strip()",
        "detail": "edictai_app.app.content_scraper",
        "documentation": {}
    },
    {
        "label": "new_chunk_creator",
        "kind": 2,
        "importPath": "edictai_app.app.creating_chunks",
        "description": "edictai_app.app.creating_chunks",
        "peekOfCode": "def new_chunk_creator(text):\n    text=text.replace('*',\"\")\n    sentences = re.split(r\"<m>|\\\\n|\\n|</m>\",text)\n    # sentences=[sentence.split(\"/n\") for sentence in sentences]\n    sentences = [sentence.strip() for sentence in sentences]\n    sentences = [sentence for sentence in sentences if sentence]\n    return (sentences)",
        "detail": "edictai_app.app.creating_chunks",
        "documentation": {}
    },
    {
        "label": "generate_script",
        "kind": 2,
        "importPath": "edictai_app.app.ganerate_script",
        "description": "edictai_app.app.ganerate_script",
        "peekOfCode": "def generate_script(user_input):\n    # Ask ChatGPT to generate a script in JSON format\n    print(\"Sahi call\")\n    print(user_input)\n    shorts_prompt = f\"\"\"Imagine yourself as a news anchor, ready to captivate your audience with an engaging video script.  You can compress script so that it can be covered in 60-90 seconds.\n    Script is: {user_input}.\nBegin with a warm greeting and smoothly transition into highlighting the most significant and impactful points from the news article.\nEnsure that the script maintains an authentic and unbiased tone. Conclude the script by hinting at potential future developments, all within a video length of 60-90 seconds.\nRemember, your goal is to inform, inspire, and engage your viewers. Make it captivating and creative while staying true to the news story.\n\"\"\"",
        "detail": "edictai_app.app.ganerate_script",
        "documentation": {}
    },
    {
        "label": "news",
        "kind": 5,
        "importPath": "edictai_app.app.ganerate_script",
        "description": "edictai_app.app.ganerate_script",
        "peekOfCode": "news = '''\nPM addresses Kaushal Dikshnat Samaroh 2023 via video message\n“Kaushal Dikshnat Samaroh reflects the priorities of today's India”\n“Country develops more with stronger youth power thereby doing justice to nation’s resources”\n“Today, the whole world is of the belief that this century is going to be India's century”\n“Our government understood the importance of skill and created a separate ministry for it, allocated separate budget”\n“Important for industry, research and skill development institutions to be in tune with present times”\n“Scope of skill development is continuously increasing in India. We are not limited to just mechanics, engineers, technology or any other service”\n“Unemployment rate in India is at its lowest level in 6 years”\n“IMF is confident of India becoming the top three economies of the world in the next 3-4 years”",
        "detail": "edictai_app.app.ganerate_script",
        "documentation": {}
    },
    {
        "label": "generate_image",
        "kind": 2,
        "importPath": "edictai_app.app.generateImage",
        "description": "edictai_app.app.generateImage",
        "peekOfCode": "def generate_image(query,chunk_number):\n    client = OpenAI(\n        organization=generate_script_openai_organization,\n        api_key=generate_script_openai_api_key,\n    )\n    # Create the image using OpenAI API\n    response = client.images.generate(\n        model=\"dall-e-2\",\n        prompt=f\"{query}\",\n        size=\"1024x1024\",",
        "detail": "edictai_app.app.generateImage",
        "documentation": {}
    },
    {
        "label": "download_file",
        "kind": 2,
        "importPath": "edictai_app.app.img_search",
        "description": "edictai_app.app.img_search",
        "peekOfCode": "def download_file(url, output_directory, custom_filename):\n    try:\n        if not os.path.exists(output_directory):\n            os.makedirs(output_directory, exist_ok=True)\n        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n        response = requests.get(url, stream=True,headers=headers)\n        if response.status_code == 200:\n            parsed_url = urlparse(url)\n            path = parsed_url.path\n            filename = os.path.basename(path)",
        "detail": "edictai_app.app.img_search",
        "documentation": {}
    },
    {
        "label": "google_image_search_api",
        "kind": 2,
        "importPath": "edictai_app.app.img_search",
        "description": "edictai_app.app.img_search",
        "peekOfCode": "def google_image_search_api(query, chunk_number, limit=3):\n    # Load credentials from config.json\n    credentials_file_path = 'config.json'  # Change this path based on your actual credentials file\n    with open(credentials_file_path, 'r') as c:\n        credentials = json.load(c)\n    directory = 'images/'\n    filename = f'chunk_{chunk_number}'\n    api_url = \"https://www.googleapis.com/customsearch/v1\"\n    params = {\n        'key': credentials['google_search_api_key'],",
        "detail": "edictai_app.app.img_search",
        "documentation": {}
    },
    {
        "label": "rename_images",
        "kind": 2,
        "importPath": "edictai_app.app.img_search",
        "description": "edictai_app.app.img_search",
        "peekOfCode": "def rename_images():\n    # Path to the folder containing the image files\n    folder_path = \"images\"\n    # Get a list of all image files in the folder\n    image_files = [f for f in os.listdir(folder_path) if f.endswith(\".jpg\")]\n    # Loop through each image file and rename it\n    for i, old_name in enumerate(image_files):\n        new_name = f\"coindesk_multiple_{i}.jpg\"\n        old_path = os.path.join(folder_path, old_name)\n        new_path = os.path.join(folder_path, new_name)",
        "detail": "edictai_app.app.img_search",
        "documentation": {}
    },
    {
        "label": "multiple_image_search_google",
        "kind": 2,
        "importPath": "edictai_app.app.img_search",
        "description": "edictai_app.app.img_search",
        "peekOfCode": "def multiple_image_search_google(query,chunk_number, limit=7, download_limit=1, url=None):\n  if url is not None:\n        directory = 'images/'\n        filename = f'chunk_{chunk_number}'\n        file_path_new = download_file(url, directory, filename)\n        return file_path_new\n  api_url = \"https://www.googleapis.com/customsearch/v1\"\n  credentials_file_path = 'config.json'  # Change this path based on your actual credentials file\n  with open(credentials_file_path, 'r') as c:\n        credentials = json.load(c)",
        "detail": "edictai_app.app.img_search",
        "documentation": {}
    },
    {
        "label": "authenticate_client",
        "kind": 2,
        "importPath": "edictai_app.app.keywords_extraction",
        "description": "edictai_app.app.keywords_extraction",
        "peekOfCode": "def authenticate_client(key, endpoint):\n    ta_credential = AzureKeyCredential(key)\n    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=ta_credential)\n    return text_analytics_client\ndef keywords_extraction(sentence, key=azure_language_resource_api_key, endpoint=azure_language_resource_endpoint):\n    client = authenticate_client(key, endpoint)\n    try:\n        documents = [sentence]\n        response = client.extract_key_phrases(documents=documents)[0]\n        if not response.is_error:",
        "detail": "edictai_app.app.keywords_extraction",
        "documentation": {}
    },
    {
        "label": "keywords_extraction",
        "kind": 2,
        "importPath": "edictai_app.app.keywords_extraction",
        "description": "edictai_app.app.keywords_extraction",
        "peekOfCode": "def keywords_extraction(sentence, key=azure_language_resource_api_key, endpoint=azure_language_resource_endpoint):\n    client = authenticate_client(key, endpoint)\n    try:\n        documents = [sentence]\n        response = client.extract_key_phrases(documents=documents)[0]\n        if not response.is_error:\n            # Return the top key phrase\n            return response.key_phrases[0] if response.key_phrases else None\n        else:\n            print(response.id, response.error)",
        "detail": "edictai_app.app.keywords_extraction",
        "documentation": {}
    },
    {
        "label": "get_keyword",
        "kind": 2,
        "importPath": "edictai_app.app.keywords_extraction",
        "description": "edictai_app.app.keywords_extraction",
        "peekOfCode": "def get_keyword(chunk, aim):\n    # Ask ChatGPT to generate a script in JSON format\n    shorts_prompt = f\"\"\"below are the script chunk of a video, The context and aim of video is {aim}.\n        You have to provide us keywords which can be important entity corresponding to the chunk keeping strictly context in mind.\n        Also, keywords can be human entity, place names, things, overall it should a visual description of chunk which can help us to get a releavant image for that chunk and complete video in 3-4 words.       \n        Chunks is:{chunk}\n    \"\"\"\n    client = OpenAI(\n        api_key=\"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\", \n    )",
        "detail": "edictai_app.app.keywords_extraction",
        "documentation": {}
    },
    {
        "label": "transcribe_audio",
        "kind": 2,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "def transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "abstract_summary_extraction",
        "kind": 2,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "def abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a highly skilled AI trained in language comprehension and summarization. I would like you to read the following text and summarize it into a concise abstract paragraph. Aim to retain the most important points, providing a coherent and readable summary that could help a person understand the main points of the discussion without needing to read the entire text. Please avoid unnecessary details or tangential points.\"\n            },\n            {",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "key_points_extraction",
        "kind": 2,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "def key_points_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a proficient AI with a specialty in distilling information into key points. Based on the following text, identify and list the main points that were discussed or brought up. These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. Your goal is to provide a list that someone could read to quickly understand what was talked about.\"\n            },\n            {",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "action_item_extraction",
        "kind": 2,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "def action_item_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are an AI expert in analyzing conversations and extracting action items. Please review the text and identify any tasks, assignments, or actions that were agreed upon or mentioned as needing to be done. These could be tasks assigned to specific individuals, or general actions that the group has decided to take. Please list these action items clearly and concisely.\"\n            },\n            {",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "sentiment_analysis",
        "kind": 2,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "def sentiment_analysis(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"As an AI with expertise in language and emotion analysis, your task is to analyze the sentiment of the following text. Please consider the overall tone of the discussion, the emotion conveyed by the language used, and the context in which words and phrases are used. Indicate whether the sentiment is generally positive, negative, or neutral, and provide brief explanations for your analysis where possible.\"\n            },\n            {",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "meeting_minutes",
        "kind": 2,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "def meeting_minutes(transcription):\n    abstract_summary = abstract_summary_extraction(transcription)\n    key_points = key_points_extraction(transcription)\n    action_items = action_item_extraction(transcription)\n    sentiment = sentiment_analysis(transcription)\n    return {\n        'abstract_summary': abstract_summary,\n        'key_points': key_points,\n        'action_items': action_items,\n        'sentiment': sentiment",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "audio_file_path",
        "kind": 5,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "audio_file_path = \"blob_images/Shorts.mp4\"\nopenai.organization = generate_script_openai_organization\nopenai.api_key = generate_script_openai_api_key\ndef transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "openai.organization = generate_script_openai_organization\nopenai.api_key = generate_script_openai_api_key\ndef transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "openai.api_key = generate_script_openai_api_key\ndef transcribe_audio(audio_file_path):\n    with open(audio_file_path, 'rb') as audio_file:\n        transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcription['text']\ndef abstract_summary_extraction(transcription):\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "news",
        "kind": 5,
        "importPath": "edictai_app.app.keyword_extraction_openai",
        "description": "edictai_app.app.keyword_extraction_openai",
        "peekOfCode": "news = '''\nPM addresses Kaushal Dikshnat Samaroh 2023 via video message\n“Kaushal Dikshnat Samaroh reflects the priorities of today's India”\n“Country develops more with stronger youth power thereby doing justice to nation’s resources”\n“Today, the whole world is of the belief that this century is going to be India's century”\n“Our government understood the importance of skill and created a separate ministry for it, allocated separate budget”\n“Important for industry, research and skill development institutions to be in tune with present times”\n“Scope of skill development is continuously increasing in India. We are not limited to just mechanics, engineers, technology or any other service”\n“Unemployment rate in India is at its lowest level in 6 years”\n“IMF is confident of India becoming the top three economies of the world in the next 3-4 years”",
        "detail": "edictai_app.app.keyword_extraction_openai",
        "documentation": {}
    },
    {
        "label": "rename_file",
        "kind": 2,
        "importPath": "edictai_app.app.new_final",
        "description": "edictai_app.app.new_final",
        "peekOfCode": "def rename_file(original_path, new_name):\n    try:\n        print(\"entered renaming\")\n        directory, original_name = os.path.split(original_path)\n        new_path = os.path.join(directory, new_name)\n        if os.path.exists(new_path):\n            os.remove(new_path)\n        os.rename(original_path, new_path)\n        print(f\"File successfully renamed from {original_path} to {new_path}\")\n    except FileNotFoundError:",
        "detail": "edictai_app.app.new_final",
        "documentation": {}
    },
    {
        "label": "edict_video",
        "kind": 2,
        "importPath": "edictai_app.app.new_final",
        "description": "edictai_app.app.new_final",
        "peekOfCode": "def edict_video(url,content_passed):\n    # Web Scraping\n    # data = {\"ministry name\": ministry_name,\n    #         \"title\":title,\n    #         \"postedon\": posted_on,\n    #         \"content\" : content,\n    #         \"releaseid\":release_id,\n    #         \"visitorcount\":visitor_count,\n    #         \"releaseLang\":release_lang,\n    #         \"links_with_text\":links_with_text,",
        "detail": "edictai_app.app.new_final",
        "documentation": {}
    },
    {
        "label": "yt_upload_video",
        "kind": 2,
        "importPath": "edictai_app.app.run_upload_video",
        "description": "edictai_app.app.run_upload_video",
        "peekOfCode": "def yt_upload_video(filename, title, description):\n    # topic = \"\"\n    # keywords = get_top_keywords(topic)\n    new_description = description.replace('\"', '')\n    working_directory = os.getcwd().replace('\\\\', '/')\n    print(working_directory)\n    os.system(f''' python3 {working_directory}/edictai/app/upload_video.py --file=\"{working_directory}/videos/{filename}\" --title=\"{title}\" --description=\"{new_description}\" --keywords=\"Edict.AI\" --category=\"22\" --privacyStatus=\"unlisted\" ''')\nyt_upload_video(\"output_video.mp4\", \" ka title\", \"description ka \")",
        "detail": "edictai_app.app.run_upload_video",
        "documentation": {}
    },
    {
        "label": "coindesk_single",
        "kind": 2,
        "importPath": "edictai_app.app.scraper",
        "description": "edictai_app.app.scraper",
        "peekOfCode": "def coindesk_single(url):\n    response = requests.get(url)\n    if response.status_code == 200:\n        soup = BeautifulSoup(response.content, 'html.parser')\n        headline = soup.find('div', class_='at-headline').find('h1').get_text().strip()\n        subheadline = soup.find('div', class_='at-subheadline').find('h2').get_text().strip()\n        content_div = soup.find('div', class_='at-content-wrapper')\n        content = ' '.join([p.get_text().strip() for p in content_div.find_all('p')])\n    else:\n        print(\"Request failed with status code:\", response.status_code)",
        "detail": "edictai_app.app.scraper",
        "documentation": {}
    },
    {
        "label": "the_hindu_single",
        "kind": 2,
        "importPath": "edictai_app.app.scraper",
        "description": "edictai_app.app.scraper",
        "peekOfCode": "def the_hindu_single(url):\n    getData = requests.get(url)\n    getHtml = BeautifulSoup(getData.content, \"html.parser\")\n    # scraping the title of article\n    title = getHtml.find(\"h1\", {\"class\" :\"title\"}).getText().replace(\"\\n\", \"\").replace(\"\\\\\", \"\")\n    subtitle = getHtml.find('h3', {\"class\" : \"sub-title\"}).getText().replace(\"\\n\", \"\").replace(\"\\\\\", \"\")\n    scraped_content = \"\"\n    div = getHtml.find(\"div\", {\"class\" : \"articlebodycontent col-xl-9 col-lg-12 col-md-12 col-sm-12 col-12\"})\n    # (Byfind.XPATH,'//div[@class=\"articlebodycontent col-xl-9 col-lg-12 col-md-12 col-sm-12 col-12\"]/p')\n    p_tags = div.findAll(\"p\")",
        "detail": "edictai_app.app.scraper",
        "documentation": {}
    },
    {
        "label": "ndtv_single",
        "kind": 2,
        "importPath": "edictai_app.app.scraper",
        "description": "edictai_app.app.scraper",
        "peekOfCode": "def ndtv_single(url):\n    getData = requests.get(url)\n    getHtml = BeautifulSoup(getData.content, \"html.parser\")\n    # scraping the title of article\n    title = getHtml.find(\"h1\", {\"class\" :\"sp-ttl\"}).getText()\n    subtitle =\"\"\n    try:\n        subtitle = getHtml.find('h3', {\"class\" : \"sp-descp\"}).getText()\n    except Exception as e:\n        pass",
        "detail": "edictai_app.app.scraper",
        "documentation": {}
    },
    {
        "label": "url_select",
        "kind": 2,
        "importPath": "edictai_app.app.scraper",
        "description": "edictai_app.app.scraper",
        "peekOfCode": "def url_select(url):\n    if(\"https://www.coindesk.com/\" in url):\n        data = coindesk_single(url)\n    elif(\"https://www.ndtv.com/\" in url):\n        data = ndtv_single(url)\n    elif(\"https://www.thehindu.com/\" in url):\n        data = the_hindu_single(url)\n    return(data)\n# url = input(\"Enter URL : \")\n# data = url_select(url)",
        "detail": "edictai_app.app.scraper",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 2,
        "importPath": "edictai_app.app.semantic_search",
        "description": "edictai_app.app.semantic_search",
        "peekOfCode": "def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\ndef create_final_sentence(obj):\n    # Combine title, tags, and description to create the final sentence\n    final_sentence_parts = []\n    if 'custom_properties' in obj and isinstance(obj['custom_properties'], dict):\n        custom_properties = obj['custom_properties']\n        if 'title' in custom_properties:\n            final_sentence_parts.append(custom_properties['title'])",
        "detail": "edictai_app.app.semantic_search",
        "documentation": {}
    },
    {
        "label": "create_final_sentence",
        "kind": 2,
        "importPath": "edictai_app.app.semantic_search",
        "description": "edictai_app.app.semantic_search",
        "peekOfCode": "def create_final_sentence(obj):\n    # Combine title, tags, and description to create the final sentence\n    final_sentence_parts = []\n    if 'custom_properties' in obj and isinstance(obj['custom_properties'], dict):\n        custom_properties = obj['custom_properties']\n        if 'title' in custom_properties:\n            final_sentence_parts.append(custom_properties['title'])\n        if 'tags' in custom_properties:\n            if isinstance(custom_properties['tags'], list):\n                final_sentence_parts.extend(custom_properties['tags'])",
        "detail": "edictai_app.app.semantic_search",
        "documentation": {}
    },
    {
        "label": "find_max_similarity_index",
        "kind": 2,
        "importPath": "edictai_app.app.semantic_search",
        "description": "edictai_app.app.semantic_search",
        "peekOfCode": "def find_max_similarity_index(query_sentence, sentences):\n    output = query({\n        \"inputs\": {\n            \"source_sentence\": query_sentence,\n            \"sentences\": sentences\n        },\n    })\n    # Enumerate to keep track of original indices\n    similarity_with_indices = list(enumerate(output))\n    # Sort based on similarity score in descending order",
        "detail": "edictai_app.app.semantic_search",
        "documentation": {}
    },
    {
        "label": "semantic_search",
        "kind": 2,
        "importPath": "edictai_app.app.semantic_search",
        "description": "edictai_app.app.semantic_search",
        "peekOfCode": "def semantic_search(api_jsons, query2):\n    print(len(api_jsons))\n    final_sentences = []\n    print(final_sentences)\n    filtered_api_jsons = []  # Create a new list for filtered objects\n    for obj in api_jsons:\n        url = obj.get('url', '')\n        # Check if the length of the URL is between 150 and 200\n        if len(url) <= 200:\n            final_sentences.append(create_final_sentence(obj))",
        "detail": "edictai_app.app.semantic_search",
        "documentation": {}
    },
    {
        "label": "semantic_search_web",
        "kind": 2,
        "importPath": "edictai_app.app.semantic_search",
        "description": "edictai_app.app.semantic_search",
        "peekOfCode": "def semantic_search_web(api_jsons, query2):\n    print(len(api_jsons))\n    final_sentences = []\n    print(final_sentences)\n    filtered_api_jsons = []  # Create a new list for filtered objects``\n    max_similarity_index = find_max_similarity_index(query2, final_sentences)\n    # print(\"filtered_api_jsons\")\n    # print(len(filtered_api_jsons))\n    # ans = []\n    # for i in max_similarity_index:",
        "detail": "edictai_app.app.semantic_search",
        "documentation": {}
    },
    {
        "label": "API_URL",
        "kind": 5,
        "importPath": "edictai_app.app.semantic_search",
        "description": "edictai_app.app.semantic_search",
        "peekOfCode": "API_URL = \"https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\"\nheaders = {\"Authorization\": \"Bearer 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\"}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\ndef create_final_sentence(obj):\n    # Combine title, tags, and description to create the final sentence\n    final_sentence_parts = []\n    if 'custom_properties' in obj and isinstance(obj['custom_properties'], dict):\n        custom_properties = obj['custom_properties']",
        "detail": "edictai_app.app.semantic_search",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "edictai_app.app.semantic_search",
        "description": "edictai_app.app.semantic_search",
        "peekOfCode": "headers = {\"Authorization\": \"Bearer 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\"}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\ndef create_final_sentence(obj):\n    # Combine title, tags, and description to create the final sentence\n    final_sentence_parts = []\n    if 'custom_properties' in obj and isinstance(obj['custom_properties'], dict):\n        custom_properties = obj['custom_properties']\n        if 'title' in custom_properties:",
        "detail": "edictai_app.app.semantic_search",
        "documentation": {}
    },
    {
        "label": "search_videos",
        "kind": 2,
        "importPath": "edictai_app.app.seo_description",
        "description": "edictai_app.app.seo_description",
        "peekOfCode": "def search_videos(query, max_results=10):\n    api_key = \"AIzaSyChDd8Vx0INbI9A9NPmxeuhdSTuV1jCpfg\"\n    url = f\"https://www.googleapis.com/youtube/v3/search?part=snippet&q={query}&type=video&order=relevance&maxResults={max_results}&key={api_key}\"\n    response = requests.get(url)\n    if response.status_code == 200:\n        data = response.json()\n        videos = []\n        for item in data[\"items\"]:\n            title = item[\"snippet\"][\"title\"]\n            videos.append({\"title\": title})",
        "detail": "edictai_app.app.seo_description",
        "documentation": {}
    },
    {
        "label": "get_top_keywords",
        "kind": 2,
        "importPath": "edictai_app.app.seo_description",
        "description": "edictai_app.app.seo_description",
        "peekOfCode": "def get_top_keywords(topic, limit=10):\n    videos = search_videos(topic)\n    if not videos:\n        return []\n    keywords = []\n    for video in videos:\n        title = video[\"title\"]\n        words = title.split(\" \")\n        keywords.extend(words)\n    return keywords",
        "detail": "edictai_app.app.seo_description",
        "documentation": {}
    },
    {
        "label": "inputList1",
        "kind": 5,
        "importPath": "edictai_app.app.test",
        "description": "edictai_app.app.test",
        "peekOfCode": "inputList1 = [\n    {'word': ' Good', 'start': 0.0, 'end': 0.34},\n    {'word': ' morning', 'start': 0.34, 'end': 0.82},\n    {'word': ' everyone', 'start': 0.98, 'end': 1.56},\n    {'word': \" I'm\", 'start': 2.64, 'end': 2.78},\n    {'word': ' here', 'start': 2.78, 'end': 3.0},\n    {'word': ' today', 'start': 3.0, 'end': 3.38},\n    {'word': ' to', 'start': 3.38, 'end': 3.68},\n    {'word': ' talk', 'start': 3.68, 'end': 3.94},\n    {'word': ' about', 'start': 3.94, 'end': 4.12},",
        "detail": "edictai_app.app.test",
        "documentation": {}
    },
    {
        "label": "inputList2",
        "kind": 5,
        "importPath": "edictai_app.app.test",
        "description": "edictai_app.app.test",
        "peekOfCode": "inputList2 = [\n    {'sentence': \"Good morning everyone\", 'keywords': ['morning']},\n    {'sentence':  \"I'm here today to talk about the\", 'keywords': ['talk', 'about']},\n    {\"sentence\": \"historic passage of the\", \"keywords\": [\"historic\"]},\n    {'sentence': \"Nari Shakti Vandana\", 'keywords': ['Nari']}\n]\noutput = []\n# item={'chunk':inputList2[0]['sentence'],'start_time':inputList1[0]['start'],'end_time':inputList1[0+len(inputList2[0]['sentence'].split())]['end'],'keywords':inputList2[0]['keywords']}\n# print(item)\n# # print(inputList1[len(inputList2[0]['sentence'])]['end'])",
        "detail": "edictai_app.app.test",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "edictai_app.app.test",
        "description": "edictai_app.app.test",
        "peekOfCode": "output = []\n# item={'chunk':inputList2[0]['sentence'],'start_time':inputList1[0]['start'],'end_time':inputList1[0+len(inputList2[0]['sentence'].split())]['end'],'keywords':inputList2[0]['keywords']}\n# print(item)\n# # print(inputList1[len(inputList2[0]['sentence'])]['end'])\n# for i in range(0,len(inputList2[0]['sentence'].split())):\n#     if(inputList1[i]['word']==' Good'):\n#         output.append(inputList1[i]['word'])\n#     else:continue\nfinalop = []\ncurrentStartWord = 0",
        "detail": "edictai_app.app.test",
        "documentation": {}
    },
    {
        "label": "finalop",
        "kind": 5,
        "importPath": "edictai_app.app.test",
        "description": "edictai_app.app.test",
        "peekOfCode": "finalop = []\ncurrentStartWord = 0\nfor i in inputList2:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            if (inputList1[k]['word'].strip() == j):\n                keywordArray.append({'word':j,'start_time':inputList1[k]['start'],'end_time':inputList1[k]['end']})\n    print(inputList1[currentStartWord]['start'])\n    item = {'chunk': i['sentence'], 'start_time': inputList1[currentStartWord]['start'],",
        "detail": "edictai_app.app.test",
        "documentation": {}
    },
    {
        "label": "currentStartWord",
        "kind": 5,
        "importPath": "edictai_app.app.test",
        "description": "edictai_app.app.test",
        "peekOfCode": "currentStartWord = 0\nfor i in inputList2:\n    keywordArray = []\n    for j in i['keywords']:\n        for k in range(currentStartWord, currentStartWord+len(i['sentence'].split())):\n            if (inputList1[k]['word'].strip() == j):\n                keywordArray.append({'word':j,'start_time':inputList1[k]['start'],'end_time':inputList1[k]['end']})\n    print(inputList1[currentStartWord]['start'])\n    item = {'chunk': i['sentence'], 'start_time': inputList1[currentStartWord]['start'],\n            'end_time': inputList1[currentStartWord+len(i['sentence'].split())-1]['end'], 'keywords': keywordArray}",
        "detail": "edictai_app.app.test",
        "documentation": {}
    },
    {
        "label": "recognize_from_microphone",
        "kind": 2,
        "importPath": "edictai_app.app.test1",
        "description": "edictai_app.app.test1",
        "peekOfCode": "def recognize_from_microphone():\n    speech_config = speechsdk.SpeechConfig(subscription=tes1_api_key, region=\"centralindia\")\n    speech_config.speech_recognition_language=\"en-US\"\n    audio_config = speechsdk.AudioConfig(filename=\"audios/chunk.wav\")\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n    result = speech_recognizer.recognize_once_async().get()",
        "detail": "edictai_app.app.test1",
        "documentation": {}
    },
    {
        "label": "large_tts_azure",
        "kind": 2,
        "importPath": "edictai_app.app.text_to_speech_azure",
        "description": "edictai_app.app.text_to_speech_azure",
        "peekOfCode": "def large_tts_azure(chunk, meraNum):\n    # This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n    speech_config = speechsdk.SpeechConfig(subscription=text_to_speech_azure_subscription_key, region=\"centralindia\")\n    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n    # The language of the voice that speaks.\n    speech_config.speech_synthesis_voice_name='en-US-JennyNeural'\n    # speech_config.speech_synthesis_voice_name='mr-IN-AarohiNeural' \n    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n    # Get text from the console and synthesize to the default speaker.\n    # print(\"Enter some text that you want to speak >\")",
        "detail": "edictai_app.app.text_to_speech_azure",
        "documentation": {}
    },
    {
        "label": "bg_image",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "bg_image = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\background.jpg\")\nbg_width, bg_height = bg_image.size\nnew_bg_size = (800, 600)\nbg_image = bg_image.resize(new_bg_size)\n# Open the two images to be added\nimage1 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\test.png\")\nimage2 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\image1.jpeg\")\n# Resize the images to the desired size\nnew_size = (200, 200)\nnew_size2 = (200,300)",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "new_bg_size",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "new_bg_size = (800, 600)\nbg_image = bg_image.resize(new_bg_size)\n# Open the two images to be added\nimage1 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\test.png\")\nimage2 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\image1.jpeg\")\n# Resize the images to the desired size\nnew_size = (200, 200)\nnew_size2 = (200,300)\nimage1 = image1.resize(new_size2)\nimage2 = image2.resize(new_size)",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "bg_image",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "bg_image = bg_image.resize(new_bg_size)\n# Open the two images to be added\nimage1 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\test.png\")\nimage2 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\image1.jpeg\")\n# Resize the images to the desired size\nnew_size = (200, 200)\nnew_size2 = (200,300)\nimage1 = image1.resize(new_size2)\nimage2 = image2.resize(new_size)\n# Add white border to the images",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image1",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image1 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\test.png\")\nimage2 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\image1.jpeg\")\n# Resize the images to the desired size\nnew_size = (200, 200)\nnew_size2 = (200,300)\nimage1 = image1.resize(new_size2)\nimage2 = image2.resize(new_size)\n# Add white border to the images\nborder_width = 8\nimage1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image2",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image2 = Image.open(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\image captioning\\\\image1.jpeg\")\n# Resize the images to the desired size\nnew_size = (200, 200)\nnew_size2 = (200,300)\nimage1 = image1.resize(new_size2)\nimage2 = image2.resize(new_size)\n# Add white border to the images\nborder_width = 8\nimage1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))\nimage2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "new_size",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "new_size = (200, 200)\nnew_size2 = (200,300)\nimage1 = image1.resize(new_size2)\nimage2 = image2.resize(new_size)\n# Add white border to the images\nborder_width = 8\nimage1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))\nimage2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))\n# Calculate the position of the images\nimage1_x = border_width",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "new_size2",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "new_size2 = (200,300)\nimage1 = image1.resize(new_size2)\nimage2 = image2.resize(new_size)\n# Add white border to the images\nborder_width = 8\nimage1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))\nimage2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))\n# Calculate the position of the images\nimage1_x = border_width\nimage1_y = new_bg_size[1] - new_size[1] - border_width - 35",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image1",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image1 = image1.resize(new_size2)\nimage2 = image2.resize(new_size)\n# Add white border to the images\nborder_width = 8\nimage1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))\nimage2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))\n# Calculate the position of the images\nimage1_x = border_width\nimage1_y = new_bg_size[1] - new_size[1] - border_width - 35\nimage2_x = new_bg_size[0] - new_size[0] - border_width - 35",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image2",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image2 = image2.resize(new_size)\n# Add white border to the images\nborder_width = 8\nimage1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))\nimage2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))\n# Calculate the position of the images\nimage1_x = border_width\nimage1_y = new_bg_size[1] - new_size[1] - border_width - 35\nimage2_x = new_bg_size[0] - new_size[0] - border_width - 35\nimage2_y = border_width",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "border_width",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "border_width = 8\nimage1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))\nimage2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))\n# Calculate the position of the images\nimage1_x = border_width\nimage1_y = new_bg_size[1] - new_size[1] - border_width - 35\nimage2_x = new_bg_size[0] - new_size[0] - border_width - 35\nimage2_y = border_width\n# Paste the images onto the background image at the desired positions\nbg_image.paste(image1, (image1_x, image1_y))",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image1",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image1 = ImageOps.expand(image1, border=border_width, fill=(255, 255, 255))\nimage2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))\n# Calculate the position of the images\nimage1_x = border_width\nimage1_y = new_bg_size[1] - new_size[1] - border_width - 35\nimage2_x = new_bg_size[0] - new_size[0] - border_width - 35\nimage2_y = border_width\n# Paste the images onto the background image at the desired positions\nbg_image.paste(image1, (image1_x, image1_y))\nbg_image.paste(image2, (image2_x, image2_y))",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image2",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image2 = ImageOps.expand(image2, border=border_width, fill=(255, 255, 255))\n# Calculate the position of the images\nimage1_x = border_width\nimage1_y = new_bg_size[1] - new_size[1] - border_width - 35\nimage2_x = new_bg_size[0] - new_size[0] - border_width - 35\nimage2_y = border_width\n# Paste the images onto the background image at the desired positions\nbg_image.paste(image1, (image1_x, image1_y))\nbg_image.paste(image2, (image2_x, image2_y))\n# Calculate the position of the text",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image1_x",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image1_x = border_width\nimage1_y = new_bg_size[1] - new_size[1] - border_width - 35\nimage2_x = new_bg_size[0] - new_size[0] - border_width - 35\nimage2_y = border_width\n# Paste the images onto the background image at the desired positions\nbg_image.paste(image1, (image1_x, image1_y))\nbg_image.paste(image2, (image2_x, image2_y))\n# Calculate the position of the text\ntext = \"Sample Text\"\nfont = ImageFont.truetype(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\Helvetica.ttf\", 50)",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image1_y",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image1_y = new_bg_size[1] - new_size[1] - border_width - 35\nimage2_x = new_bg_size[0] - new_size[0] - border_width - 35\nimage2_y = border_width\n# Paste the images onto the background image at the desired positions\nbg_image.paste(image1, (image1_x, image1_y))\nbg_image.paste(image2, (image2_x, image2_y))\n# Calculate the position of the text\ntext = \"Sample Text\"\nfont = ImageFont.truetype(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\Helvetica.ttf\", 50)\ntext_width, text_height = font.getsize(text)",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image2_x",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image2_x = new_bg_size[0] - new_size[0] - border_width - 35\nimage2_y = border_width\n# Paste the images onto the background image at the desired positions\nbg_image.paste(image1, (image1_x, image1_y))\nbg_image.paste(image2, (image2_x, image2_y))\n# Calculate the position of the text\ntext = \"Sample Text\"\nfont = ImageFont.truetype(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\Helvetica.ttf\", 50)\ntext_width, text_height = font.getsize(text)\ntext_x1 = border_width",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "image2_y",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "image2_y = border_width\n# Paste the images onto the background image at the desired positions\nbg_image.paste(image1, (image1_x, image1_y))\nbg_image.paste(image2, (image2_x, image2_y))\n# Calculate the position of the text\ntext = \"Sample Text\"\nfont = ImageFont.truetype(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\Helvetica.ttf\", 50)\ntext_width, text_height = font.getsize(text)\ntext_x1 = border_width\ntext_y1 = border_width",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "text = \"Sample Text\"\nfont = ImageFont.truetype(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\Helvetica.ttf\", 50)\ntext_width, text_height = font.getsize(text)\ntext_x1 = border_width\ntext_y1 = border_width\ntext_x2 = new_bg_size[0] - text_width - border_width\ntext_y2 = new_bg_size[1] - text_height - border_width\n# Add text to the image\ndraw = ImageDraw.Draw(bg_image)\ndraw.text((text_x1, text_y1), text, font=font, fill=(255, 255, 255))",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "font",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "font = ImageFont.truetype(\"C:\\\\Users\\\\chawl\\\\Desktop\\\\n2v\\\\Helvetica.ttf\", 50)\ntext_width, text_height = font.getsize(text)\ntext_x1 = border_width\ntext_y1 = border_width\ntext_x2 = new_bg_size[0] - text_width - border_width\ntext_y2 = new_bg_size[1] - text_height - border_width\n# Add text to the image\ndraw = ImageDraw.Draw(bg_image)\ndraw.text((text_x1, text_y1), text, font=font, fill=(255, 255, 255))\ndraw.text((text_x2, text_y2), text, font=font, fill=(255, 255, 255))",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "text_x1",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "text_x1 = border_width\ntext_y1 = border_width\ntext_x2 = new_bg_size[0] - text_width - border_width\ntext_y2 = new_bg_size[1] - text_height - border_width\n# Add text to the image\ndraw = ImageDraw.Draw(bg_image)\ndraw.text((text_x1, text_y1), text, font=font, fill=(255, 255, 255))\ndraw.text((text_x2, text_y2), text, font=font, fill=(255, 255, 255))\n# Save the final image\nbg_image.save(\"output.jpg\")",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "text_y1",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "text_y1 = border_width\ntext_x2 = new_bg_size[0] - text_width - border_width\ntext_y2 = new_bg_size[1] - text_height - border_width\n# Add text to the image\ndraw = ImageDraw.Draw(bg_image)\ndraw.text((text_x1, text_y1), text, font=font, fill=(255, 255, 255))\ndraw.text((text_x2, text_y2), text, font=font, fill=(255, 255, 255))\n# Save the final image\nbg_image.save(\"output.jpg\")",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "text_x2",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "text_x2 = new_bg_size[0] - text_width - border_width\ntext_y2 = new_bg_size[1] - text_height - border_width\n# Add text to the image\ndraw = ImageDraw.Draw(bg_image)\ndraw.text((text_x1, text_y1), text, font=font, fill=(255, 255, 255))\ndraw.text((text_x2, text_y2), text, font=font, fill=(255, 255, 255))\n# Save the final image\nbg_image.save(\"output.jpg\")",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "text_y2",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "text_y2 = new_bg_size[1] - text_height - border_width\n# Add text to the image\ndraw = ImageDraw.Draw(bg_image)\ndraw.text((text_x1, text_y1), text, font=font, fill=(255, 255, 255))\ndraw.text((text_x2, text_y2), text, font=font, fill=(255, 255, 255))\n# Save the final image\nbg_image.save(\"output.jpg\")",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "draw",
        "kind": 5,
        "importPath": "edictai_app.app.thumbnail",
        "description": "edictai_app.app.thumbnail",
        "peekOfCode": "draw = ImageDraw.Draw(bg_image)\ndraw.text((text_x1, text_y1), text, font=font, fill=(255, 255, 255))\ndraw.text((text_x2, text_y2), text, font=font, fill=(255, 255, 255))\n# Save the final image\nbg_image.save(\"output.jpg\")",
        "detail": "edictai_app.app.thumbnail",
        "documentation": {}
    },
    {
        "label": "pan_effect",
        "kind": 2,
        "importPath": "edictai_app.app.transition",
        "description": "edictai_app.app.transition",
        "peekOfCode": "def pan_effect(input_image_path, custom_duration):\n    output_width = 1440\n    output_height = 2560\n    fps = 24\n    if input_image_path is None:\n        # If input image is None, create a black screen video\n        black_screen = np.zeros((output_height, output_width, 3), dtype=np.uint8)\n        out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (output_width, output_height))\n        for _ in range(int(custom_duration * fps)):\n            out.write(black_screen)",
        "detail": "edictai_app.app.transition",
        "documentation": {}
    },
    {
        "label": "input_image_path",
        "kind": 5,
        "importPath": "edictai_app.app.transition",
        "description": "edictai_app.app.transition",
        "peekOfCode": "input_image_path = 'chunk_3.jpg'\n# Set the output video properties\n# def pan_effect(input_image_path,custom_duration):\n#     output_width = 1440\n#     output_height = 2560\n#     fps = 24\n#     # Load the input image\n#     image = cv2.imread(input_image_path)\n#     # Calculate the aspect ratio of the input image\n#     aspect_ratio = image.shape[1] / image.shape[0]",
        "detail": "edictai_app.app.transition",
        "documentation": {}
    },
    {
        "label": "openai.organization",
        "kind": 5,
        "importPath": "edictai_app.app.trsst",
        "description": "edictai_app.app.trsst",
        "peekOfCode": "openai.organization = generate_script_openai_organization\nopenai.api_key = generate_script_openai_api_key\n# Create the image using OpenAI API\nresponse = openai.Image.create(\n    prompt=\"clock icon\",\n    n=1,\n    size=\"1024x1024\"\n)\n# Get the image URL from the response\nimage_url = response['data'][0]['url']",
        "detail": "edictai_app.app.trsst",
        "documentation": {}
    },
    {
        "label": "openai.api_key",
        "kind": 5,
        "importPath": "edictai_app.app.trsst",
        "description": "edictai_app.app.trsst",
        "peekOfCode": "openai.api_key = generate_script_openai_api_key\n# Create the image using OpenAI API\nresponse = openai.Image.create(\n    prompt=\"clock icon\",\n    n=1,\n    size=\"1024x1024\"\n)\n# Get the image URL from the response\nimage_url = response['data'][0]['url']\n# Define the filename for the downloaded image",
        "detail": "edictai_app.app.trsst",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.trsst",
        "description": "edictai_app.app.trsst",
        "peekOfCode": "response = openai.Image.create(\n    prompt=\"clock icon\",\n    n=1,\n    size=\"1024x1024\"\n)\n# Get the image URL from the response\nimage_url = response['data'][0]['url']\n# Define the filename for the downloaded image\nimage_filename = \"chunk.png\"\n# Download the image and save it with the desired filename",
        "detail": "edictai_app.app.trsst",
        "documentation": {}
    },
    {
        "label": "image_url",
        "kind": 5,
        "importPath": "edictai_app.app.trsst",
        "description": "edictai_app.app.trsst",
        "peekOfCode": "image_url = response['data'][0]['url']\n# Define the filename for the downloaded image\nimage_filename = \"chunk.png\"\n# Download the image and save it with the desired filename\nresponse = requests.get(image_url)\nif response.status_code == 200:\n    with open(image_filename, 'wb') as f:\n        f.write(response.content)\n    print(f\"Image downloaded and saved as {image_filename}\")\nelse:",
        "detail": "edictai_app.app.trsst",
        "documentation": {}
    },
    {
        "label": "image_filename",
        "kind": 5,
        "importPath": "edictai_app.app.trsst",
        "description": "edictai_app.app.trsst",
        "peekOfCode": "image_filename = \"chunk.png\"\n# Download the image and save it with the desired filename\nresponse = requests.get(image_url)\nif response.status_code == 200:\n    with open(image_filename, 'wb') as f:\n        f.write(response.content)\n    print(f\"Image downloaded and saved as {image_filename}\")\nelse:\n    print(\"Failed to download the image\")\n# Now the image is saved as \"chunk.png\" in your current working directory",
        "detail": "edictai_app.app.trsst",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "edictai_app.app.trsst",
        "description": "edictai_app.app.trsst",
        "peekOfCode": "response = requests.get(image_url)\nif response.status_code == 200:\n    with open(image_filename, 'wb') as f:\n        f.write(response.content)\n    print(f\"Image downloaded and saved as {image_filename}\")\nelse:\n    print(\"Failed to download the image\")\n# Now the image is saved as \"chunk.png\" in your current working directory",
        "detail": "edictai_app.app.trsst",
        "documentation": {}
    },
    {
        "label": "get_file_extension",
        "kind": 2,
        "importPath": "edictai_app.app.upload_blob",
        "description": "edictai_app.app.upload_blob",
        "peekOfCode": "def get_file_extension(file_name):\n    # Split the file name by '.' to separate the base name and extension\n    parts = file_name.split('.')\n    # Check if there is at least one period in the file name\n    if len(parts) > 1:\n        # The file extension is the last part of the split\n        extension = parts[-1]\n        return extension\n    else:\n        # If there's no period, return an empty string to indicate no extension",
        "detail": "edictai_app.app.upload_blob",
        "documentation": {}
    },
    {
        "label": "blob_file_upload",
        "kind": 2,
        "importPath": "edictai_app.app.upload_blob",
        "description": "edictai_app.app.upload_blob",
        "peekOfCode": "def blob_file_upload(upload_file_path):\n    # local_file_name =  \"chunk_1.jpg\"\n    # upload_file_path = f\"images/{local_file_name}\"\n    uniID=uuid.uuid1()\n    blob_client = blob_service_client.get_blob_client(container=\"images\", blob=str(uniID))\n    print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + str(uniID))\n    with open(file=upload_file_path, mode=\"rb\") as data:\n        blob_client.upload_blob(data)\n    return str(uniID)\ndef list_blobs():",
        "detail": "edictai_app.app.upload_blob",
        "documentation": {}
    },
    {
        "label": "list_blobs",
        "kind": 2,
        "importPath": "edictai_app.app.upload_blob",
        "description": "edictai_app.app.upload_blob",
        "peekOfCode": "def list_blobs():\n    print(\"\\nListing blobs...\")\n    blob_list = container_client.list_blobs()\n    for blob in blob_list:\n        print(\"\\t\" + blob.name)\ndef download_blobs():\n    print(\"\\nDownloading blob to \\n\\t\" + \"blob_images\")\n    blob_list = container_client.list_blobs()\n    for blob in blob_list: \n        with open(file=f\"blob_images/{blob.name}\", mode=\"wb\") as download_file:",
        "detail": "edictai_app.app.upload_blob",
        "documentation": {}
    },
    {
        "label": "download_blobs",
        "kind": 2,
        "importPath": "edictai_app.app.upload_blob",
        "description": "edictai_app.app.upload_blob",
        "peekOfCode": "def download_blobs():\n    print(\"\\nDownloading blob to \\n\\t\" + \"blob_images\")\n    blob_list = container_client.list_blobs()\n    for blob in blob_list: \n        with open(file=f\"blob_images/{blob.name}\", mode=\"wb\") as download_file:\n            download_file.write(container_client.download_blob(blob.name).readall())\n# try:\n#     print(\"Azure Blob Storage Python quickstart sample\")\n#     blob_file_upload()\n#     # list_blobs()",
        "detail": "edictai_app.app.upload_blob",
        "documentation": {}
    },
    {
        "label": "blob_service_client",
        "kind": 5,
        "importPath": "edictai_app.app.upload_blob",
        "description": "edictai_app.app.upload_blob",
        "peekOfCode": "blob_service_client = BlobServiceClient.from_connection_string(f\"DefaultEndpointsProtocol=https;AccountName=mentormeestorage;AccountKey=/{upload_blob_api_key}/GJ0lsRDkRgZf+AStG+6wlA==;EndpointSuffix=core.windows.net\")\ncontainer_client = blob_service_client.get_container_client(container= \"images\")\ndef get_file_extension(file_name):\n    # Split the file name by '.' to separate the base name and extension\n    parts = file_name.split('.')\n    # Check if there is at least one period in the file name\n    if len(parts) > 1:\n        # The file extension is the last part of the split\n        extension = parts[-1]\n        return extension",
        "detail": "edictai_app.app.upload_blob",
        "documentation": {}
    },
    {
        "label": "container_client",
        "kind": 5,
        "importPath": "edictai_app.app.upload_blob",
        "description": "edictai_app.app.upload_blob",
        "peekOfCode": "container_client = blob_service_client.get_container_client(container= \"images\")\ndef get_file_extension(file_name):\n    # Split the file name by '.' to separate the base name and extension\n    parts = file_name.split('.')\n    # Check if there is at least one period in the file name\n    if len(parts) > 1:\n        # The file extension is the last part of the split\n        extension = parts[-1]\n        return extension\n    else:",
        "detail": "edictai_app.app.upload_blob",
        "documentation": {}
    },
    {
        "label": "upload_video",
        "kind": 2,
        "importPath": "edictai_app.app.upload_cloudinary",
        "description": "edictai_app.app.upload_cloudinary",
        "peekOfCode": "def upload_video(location):\n    cloudinary.config( \n    cloud_name = \"mentormee-cloud\", \n  api_key = cloudinary_api_key, \n  api_secret = cloudinary_api_secret  \n    )\n    data = cloudinary.uploader.upload(location, \n    resource_type='video', \n    public_id='video_upload_example')\n    return data['secure_url']",
        "detail": "edictai_app.app.upload_cloudinary",
        "documentation": {}
    },
    {
        "label": "create_media_object",
        "kind": 2,
        "importPath": "edictai_app.app.upload_socials",
        "description": "edictai_app.app.upload_socials",
        "peekOfCode": "def create_media_object(params):\n    url = f\"{params['endpoint_base']}{params['instagram_account_id']}/media\"  # endpoint url\n    endpoint_params = {\n        'caption': params['caption'],\n        'access_token': params['access_token']\n    }\n    if params['media_type'] == 'IMAGE':  # posting image\n        endpoint_params['image_url'] = params['media_url']  # url to the asset\n    else:  # posting video\n        endpoint_params['media_type'] = params['media_type']  # specify media type",
        "detail": "edictai_app.app.upload_socials",
        "documentation": {}
    },
    {
        "label": "get_media_object_status",
        "kind": 2,
        "importPath": "edictai_app.app.upload_socials",
        "description": "edictai_app.app.upload_socials",
        "peekOfCode": "def get_media_object_status(media_object_id, params):\n    url = f\"{params['endpoint_base']}/{media_object_id}\"  # endpoint url\n    endpoint_params = {\n        'fields': 'status_code',\n        'access_token': params['access_token']          \n    }\n    response = requests.get(url, params=endpoint_params)\n    return response.json()  # make the api call\ndef publish_media(media_object_id, params):\n    \"\"\" Publish content",
        "detail": "edictai_app.app.upload_socials",
        "documentation": {}
    },
    {
        "label": "publish_media",
        "kind": 2,
        "importPath": "edictai_app.app.upload_socials",
        "description": "edictai_app.app.upload_socials",
        "peekOfCode": "def publish_media(media_object_id, params):\n    \"\"\" Publish content\n    Args:\n        media_object_id: id of the media object\n        params: dictionary of params\n    API Endpoint:\n        https://graph.facebook.com/v5.0/{ig-user-id}/media_publish?creation_id={creation-id}&access_token={access-token}\n    Returns:\n        object: data from the endpoint\n    \"\"\"",
        "detail": "edictai_app.app.upload_socials",
        "documentation": {}
    },
    {
        "label": "get_content_publishing_limit",
        "kind": 2,
        "importPath": "edictai_app.app.upload_socials",
        "description": "edictai_app.app.upload_socials",
        "peekOfCode": "def get_content_publishing_limit(params):\n    \"\"\" Get the API limit for the user\n    Args:\n        params: dictionary of params\n    API Endpoint:\n        https://graph.facebook.com/v5.0/{ig-user-id}/content_publishing_limit?fields=config,quota_usage\n    Returns:\n        object: data from the endpoint\n    \"\"\"\n    url = f\"{params['endpoint_base']}{params['instagram_account_id']}/content_publishing_limit\"  # endpoint url",
        "detail": "edictai_app.app.upload_socials",
        "documentation": {}
    },
    {
        "label": "Upload_video_on_one_click",
        "kind": 2,
        "importPath": "edictai_app.app.upload_socials",
        "description": "edictai_app.app.upload_socials",
        "peekOfCode": "def Upload_video_on_one_click(url, caption) :\n    params = {\n        'endpoint_base': 'https://graph.facebook.com/v18.0/',\n        'instagram_account_id': '17841462256631392',\n        'access_token': upload_social_access_token,\n        'media_type': 'VIDEO',  # or 'VIDEO'\n        'media_url': url,\n        'caption': caption,\n    }\n    video_media_object_response = create_media_object(params)",
        "detail": "edictai_app.app.upload_socials",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "edictai_app.migrations.0001_initial",
        "description": "edictai_app.migrations.0001_initial",
        "peekOfCode": "class Migration(migrations.Migration):\n    initial = True\n    dependencies = [\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='Videos',\n            fields=[\n                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('video', models.FileField(upload_to='video/')),",
        "detail": "edictai_app.migrations.0001_initial",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "edictai_app.migrations.0002_images_videos_audio_alter_videos_script_and_more",
        "description": "edictai_app.migrations.0002_images_videos_audio_alter_videos_script_and_more",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('edictai_app', '0001_initial'),\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='Images',\n            fields=[\n                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('image', models.FileField(blank=1, upload_to='images/')),",
        "detail": "edictai_app.migrations.0002_images_videos_audio_alter_videos_script_and_more",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "edictai_app.migrations.0003_videos_timestamp_videoclips",
        "description": "edictai_app.migrations.0003_videos_timestamp_videoclips",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('edictai_app', '0002_images_videos_audio_alter_videos_script_and_more'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='videos',\n            name='timestamp',\n            field=models.DateTimeField(auto_now=True),\n        ),",
        "detail": "edictai_app.migrations.0003_videos_timestamp_videoclips",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "edictai_app.migrations.0004_videos_link",
        "description": "edictai_app.migrations.0004_videos_link",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('edictai_app', '0003_videos_timestamp_videoclips'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='videos',\n            name='link',\n            field=models.CharField(blank=1, max_length=200),\n        ),",
        "detail": "edictai_app.migrations.0004_videos_link",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "edictai_app.migrations.0005_alter_videos_timestamp",
        "description": "edictai_app.migrations.0005_alter_videos_timestamp",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('edictai_app', '0004_videos_link'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name='videos',\n            name='timestamp',\n            field=models.DateTimeField(auto_now_add=True),\n        ),",
        "detail": "edictai_app.migrations.0005_alter_videos_timestamp",
        "documentation": {}
    },
    {
        "label": "EdictaiAppConfig",
        "kind": 6,
        "importPath": "edictai_app.apps",
        "description": "edictai_app.apps",
        "peekOfCode": "class EdictaiAppConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'edictai_app'",
        "detail": "edictai_app.apps",
        "documentation": {}
    },
    {
        "label": "Videos",
        "kind": 6,
        "importPath": "edictai_app.models",
        "description": "edictai_app.models",
        "peekOfCode": "class Videos(models.Model):\n    video=models.FileField(upload_to=\"video/\",blank=1)\n    name=models.CharField(max_length=100)\n    script=models.TextField(blank=1)\n    audio=models.FileField(upload_to='audios/',blank=1)\n    link=models.CharField(max_length=200,blank=1)\n    timestamp=models.DateTimeField(auto_now_add=True)\nclass Images(models.Model):\n    image=models.FileField(upload_to='images/',blank=1)\n    video=models.ForeignKey(Videos,on_delete=models.CASCADE)",
        "detail": "edictai_app.models",
        "documentation": {}
    },
    {
        "label": "Images",
        "kind": 6,
        "importPath": "edictai_app.models",
        "description": "edictai_app.models",
        "peekOfCode": "class Images(models.Model):\n    image=models.FileField(upload_to='images/',blank=1)\n    video=models.ForeignKey(Videos,on_delete=models.CASCADE)\nclass Videoclips(models.Model):\n    videoclip=models.FileField(upload_to='videoclips/')\n    video=models.ForeignKey(Videos,on_delete=models.CASCADE)\n# Create your models here.",
        "detail": "edictai_app.models",
        "documentation": {}
    },
    {
        "label": "Videoclips",
        "kind": 6,
        "importPath": "edictai_app.models",
        "description": "edictai_app.models",
        "peekOfCode": "class Videoclips(models.Model):\n    videoclip=models.FileField(upload_to='videoclips/')\n    video=models.ForeignKey(Videos,on_delete=models.CASCADE)\n# Create your models here.",
        "detail": "edictai_app.models",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "edictai_app.urls",
        "description": "edictai_app.urls",
        "peekOfCode": "urlpatterns = [\n    path('',views.index,name=\"index\"),\n    path(\"test/\",views.test,name=\"test\"),\n    path('posttest',csrf_exempt(views.posttest),name=\"posttest\")\n]\nif settings.DEBUG:\n    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)",
        "detail": "edictai_app.urls",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "edictai_app.views",
        "description": "edictai_app.views",
        "peekOfCode": "def index(req):\n    if req.method==\"POST\":\n            print(\"post request arrived\")\n            url=req.POST.get('url')\n            url2 = req.POST.get('url2')\n            content_passed = req.POST.get('contentorurl')\n            if content_passed==\"url_pass\":\n                link=new_final.edict_video(url,content_passed)\n            else:\n                link=new_final.edict_video(url2,content_passed)",
        "detail": "edictai_app.views",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "edictai_app.views",
        "description": "edictai_app.views",
        "peekOfCode": "def test(req):\n    path = Path(\"videos/chunk_7.mp4\")\n    video=Videos()\n    with path.open(mode=\"rb\") as f:\n        video.name=\"ASif\"\n        video.video = File(f, name=path.name)\n        video.save()\n    return HttpResponse(\"Test chal raha hai\")\ndef posttest(req):\n    print(\"body\",req.body)",
        "detail": "edictai_app.views",
        "documentation": {}
    },
    {
        "label": "posttest",
        "kind": 2,
        "importPath": "edictai_app.views",
        "description": "edictai_app.views",
        "peekOfCode": "def posttest(req):\n    print(\"body\",req.body)\n    json_data = req.body.decode('utf-8')\n    python_data = json.loads(json_data)\n    print(python_data['name'])\n    return HttpResponse(\"Test chal raha hai\")\n# Create your views here.",
        "detail": "edictai_app.views",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "manage",
        "description": "manage",
        "peekOfCode": "def main():\n    \"\"\"Run administrative tasks.\"\"\"\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'EdictAI.settings')\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError(\n            \"Couldn't import Django. Are you sure it's installed and \"\n            \"available on your PYTHONPATH environment variable? Did you \"\n            \"forget to activate a virtual environment?\"",
        "detail": "manage",
        "documentation": {}
    }
]